{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523b4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (15912393, 22)\n",
      "Columns: ['YEAR', 'MULTYEAR', 'SAMPLE', 'SERIAL', 'CBSERIAL', 'HHWT', 'CLUSTER', 'STATEFIP', 'COUNTYICP', 'COUNTYFIP', 'PUMA', 'MET2013', 'STRATA', 'GQ', 'PERNUM', 'PERWT', 'AGE', 'EMPSTAT', 'EMPSTATD', 'LABFORCE', 'IND', 'INDNAICS']\n",
      "\n",
      "First few rows:\n",
      "   YEAR  MULTYEAR  SAMPLE  SERIAL       CBSERIAL  HHWT        CLUSTER  \\\n",
      "0  2023      2019  202303       1  2019010000088   2.0  2023000000013   \n",
      "1  2023      2019  202303       2  2019010000096  14.0  2023000000023   \n",
      "2  2023      2019  202303       3  2019010000153   4.0  2023000000033   \n",
      "3  2023      2019  202303       4  2019010000198  17.0  2023000000043   \n",
      "4  2023      2019  202303       5  2019010000205  11.0  2023000000053   \n",
      "\n",
      "   STATEFIP  COUNTYICP  COUNTYFIP  ...  STRATA  GQ  PERNUM  PERWT  AGE  \\\n",
      "0         1          0          0  ...  260001   4       1    2.0   39   \n",
      "1         1          0          0  ...   70001   3       1   14.0   21   \n",
      "2         1        150         15  ...   80001   4       1    4.0   19   \n",
      "3         1        150         15  ...   80001   3       1   17.0   77   \n",
      "4         1        970         97  ...  280301   3       1   11.0   41   \n",
      "\n",
      "   EMPSTAT  EMPSTATD  LABFORCE   IND  INDNAICS  \n",
      "0        3        30         1     0         0  \n",
      "1        3        30         1     0         0  \n",
      "2        1        10         2  9160   8131     \n",
      "3        3        30         1     0         0  \n",
      "4        3        30         1     0         0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the compressed CSV file\n",
    "# file_path = r\"C:\\Users\\JennyDuan\\OneDrive - Burning Glass Institute\\BGI Projects\\Rural Data Paper\\usa_00051.csv.gz\"\n",
    "file_path = \"usa_00051.csv.gz\"\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ca0d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MULTYEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>COUNTYICP</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>...</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>EMPSTATD</th>\n",
       "      <th>LABFORCE</th>\n",
       "      <th>IND</th>\n",
       "      <th>INDNAICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>1</td>\n",
       "      <td>2019010000088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023000000013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>260001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>2</td>\n",
       "      <td>2019010000096</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2023000000023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>3</td>\n",
       "      <td>2019010000153</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023000000033</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>80001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9160</td>\n",
       "      <td>8131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>4</td>\n",
       "      <td>2019010000198</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2023000000043</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>80001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>5</td>\n",
       "      <td>2019010000205</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2023000000053</td>\n",
       "      <td>1</td>\n",
       "      <td>970</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>280301</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912388</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086486</td>\n",
       "      <td>2023001457972</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2023070864863</td>\n",
       "      <td>56</td>\n",
       "      <td>210</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>30056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7860</td>\n",
       "      <td>6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912389</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086486</td>\n",
       "      <td>2023001457972</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2023070864863</td>\n",
       "      <td>56</td>\n",
       "      <td>210</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>30056</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>7860</td>\n",
       "      <td>6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912390</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086487</td>\n",
       "      <td>2023001458196</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2023070864873</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8191</td>\n",
       "      <td>622M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912391</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086488</td>\n",
       "      <td>2023001459187</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023070864883</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10056</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912392</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086488</td>\n",
       "      <td>2023001459187</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023070864883</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10056</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15912393 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          YEAR  MULTYEAR  SAMPLE   SERIAL       CBSERIAL  HHWT        CLUSTER  \\\n",
       "0         2023      2019  202303        1  2019010000088   2.0  2023000000013   \n",
       "1         2023      2019  202303        2  2019010000096  14.0  2023000000023   \n",
       "2         2023      2019  202303        3  2019010000153   4.0  2023000000033   \n",
       "3         2023      2019  202303        4  2019010000198  17.0  2023000000043   \n",
       "4         2023      2019  202303        5  2019010000205  11.0  2023000000053   \n",
       "...        ...       ...     ...      ...            ...   ...            ...   \n",
       "15912388  2023      2023  202303  7086486  2023001457972  15.0  2023070864863   \n",
       "15912389  2023      2023  202303  7086486  2023001457972  15.0  2023070864863   \n",
       "15912390  2023      2023  202303  7086487  2023001458196  15.0  2023070864873   \n",
       "15912391  2023      2023  202303  7086488  2023001459187   7.0  2023070864883   \n",
       "15912392  2023      2023  202303  7086488  2023001459187   7.0  2023070864883   \n",
       "\n",
       "          STATEFIP  COUNTYICP  COUNTYFIP  ...  STRATA  GQ  PERNUM  PERWT  AGE  \\\n",
       "0                1          0          0  ...  260001   4       1    2.0   39   \n",
       "1                1          0          0  ...   70001   3       1   14.0   21   \n",
       "2                1        150         15  ...   80001   4       1    4.0   19   \n",
       "3                1        150         15  ...   80001   3       1   17.0   77   \n",
       "4                1        970         97  ...  280301   3       1   11.0   41   \n",
       "...            ...        ...        ...  ...     ...  ..     ...    ...  ...   \n",
       "15912388        56        210         21  ...   30056   1       1   14.0   53   \n",
       "15912389        56        210         21  ...   30056   1       2   12.0   66   \n",
       "15912390        56          0          0  ...   20056   1       1   14.0   63   \n",
       "15912391        56          0          0  ...   10056   1       1    8.0   63   \n",
       "15912392        56          0          0  ...   10056   1       2    9.0   66   \n",
       "\n",
       "          EMPSTAT  EMPSTATD  LABFORCE   IND  INDNAICS  \n",
       "0               3        30         1     0         0  \n",
       "1               3        30         1     0         0  \n",
       "2               1        10         2  9160   8131     \n",
       "3               3        30         1     0         0  \n",
       "4               3        30         1     0         0  \n",
       "...           ...       ...       ...   ...       ...  \n",
       "15912388        1        10         2  7860   6111     \n",
       "15912389        3        30         1  7860   6111     \n",
       "15912390        1        10         2  8191   622M     \n",
       "15912391        3        30         1     0         0  \n",
       "15912392        3        30         1     0         0  \n",
       "\n",
       "[15912393 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71bfca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in dataset: 15,912,393\n",
      "COUNTYICP (ICPSR codes) Coverage:\n",
      "  Records with identifiable counties: 9,961,492 (62.6%)\n",
      "  Records with unidentifiable counties: 5,950,901 (37.4%)\n",
      "  Unique counties identified: 129\n",
      "\n",
      "Population coverage (using PERWT):\n",
      "  Total population: 332,387,543\n",
      "  COUNTYICP identified population: 225,979,438 (68.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic dataset overview\n",
    "print(f\"Total records in dataset: {len(df):,}\")\n",
    "\n",
    "# COUNTYICP analysis  \n",
    "countyicp_identified = df[df['COUNTYICP'] != 0]\n",
    "countyicp_missing = df[df['COUNTYICP'] == 0]\n",
    "print(\"COUNTYICP (ICPSR codes) Coverage:\")\n",
    "print(f\"  Records with identifiable counties: {len(countyicp_identified):,} ({len(countyicp_identified)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Records with unidentifiable counties: {len(countyicp_missing):,} ({len(countyicp_missing)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Unique counties identified: {df['COUNTYICP'].nunique()-1}\")  # -1 to exclude 0\n",
    "print()\n",
    "\n",
    "# Population coverage\n",
    "total_pop = df['PERWT'].sum()\n",
    "countyicp_pop = countyicp_identified['PERWT'].sum()\n",
    "print(f\"Population coverage (using PERWT):\")\n",
    "print(f\"  Total population: {total_pop:,.0f}\")\n",
    "print(f\"  COUNTYICP identified population: {countyicp_pop:,.0f} ({countyicp_pop/total_pop*100:.1f}%)\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d87239",
   "metadata": {},
   "source": [
    "# Rural Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e62f7ebb-5116-460a-a8bd-926caa595703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rural dataframe\n",
    "rural_df = df[df['MET2013'] == 0].copy()\n",
    "rural_df = rural_df[rural_df['PUMA'] != 0]  # Ensure PUMA is identified\n",
    "rural_df['metro_status'] = 'Non-metro/Rural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "161050b3-1db5-44ee-97b6-cacf050e2fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rural PUMA populations...\n",
      "   Rural DataFrame: 4,142,396 records\n",
      "   Rural population: 69,123,668\n",
      "   Rural PUMAs: 164\n"
     ]
    }
   ],
   "source": [
    "# Calculate PUMA populations in rural areas\n",
    "print(\"Calculating rural PUMA populations...\")\n",
    "# Create unique PUMA identifier using STATEFIP + PUMA\n",
    "rural_df['unique_puma'] = rural_df['STATEFIP'].astype(str) + '_' + rural_df['PUMA'].astype(str)\n",
    "\n",
    "# Add metro status classification\n",
    "rural_df['metro_status'] = 'Non-metro/Rural'\n",
    "\n",
    "print(f\"   Rural DataFrame: {len(rural_df):,} records\")\n",
    "print(f\"   Rural population: {rural_df['PERWT'].sum():,.0f}\")\n",
    "print(f\"   Rural PUMAs: {rural_df['PUMA'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd9c0426-ae84-477a-af0f-648f1ff49e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MULTYEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>COUNTYICP</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>...</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>EMPSTATD</th>\n",
       "      <th>LABFORCE</th>\n",
       "      <th>IND</th>\n",
       "      <th>INDNAICS</th>\n",
       "      <th>metro_status</th>\n",
       "      <th>unique_puma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>1</td>\n",
       "      <td>2019010000088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023000000013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>1_2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>2</td>\n",
       "      <td>2019010000096</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2023000000023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>1_700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>8</td>\n",
       "      <td>2019010000284</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023000000083</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>1_1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>13</td>\n",
       "      <td>2019010000617</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2023000000133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>1_2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023</td>\n",
       "      <td>2019</td>\n",
       "      <td>202303</td>\n",
       "      <td>17</td>\n",
       "      <td>2019010000742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023000000173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>1_1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912386</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086485</td>\n",
       "      <td>2023001456541</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2023070864853</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>722Z</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>56_500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912387</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086485</td>\n",
       "      <td>2023001456541</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2023070864853</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9480</td>\n",
       "      <td>923</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>56_500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912390</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086487</td>\n",
       "      <td>2023001458196</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2023070864873</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8191</td>\n",
       "      <td>622M</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>56_200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912391</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086488</td>\n",
       "      <td>2023001459187</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023070864883</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>56_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912392</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>202303</td>\n",
       "      <td>7086488</td>\n",
       "      <td>2023001459187</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023070864883</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>56_100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4142396 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          YEAR  MULTYEAR  SAMPLE   SERIAL       CBSERIAL  HHWT        CLUSTER  \\\n",
       "0         2023      2019  202303        1  2019010000088   2.0  2023000000013   \n",
       "1         2023      2019  202303        2  2019010000096  14.0  2023000000023   \n",
       "7         2023      2019  202303        8  2019010000284   3.0  2023000000083   \n",
       "12        2023      2019  202303       13  2019010000617  14.0  2023000000133   \n",
       "16        2023      2019  202303       17  2019010000742  16.0  2023000000173   \n",
       "...        ...       ...     ...      ...            ...   ...            ...   \n",
       "15912386  2023      2023  202303  7086485  2023001456541  25.0  2023070864853   \n",
       "15912387  2023      2023  202303  7086485  2023001456541  25.0  2023070864853   \n",
       "15912390  2023      2023  202303  7086487  2023001458196  15.0  2023070864873   \n",
       "15912391  2023      2023  202303  7086488  2023001459187   7.0  2023070864883   \n",
       "15912392  2023      2023  202303  7086488  2023001459187   7.0  2023070864883   \n",
       "\n",
       "          STATEFIP  COUNTYICP  COUNTYFIP  ...  PERNUM  PERWT  AGE  EMPSTAT  \\\n",
       "0                1          0          0  ...       1    2.0   39        3   \n",
       "1                1          0          0  ...       1   14.0   21        3   \n",
       "7                1          0          0  ...       1    3.0   35        3   \n",
       "12               1          0          0  ...       1   14.0   19        3   \n",
       "16               1          0          0  ...       1   16.0   25        3   \n",
       "...            ...        ...        ...  ...     ...    ...  ...      ...   \n",
       "15912386        56          0          0  ...       3   15.0   42        1   \n",
       "15912387        56          0          0  ...       4   15.0   38        1   \n",
       "15912390        56          0          0  ...       1   14.0   63        1   \n",
       "15912391        56          0          0  ...       1    8.0   63        3   \n",
       "15912392        56          0          0  ...       2    9.0   66        3   \n",
       "\n",
       "          EMPSTATD  LABFORCE   IND  INDNAICS     metro_status  unique_puma  \n",
       "0               30         1     0         0  Non-metro/Rural       1_2600  \n",
       "1               30         1     0         0  Non-metro/Rural        1_700  \n",
       "7               30         1     0         0  Non-metro/Rural       1_1100  \n",
       "12              30         1     0         0  Non-metro/Rural       1_2000  \n",
       "16              30         1     0         0  Non-metro/Rural       1_1600  \n",
       "...            ...       ...   ...       ...              ...          ...  \n",
       "15912386        10         2  8680   722Z     Non-metro/Rural       56_500  \n",
       "15912387        10         2  9480   923      Non-metro/Rural       56_500  \n",
       "15912390        10         2  8191   622M     Non-metro/Rural       56_200  \n",
       "15912391        30         1     0         0  Non-metro/Rural       56_100  \n",
       "15912392        30         1     0         0  Non-metro/Rural       56_100  \n",
       "\n",
       "[4142396 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rural_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3280ec5a-fb9d-4e5e-8198-089eef926161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rural PUMAs identified: 509\n"
     ]
    }
   ],
   "source": [
    "# Rural pumas population counts\n",
    "rural_puma_pop = rural_df.groupby('unique_puma').agg({\n",
    "    'PERWT': 'sum',\n",
    "    'STATEFIP': 'first', \n",
    "    'PUMA': 'first'\n",
    "}).reset_index()\n",
    "rural_puma_pop.columns = ['unique_puma', 'population', 'STATEFIP', 'PUMA']\n",
    "print(f\"Rural PUMAs identified: {len(rural_puma_pop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91cf0b61-ffd7-49f4-88e1-c123b574ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population bins\n",
    "pop_bins = [0, 75000, 100000, 125000, 150000, 175000, 200000, 250000, np.inf]\n",
    "pop_labels = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', '175-200K', '200-250K', '250K+']\n",
    "rural_puma_pop['pop_label'] = pd.cut(rural_puma_pop['population'], bins=pop_bins, labels=pop_labels, right=False)\n",
    "puma_counts = rural_puma_pop['pop_label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb5d52b1-334e-4b40-9fe7-95ace108bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rural employed persons: 31,199,345\n"
     ]
    }
   ],
   "source": [
    "# Get employed persons\n",
    "rural_employed = rural_df[rural_df['EMPSTAT'] == 1].copy()\n",
    "print(f\"Total rural employed persons: {rural_employed['PERWT'].sum():,.0f}\")\n",
    "\n",
    "# Map to NAICS 2-digit\n",
    "def map_to_naics_2digit(ind_code):\n",
    "    \"\"\"Map IND codes to 2-digit NAICS sectors\"\"\"\n",
    "    if pd.isna(ind_code) or ind_code == 0:\n",
    "        return 'Other'\n",
    "    \n",
    "    ind_str = str(int(ind_code)).zfill(4)\n",
    "    \n",
    "    if ind_str.startswith(('017', '018', '019', '027', '028', '029')):\n",
    "        return 'NAICS_11'  # Agriculture, Forestry, Fishing and Hunting\n",
    "    elif ind_str.startswith(('037', '038', '039', '047', '048', '049')):\n",
    "        return 'NAICS_21'  # Mining, Quarrying, and Oil and Gas Extraction\n",
    "    elif ind_str.startswith(('057', '058', '059')):\n",
    "        return 'NAICS_22'  # Utilities\n",
    "    elif ind_str.startswith(('067', '068', '069', '077', '078', '079')):\n",
    "        return 'NAICS_23'  # Construction\n",
    "    elif ind_str.startswith(('107', '108', '109', '117', '118', '119', '127', '128', '129',\n",
    "                             '137', '138', '139', '147', '148', '149', '157', '158', '159',\n",
    "                             '167', '168', '169', '177', '178', '179', '187', '188', '189',\n",
    "                             '197', '198', '199', '207', '208', '209', '217', '218', '219',\n",
    "                             '227', '228', '229', '237', '238', '239', '247', '248', '249',\n",
    "                             '257', '258', '259', '267', '268', '269', '277', '278', '279',\n",
    "                             '287', '288', '289', '297', '298', '299', '307', '308', '309',\n",
    "                             '317', '318', '319', '327', '328', '329', '337', '338', '339',\n",
    "                             '347', '348', '349', '357', '358', '359', '367', '368', '369',\n",
    "                             '377', '378', '379', '387', '388', '389', '397', '398', '399')):\n",
    "        return 'NAICS_31-33'  # Manufacturing\n",
    "    elif ind_str.startswith(('407', '408', '409', '417', '418', '419', '427', '428', '429')):\n",
    "        return 'NAICS_42'  # Wholesale Trade\n",
    "    elif ind_str.startswith(('447', '448', '449', '457', '458', '459', '467', '468', '469',\n",
    "                             '477', '478', '479', '487', '488', '489', '497', '498', '499',\n",
    "                             '507', '508', '509', '517', '518', '519', '527', '528', '529',\n",
    "                             '537', '538', '539', '547', '548', '549', '557', '558', '559',\n",
    "                             '567', '568', '569', '577', '578', '579', '587', '588', '589',\n",
    "                             '597', '598', '599')):\n",
    "        return 'NAICS_44-45'  # Retail Trade\n",
    "    elif ind_str.startswith(('607', '608', '609', '617', '618', '619', '627', '628', '629',\n",
    "                             '637', '638', '639', '647', '648', '649', '657', '658', '659')):\n",
    "        return 'NAICS_48-49'  # Transportation and Warehousing\n",
    "    elif ind_str.startswith(('667', '668', '669', '677', '678', '679', '687', '688', '689')):\n",
    "        return 'NAICS_51'  # Information\n",
    "    elif ind_str.startswith(('697', '698', '699', '707', '708', '709')):\n",
    "        return 'NAICS_52'  # Finance and Insurance\n",
    "    elif ind_str.startswith(('717', '718', '719', '727', '728', '729')):\n",
    "        return 'NAICS_53'  # Real Estate and Rental and Leasing\n",
    "    elif ind_str.startswith(('737', '738', '739', '747', '748', '749', '757', '758', '759')):\n",
    "        return 'NAICS_54'  # Professional, Scientific, and Technical Services\n",
    "    elif ind_str.startswith(('767', '768', '769')):\n",
    "        return 'NAICS_55'  # Management of Companies and Enterprises\n",
    "    elif ind_str.startswith(('777', '778', '779', '787', '788', '789')):\n",
    "        return 'NAICS_56'  # Administrative and Support and Waste Management\n",
    "    elif ind_str.startswith(('807', '808', '809', '817', '818', '819')):\n",
    "        return 'NAICS_61'  # Educational Services\n",
    "    elif ind_str.startswith(('827', '828', '829', '837', '838', '839', '847', '848', '849',\n",
    "                             '857', '858', '859', '867', '868', '869')):\n",
    "        return 'NAICS_62'  # Health Care and Social Assistance\n",
    "    elif ind_str.startswith(('877', '878', '879', '887', '888', '889')):\n",
    "        return 'NAICS_71'  # Arts, Entertainment, and Recreation\n",
    "    elif ind_str.startswith(('897', '898', '899')):\n",
    "        return 'NAICS_72'  # Accommodation and Food Services\n",
    "    elif ind_str.startswith(('907', '908', '909', '917', '918', '919', '927', '928', '929')):\n",
    "        return 'NAICS_81'  # Other Services (except Public Administration)\n",
    "    elif ind_str.startswith(('937', '938', '939', '947', '948', '949', '957', '958', '959')):\n",
    "        return 'NAICS_92'  # Public Administration\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply NAICS mapping\n",
    "rural_employed['naics_2digit'] = rural_employed['IND'].apply(map_to_naics_2digit)\n",
    "\n",
    "# Add unique PUMA identifier to employed data\n",
    "rural_employed['unique_puma'] = rural_employed['STATEFIP'].astype(str) + '_' + rural_employed['PUMA'].astype(str)\n",
    "\n",
    "# Add population label to employed data\n",
    "rural_employed_with_pop = rural_employed.merge(rural_puma_pop[['unique_puma', 'pop_label']], on='unique_puma', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e7537e8-fa5b-45b0-9846-67fcf4e00930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment percentages calculated\n",
      "Complete employment summary created\n"
     ]
    }
   ],
   "source": [
    "# Calculate employment by population bucket and NAICS sector\n",
    "employment_by_pop_naics = rural_employed_with_pop.groupby(['pop_label', 'naics_2digit'], observed=True)['PERWT'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Calculate total employment by population bucket\n",
    "total_employment_by_pop = employment_by_pop_naics.sum(axis=1)\n",
    "\n",
    "# Calculate employment percentages\n",
    "employment_percentages = employment_by_pop_naics.div(total_employment_by_pop, axis=0) * 100\n",
    "\n",
    "print(\"Employment percentages calculated\")\n",
    "\n",
    "# Calculate total population and total employed by population bucket\n",
    "population_summary = rural_puma_pop.groupby('pop_label', observed=True).agg({\n",
    "    'population': 'sum',\n",
    "    'unique_puma': 'count'\n",
    "}).rename(columns={'unique_puma': 'n_pumas'}).reset_index()\n",
    "\n",
    "employed_summary = rural_employed_with_pop.groupby('pop_label', observed=True)['PERWT'].sum().reset_index()\n",
    "employed_summary.columns = ['pop_label', 'total_employed']\n",
    "\n",
    "# Merge population and employment data\n",
    "pop_emp_summary = population_summary.merge(employed_summary, on='pop_label', how='left')\n",
    "pop_emp_summary['total_employed'] = pop_emp_summary['total_employed'].fillna(0)\n",
    "\n",
    "# Get ALL NAICS sectors (including Other)\n",
    "all_sectors = [col for col in employment_percentages.columns if col.startswith('NAICS') or col == 'Other']\n",
    "\n",
    "# Create complete summary with ALL sectors\n",
    "complete_summary = employment_percentages[all_sectors].fillna(0).round(0).astype(int)\n",
    "complete_summary = complete_summary.reset_index()\n",
    "\n",
    "# Merge with population and employment totals  \n",
    "complete_summary = complete_summary.merge(pop_emp_summary, on='pop_label', how='left')\n",
    "\n",
    "# Move key columns to front\n",
    "key_cols = ['pop_label', 'n_pumas', 'population', 'total_employed']\n",
    "sector_cols = [col for col in complete_summary.columns if col.startswith('NAICS') or col == 'Other']\n",
    "final_complete_cols = key_cols + sector_cols\n",
    "complete_summary = complete_summary[final_complete_cols]\n",
    "\n",
    "print(\"Complete employment summary created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "189e6c64-6f2b-403e-8481-b8d903dd5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total employment by population bucket\n",
    "total_employment = rural_employed_with_pop.groupby('pop_label', observed=True)['PERWT'].sum().reset_index()\n",
    "total_employment.columns = ['pop_label', 'total_employment']\n",
    "\n",
    "# Check NAICS 2-digit conservation\n",
    "naics2_employment = rural_employed_with_pop.groupby(['pop_label', 'naics_2digit'], observed=True)['PERWT'].sum().reset_index()\n",
    "naics2_totals = naics2_employment.groupby('pop_label', observed=True)['PERWT'].sum().reset_index()\n",
    "naics2_totals.columns = ['pop_label', 'naics2_total']\n",
    "\n",
    "# Create conservation check\n",
    "conservation_check = total_employment.merge(naics2_totals, on='pop_label')\n",
    "conservation_check['naics2_coverage_pct'] = (conservation_check['naics2_total'] / conservation_check['total_employment'] * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b05cd4e0-1f01-4ed2-96c1-3644abbe988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed NAICS mappings for other levels\n",
    "def get_naics_levels(ind_code):\n",
    "    if pd.isna(ind_code) or ind_code == 0:\n",
    "        return {\n",
    "            'naics_2digit_detail': 'Missing',\n",
    "            'naics_3digit_detail': 'Missing', \n",
    "            'naics_4digit_detail': 'Missing',\n",
    "            'naics_5digit_detail': 'Missing',\n",
    "            'naics_6digit_detail': 'Missing'\n",
    "        }\n",
    "    \n",
    "    ind_str = str(int(ind_code)).zfill(4)\n",
    "    \n",
    "    return {\n",
    "        'naics_2digit_detail': ind_str[:1] + 'X',\n",
    "        'naics_3digit_detail': ind_str[:2] + 'X',\n",
    "        'naics_4digit_detail': ind_str[:3] + 'X',\n",
    "        'naics_5digit_detail': ind_str[:4] + 'X',\n",
    "        'naics_6digit_detail': ind_str[:4] + 'XX'\n",
    "    }\n",
    "\n",
    "# Apply to data\n",
    "naics_levels = rural_employed_with_pop['IND'].apply(get_naics_levels)\n",
    "naics_levels_df = pd.DataFrame(naics_levels.tolist())\n",
    "\n",
    "for col in naics_levels_df.columns:\n",
    "    rural_employed_with_pop[col] = naics_levels_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79743bf8-3bc7-4118-abb6-0cf73e8e9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check conservation at all detail levels\n",
    "naics_levels_to_check = ['naics_2digit_detail', 'naics_3digit_detail', 'naics_4digit_detail', 'naics_5digit_detail', 'naics_6digit_detail']\n",
    "conservation_summary = total_employment.copy()\n",
    "\n",
    "for level in naics_levels_to_check:\n",
    "    level_employment = rural_employed_with_pop.groupby(['pop_label', level], observed=True)['PERWT'].sum().reset_index()\n",
    "    level_totals = level_employment.groupby('pop_label', observed=True)['PERWT'].sum().reset_index()\n",
    "    level_totals.columns = ['pop_label', f'{level}_total']\n",
    "    \n",
    "    conservation_summary = conservation_summary.merge(level_totals, on='pop_label', how='left')\n",
    "    conservation_summary[f'{level}_coverage_pct'] = (\n",
    "        conservation_summary[f'{level}_total'] / conservation_summary['total_employment'] * 100\n",
    "    ).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8d0bdcb-0cf0-4403-b195-1af5c7c9a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PUMA counts\n",
    "puma_counts_df = puma_counts.reset_index()\n",
    "puma_counts_df.columns = ['pop_label', 'n_pumas']\n",
    "conservation_summary = conservation_summary.merge(puma_counts_df, on='pop_label', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ce9a77d-130e-4af2-b70f-8e60f23e7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final conservation table\n",
    "display_cols = ['pop_label', 'n_pumas', 'total_employment']\n",
    "coverage_cols = [col for col in conservation_summary.columns if col.endswith('_coverage_pct')]\n",
    "display_cols.extend(coverage_cols)\n",
    "\n",
    "final_conservation_table = conservation_summary[display_cols].copy()\n",
    "final_conservation_table['total_employment'] = final_conservation_table['total_employment'].round(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87e6c901-6a0f-474f-9d21-a590cff542b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>n_pumas</th>\n",
       "      <th>population</th>\n",
       "      <th>total_employed</th>\n",
       "      <th>NAICS_11</th>\n",
       "      <th>NAICS_21</th>\n",
       "      <th>NAICS_22</th>\n",
       "      <th>NAICS_23</th>\n",
       "      <th>NAICS_31-33</th>\n",
       "      <th>NAICS_42</th>\n",
       "      <th>...</th>\n",
       "      <th>NAICS_54</th>\n",
       "      <th>NAICS_55</th>\n",
       "      <th>NAICS_56</th>\n",
       "      <th>NAICS_61</th>\n",
       "      <th>NAICS_62</th>\n",
       "      <th>NAICS_71</th>\n",
       "      <th>NAICS_72</th>\n",
       "      <th>NAICS_81</th>\n",
       "      <th>NAICS_92</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75-100K</td>\n",
       "      <td>3</td>\n",
       "      <td>299001.0</td>\n",
       "      <td>117644.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-125K</td>\n",
       "      <td>212</td>\n",
       "      <td>23947937.0</td>\n",
       "      <td>10832676.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125-150K</td>\n",
       "      <td>163</td>\n",
       "      <td>22141412.0</td>\n",
       "      <td>10003378.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150-175K</td>\n",
       "      <td>80</td>\n",
       "      <td>13052213.0</td>\n",
       "      <td>5901389.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175-200K</td>\n",
       "      <td>45</td>\n",
       "      <td>8399756.0</td>\n",
       "      <td>3752598.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200-250K</td>\n",
       "      <td>6</td>\n",
       "      <td>1283349.0</td>\n",
       "      <td>591660.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  n_pumas  population  total_employed  NAICS_11  NAICS_21  \\\n",
       "0   75-100K        3    299001.0        117644.0         8         2   \n",
       "1  100-125K      212  23947937.0      10832676.0         3         1   \n",
       "2  125-150K      163  22141412.0      10003378.0         3         1   \n",
       "3  150-175K       80  13052213.0       5901389.0         3         1   \n",
       "4  175-200K       45   8399756.0       3752598.0         2         1   \n",
       "5  200-250K        6   1283349.0        591660.0         2         0   \n",
       "\n",
       "   NAICS_22  NAICS_23  NAICS_31-33  NAICS_42  ...  NAICS_54  NAICS_55  \\\n",
       "0         1         9            5         1  ...         3         1   \n",
       "1         1         8           13         1  ...         3         1   \n",
       "2         1         8           13         1  ...         3         1   \n",
       "3         1         8           12         1  ...         3         1   \n",
       "4         1         8           12         1  ...         3         1   \n",
       "5         1         8            8         1  ...         4         2   \n",
       "\n",
       "   NAICS_56  NAICS_61  NAICS_62  NAICS_71  NAICS_72  NAICS_81  NAICS_92  Other  \n",
       "0         3        10        12         2         1         1         8     12  \n",
       "1         4         8        12         2         1         1         5     12  \n",
       "2         5         8        12         2         1         1         5     12  \n",
       "3         5         8        12         2         1         1         5     13  \n",
       "4         5         9        12         2         1         1         5     12  \n",
       "5         5         7        12         1         1         1         5     16  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d17ad18-7676-4946-8838-05b2c683aae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>n_pumas</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>naics_2digit_detail_coverage_pct</th>\n",
       "      <th>naics_3digit_detail_coverage_pct</th>\n",
       "      <th>naics_4digit_detail_coverage_pct</th>\n",
       "      <th>naics_5digit_detail_coverage_pct</th>\n",
       "      <th>naics_6digit_detail_coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75-100K</td>\n",
       "      <td>3</td>\n",
       "      <td>117644</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-125K</td>\n",
       "      <td>212</td>\n",
       "      <td>10832676</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125-150K</td>\n",
       "      <td>163</td>\n",
       "      <td>10003378</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150-175K</td>\n",
       "      <td>80</td>\n",
       "      <td>5901389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175-200K</td>\n",
       "      <td>45</td>\n",
       "      <td>3752598</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200-250K</td>\n",
       "      <td>6</td>\n",
       "      <td>591660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  n_pumas  total_employment  naics_2digit_detail_coverage_pct  \\\n",
       "0   75-100K        3            117644                             100.0   \n",
       "1  100-125K      212          10832676                             100.0   \n",
       "2  125-150K      163          10003378                             100.0   \n",
       "3  150-175K       80           5901389                             100.0   \n",
       "4  175-200K       45           3752598                             100.0   \n",
       "5  200-250K        6            591660                             100.0   \n",
       "\n",
       "   naics_3digit_detail_coverage_pct  naics_4digit_detail_coverage_pct  \\\n",
       "0                             100.0                             100.0   \n",
       "1                             100.0                             100.0   \n",
       "2                             100.0                             100.0   \n",
       "3                             100.0                             100.0   \n",
       "4                             100.0                             100.0   \n",
       "5                             100.0                             100.0   \n",
       "\n",
       "   naics_5digit_detail_coverage_pct  naics_6digit_detail_coverage_pct  \n",
       "0                             100.0                             100.0  \n",
       "1                             100.0                             100.0  \n",
       "2                             100.0                             100.0  \n",
       "3                             100.0                             100.0  \n",
       "4                             100.0                             100.0  \n",
       "5                             100.0                             100.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_conservation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b3758d4-8fe6-479f-92bd-98134deb4998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total employment by population bucket...\n",
      "  pop_label  total_employment\n",
      "0     0-75K               0.0\n",
      "1   75-100K          117644.0\n",
      "2  100-125K        10832676.0\n",
      "3  125-150K        10003378.0\n",
      "4  150-175K         5901389.0\n",
      "5  175-200K         3752598.0\n",
      "6  200-250K          591660.0\n",
      "7     250K+               0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10619/63071298.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  total_employment = rural_employed_with_pop.groupby('pop_label')['PERWT'].sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Calculate total employment by population bucket\n",
    "print(\"Total employment by population bucket...\")\n",
    "total_employment = rural_employed_with_pop.groupby('pop_label')['PERWT'].sum().reset_index()\n",
    "total_employment.columns = ['pop_label', 'total_employment']\n",
    "print(total_employment)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce7be1-900c-4964-9605-53ecc833719b",
   "metadata": {},
   "source": [
    "### Version 2 PUMAs rural and urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19df3f0b-8690-4f89-8a84-aea956e5a719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ALL PUMAs analysis (rural + non-rural)...\n",
      "Total PUMAs data: 15,912,393 records\n",
      "Total population: 332,387,543\n",
      "  Metropolitan: 263,263,875 (79.2%)\n",
      "  Non-metro/Rural: 69,123,668 (20.8%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create All PUMAs (Rural + Non-Rural)\n",
    "print(\"Creating ALL PUMAs analysis (rural + non-rural)...\")\n",
    "\n",
    "# All PUMAs with PUMA identification\n",
    "all_puma_df = df[df['PUMA'] != 0].copy()\n",
    "\n",
    "# Add metro status classification\n",
    "all_puma_df['metro_status'] = all_puma_df['MET2013'].apply(\n",
    "    lambda x: 'Non-metro/Rural' if x == 0 else 'Metropolitan'\n",
    ")\n",
    "\n",
    "print(f\"Total PUMAs data: {len(all_puma_df):,} records\")\n",
    "print(f\"Total population: {all_puma_df['PERWT'].sum():,.0f}\")\n",
    "\n",
    "# Check metro status distribution\n",
    "metro_distribution = all_puma_df.groupby('metro_status')['PERWT'].sum()\n",
    "for status, pop in metro_distribution.items():\n",
    "    pct = pop / metro_distribution.sum() * 100\n",
    "    print(f\"  {status}: {pop:,.0f} ({pct:.1f}%)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7a3387e-b8f9-4a70-ad8c-d5fc1add0735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUMA population analysis for ALL areas...\n",
      "Total PUMAs: 2462\n",
      "Rural PUMAs: 509\n",
      "Metro PUMAs: 1953\n",
      "\n",
      "PUMAs by population size and metro status:\n",
      "metro_status  Metropolitan  Non-metro/Rural\n",
      "pop_label                                  \n",
      "0-75K                    0                0\n",
      "75-100K                 31                3\n",
      "100-125K               846              212\n",
      "125-150K               565              163\n",
      "150-175K               328               80\n",
      "175-200K               154               45\n",
      "200-250K                28                6\n",
      "250-300K                 1                0\n",
      "300-400K                 0                0\n",
      "400-500K                 0                0\n",
      "500K+                    0                0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10619/1995347115.py:34: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  puma_counts_by_metro = all_puma_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# PUMA Population Analysis for ALL PUMAs\n",
    "print(\"PUMA population analysis for ALL areas...\")\n",
    "\n",
    "# Create unique PUMA identifier\n",
    "all_puma_df['unique_puma'] = all_puma_df['STATEFIP'].astype(str) + '_' + all_puma_df['PUMA'].astype(str)\n",
    "\n",
    "# Calculate PUMA populations by metro status\n",
    "all_puma_pop = all_puma_df.groupby('unique_puma').agg({\n",
    "    'PERWT': 'sum',\n",
    "    'STATEFIP': 'first',\n",
    "    'PUMA': 'first',\n",
    "    'MET2013': 'first'\n",
    "}).reset_index()\n",
    "all_puma_pop.columns = ['unique_puma', 'population', 'STATEFIP', 'PUMA', 'MET2013']\n",
    "\n",
    "# Add metro status\n",
    "all_puma_pop['metro_status'] = all_puma_pop['MET2013'].apply(\n",
    "    lambda x: 'Non-metro/Rural' if x == 0 else 'Metropolitan'\n",
    ")\n",
    "\n",
    "# Create population bins\n",
    "pop_bins = [0, 75000, 100000, 125000, 150000, 175000, 200000, 250000, 300000, 400000, 500000, np.inf]\n",
    "pop_labels = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', '175-200K', \n",
    "              '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "\n",
    "all_puma_pop['pop_label'] = pd.cut(all_puma_pop['population'], bins=pop_bins, labels=pop_labels, right=False)\n",
    "\n",
    "print(f\"Total PUMAs: {len(all_puma_pop)}\")\n",
    "print(f\"Rural PUMAs: {(all_puma_pop['metro_status'] == 'Non-metro/Rural').sum()}\")\n",
    "print(f\"Metro PUMAs: {(all_puma_pop['metro_status'] == 'Metropolitan').sum()}\")\n",
    "print()\n",
    "\n",
    "# PUMAs by population size and metro status\n",
    "puma_counts_by_metro = all_puma_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
    "print(\"PUMAs by population size and metro status:\")\n",
    "print(puma_counts_by_metro)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15f7ff0f-773b-4a95-9f74-22aeddc38b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment analysis for ALL PUMAs...\n",
      "Total employed persons: 160,913,396\n",
      "Employment by metro status:\n",
      "  Metropolitan: 129,714,051 (80.6%)\n",
      "  Non-metro/Rural: 31,199,345 (19.4%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Employment Analysis for ALL PUMAs\n",
    "print(\"Employment analysis for ALL PUMAs...\")\n",
    "\n",
    "# Get employed persons from all PUMAs\n",
    "all_employed = all_puma_df[all_puma_df['EMPSTAT'] == 1].copy()\n",
    "print(f\"Total employed persons: {all_employed['PERWT'].sum():,.0f}\")\n",
    "\n",
    "# Apply NAICS mapping (same function as before)\n",
    "def map_to_naics_2digit(ind_code):\n",
    "    if pd.isna(ind_code) or ind_code == 0:\n",
    "        return 'Other'\n",
    "    \n",
    "    ind_str = str(int(ind_code)).zfill(4)\n",
    "    \n",
    "    if ind_str.startswith(('017', '018', '019', '027', '028', '029')):\n",
    "        return 'NAICS_11'\n",
    "    elif ind_str.startswith(('067', '068', '069', '077', '078', '079')):\n",
    "        return 'NAICS_23'\n",
    "    elif ind_str.startswith(('107', '108', '109', '117', '118', '119', '127', '128', '129',\n",
    "                             '137', '138', '139', '147', '148', '149', '157', '158', '159',\n",
    "                             '167', '168', '169', '177', '178', '179', '187', '188', '189',\n",
    "                             '197', '198', '199', '207', '208', '209', '217', '218', '219',\n",
    "                             '227', '228', '229', '237', '238', '239', '247', '248', '249',\n",
    "                             '257', '258', '259', '267', '268', '269', '277', '278', '279',\n",
    "                             '287', '288', '289', '297', '298', '299', '307', '308', '309',\n",
    "                             '317', '318', '319', '327', '328', '329', '337', '338', '339',\n",
    "                             '347', '348', '349', '357', '358', '359', '367', '368', '369',\n",
    "                             '377', '378', '379', '387', '388', '389', '397', '398', '399')):\n",
    "        return 'NAICS_31-33'\n",
    "    elif ind_str.startswith(('447', '448', '449', '457', '458', '459', '467', '468', '469',\n",
    "                             '477', '478', '479', '487', '488', '489', '497', '498', '499',\n",
    "                             '507', '508', '509', '517', '518', '519', '527', '528', '529',\n",
    "                             '537', '538', '539', '547', '548', '549', '557', '558', '559',\n",
    "                             '567', '568', '569', '577', '578', '579', '587', '588', '589',\n",
    "                             '597', '598', '599')):\n",
    "        return 'NAICS_44-45'\n",
    "    elif ind_str.startswith(('827', '828', '829', '837', '838', '839', '847', '848', '849',\n",
    "                             '857', '858', '859', '867', '868', '869')):\n",
    "\n",
    "        return 'NAICS_62'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "all_employed['naics_2digit'] = all_employed['IND'].apply(map_to_naics_2digit)\n",
    "all_employed['unique_puma'] = all_employed['STATEFIP'].astype(str) + '_' + all_employed['PUMA'].astype(str)\n",
    "\n",
    "# Merge with PUMA population data\n",
    "all_employed_clean = all_employed.drop('metro_status', axis=1)  # Remove from left dataframe\n",
    "all_employed_with_pop = all_employed_clean.merge(\n",
    "    all_puma_pop[['unique_puma', 'pop_label', 'metro_status']], \n",
    "    on='unique_puma', how='left'\n",
    ")\n",
    "\n",
    "print(\"Employment by metro status:\")\n",
    "emp_by_metro = all_employed_with_pop.groupby('metro_status')['PERWT'].sum()\n",
    "for status, emp in emp_by_metro.items():\n",
    "    pct = emp / emp_by_metro.sum() * 100\n",
    "    print(f\"  {status}: {emp:,.0f} ({pct:.1f}%)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb865f-2c9e-4abe-9731-3f2f239c513e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "021fbc96-1759-4a67-be4f-191c117a6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate coverage analysis by metro status\n",
    "def create_coverage_by_metro_status(employed_data, puma_data, metro_type):\n",
    "    \"\"\"Create coverage analysis for specific metro status\"\"\"\n",
    "    \n",
    "    # Filter data\n",
    "    metro_employed = employed_data[employed_data['metro_status'] == metro_type]\n",
    "    metro_pumas = puma_data[puma_data['metro_status'] == metro_type]\n",
    "    \n",
    "    if len(metro_employed) == 0:\n",
    "        print(f\"No data for {metro_type}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    print(f\"Analyzing {metro_type}: {len(metro_employed):,} employment records\")\n",
    "    \n",
    "    # Apply detailed NAICS mapping if not already done\n",
    "    if 'naics_2digit' not in metro_employed.columns:\n",
    "        def create_naics_detail_levels(ind_code):\n",
    "            if pd.isna(ind_code) or ind_code == 0:\n",
    "                return {\n",
    "                    'naics_2digit': 'Unclassified',\n",
    "                    'naics_3digit': 'Unclassified',\n",
    "                    'naics_4digit': 'Unclassified', \n",
    "                    'naics_5digit': 'Unclassified',\n",
    "                    'naics_6digit': 'Unclassified'\n",
    "                }\n",
    "            \n",
    "            ind_str = str(int(ind_code)).zfill(4)\n",
    "            return {\n",
    "                'naics_2digit': ind_str[0] + '0',\n",
    "                'naics_3digit': ind_str[:2] + '0',\n",
    "                'naics_4digit': ind_str[:3] + '0',\n",
    "                'naics_5digit': ind_str,\n",
    "                'naics_6digit': ind_str + str(ind_code % 10)\n",
    "            }\n",
    "        \n",
    "        naics_detail_mapping = metro_employed['IND'].apply(create_naics_detail_levels)\n",
    "        naics_detail_df = pd.DataFrame(naics_detail_mapping.tolist())\n",
    "        \n",
    "        for col in naics_detail_df.columns:\n",
    "            metro_employed[col] = naics_detail_df[col]\n",
    "    \n",
    "    # Calculate coverage for each NAICS level\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    coverage_results = {}\n",
    "    \n",
    "    for level in naics_levels:\n",
    "        coverage_by_pop = []\n",
    "        \n",
    "        # Only analyze population buckets that actually exist\n",
    "        existing_pop_buckets = metro_employed['pop_label'].dropna().unique()\n",
    "        \n",
    "        for pop_bucket in existing_pop_buckets:\n",
    "            bucket_data = metro_employed[metro_employed['pop_label'] == pop_bucket]\n",
    "            \n",
    "            total_employment = bucket_data['PERWT'].sum()\n",
    "            classifiable_employment = bucket_data[bucket_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "            coverage_pct = (classifiable_employment / total_employment * 100) if total_employment > 0 else 0\n",
    "            \n",
    "            coverage_by_pop.append({\n",
    "                'pop_label': pop_bucket,\n",
    "                'level': level,\n",
    "                'coverage_percent': coverage_pct,\n",
    "                'metro_status': metro_type\n",
    "            })\n",
    "        \n",
    "        coverage_results[level] = pd.DataFrame(coverage_by_pop)\n",
    "    \n",
    "    # Combine coverage results\n",
    "    all_coverage = pd.concat(coverage_results.values(), ignore_index=True)\n",
    "    \n",
    "    # Pivot to get coverage by level and population bucket\n",
    "    coverage_pivot = all_coverage.pivot(index='pop_label', columns='level', values='coverage_percent').round(1)\n",
    "    \n",
    "    # Add PUMA counts (keep all population buckets, show 0 for empty ones)\n",
    "    puma_counts = metro_pumas['pop_label'].value_counts().sort_index()\n",
    "    \n",
    "    # Create complete population bucket list (including empty ones)\n",
    "    all_possible_buckets = pd.Index(['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+'])\n",
    "    puma_counts = puma_counts.reindex(all_possible_buckets, fill_value=0)\n",
    "    \n",
    "    puma_counts_df = puma_counts.reset_index()\n",
    "    puma_counts_df.columns = ['pop_label', 'n_pumas']\n",
    "    \n",
    "    # Merge and fill coverage values\n",
    "    coverage_pivot = coverage_pivot.reset_index().merge(puma_counts_df, on='pop_label', how='right')\n",
    "    \n",
    "    # Fill NaN coverage values with 0 for population buckets with no PUMAs\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    for level in naics_levels:\n",
    "        coverage_pivot[level] = coverage_pivot[level].fillna(0)\n",
    "    \n",
    "    # Reorder columns and sort by population bucket\n",
    "    cols = ['pop_label', 'n_pumas'] + naics_levels\n",
    "    coverage_pivot = coverage_pivot[cols]\n",
    "    \n",
    "    # Sort by population bucket order\n",
    "    bucket_order = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "    coverage_pivot['pop_label'] = pd.Categorical(coverage_pivot['pop_label'], categories=bucket_order, ordered=True)\n",
    "    coverage_pivot = coverage_pivot.sort_values('pop_label').reset_index(drop=True)\n",
    "    \n",
    "    return coverage_pivot, puma_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be1d20eb-0023-423b-97fa-4da7528f2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating coverage analysis for rural areas...\n",
      "Analyzing Non-metro/Rural: 1,766,302 employment records\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'naics_3digit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'naics_3digit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create coverage for Rural, Urban, and Combined\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating coverage analysis for rural areas...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rural_coverage, rural_puma_counts \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_coverage_by_metro_status\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_employed_with_pop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_puma_pop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNon-metro/Rural\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating coverage analysis for urban areas...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m urban_coverage, urban_puma_counts \u001b[38;5;241m=\u001b[39m create_coverage_by_metro_status(\n\u001b[1;32m      9\u001b[0m     all_employed_with_pop, all_puma_pop, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetropolitan\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
      "Cell \u001b[0;32mIn[53], line 56\u001b[0m, in \u001b[0;36mcreate_coverage_by_metro_status\u001b[0;34m(employed_data, puma_data, metro_type)\u001b[0m\n\u001b[1;32m     53\u001b[0m bucket_data \u001b[38;5;241m=\u001b[39m metro_employed[metro_employed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m pop_bucket]\n\u001b[1;32m     55\u001b[0m total_employment \u001b[38;5;241m=\u001b[39m bucket_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERWT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 56\u001b[0m classifiable_employment \u001b[38;5;241m=\u001b[39m bucket_data[\u001b[43mbucket_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnclassified\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERWT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     57\u001b[0m coverage_pct \u001b[38;5;241m=\u001b[39m (classifiable_employment \u001b[38;5;241m/\u001b[39m total_employment \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m total_employment \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     59\u001b[0m coverage_by_pop\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_label\u001b[39m\u001b[38;5;124m'\u001b[39m: pop_bucket,\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m: level,\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoverage_percent\u001b[39m\u001b[38;5;124m'\u001b[39m: coverage_pct,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetro_status\u001b[39m\u001b[38;5;124m'\u001b[39m: metro_type\n\u001b[1;32m     64\u001b[0m })\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'naics_3digit'"
     ]
    }
   ],
   "source": [
    "# Create coverage for Rural, Urban, and Combined\n",
    "print(\"Creating coverage analysis for rural areas...\")\n",
    "rural_coverage, rural_puma_counts = create_coverage_by_metro_status(\n",
    "    all_employed_with_pop, all_puma_pop, 'Non-metro/Rural'\n",
    ")\n",
    "\n",
    "print(\"Creating coverage analysis for urban areas...\")\n",
    "urban_coverage, urban_puma_counts = create_coverage_by_metro_status(\n",
    "    all_employed_with_pop, all_puma_pop, 'Metropolitan'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c98113-7598-4482-8793-4a2b91b1d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# STEP 2: Create coverage for Rural, Urban, and Combined\n",
    "print(\"Creating coverage analysis for rural areas...\")\n",
    "rural_coverage, rural_puma_counts = create_coverage_by_metro_status(\n",
    "    all_employed_with_pop, all_puma_pop, 'Non-metro/Rural'\n",
    ")\n",
    "\n",
    "print(\"Creating coverage analysis for urban areas...\")\n",
    "urban_coverage, urban_puma_counts = create_coverage_by_metro_status(\n",
    "    all_employed_with_pop, all_puma_pop, 'Metropolitan'\n",
    ")\n",
    "\n",
    "# STEP 3: Create combined total with rural/urban breakdown\n",
    "print(\"Creating combined totals with rural/urban breakdown...\")\n",
    "\n",
    "def create_combined_coverage_with_split():\n",
    "    \"\"\"Create coverage analysis showing rural/urban split within each population bucket\"\"\"\n",
    "    \n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    \n",
    "    # Create comprehensive breakdown\n",
    "    coverage_breakdown = []\n",
    "    \n",
    "    all_possible_buckets = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                           '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "    \n",
    "    for pop_bucket in all_possible_buckets:\n",
    "        # Get data for this population bucket\n",
    "        bucket_data = all_employed_with_pop[all_employed_with_pop['pop_label'] == pop_bucket]\n",
    "        \n",
    "        if len(bucket_data) == 0:\n",
    "            # No data for this bucket - add zeros\n",
    "            coverage_breakdown.append({\n",
    "                'pop_label': pop_bucket,\n",
    "                'total_pumas': 0,\n",
    "                'rural_pumas': 0,\n",
    "                'urban_pumas': 0,\n",
    "                **{f'total_{level}': 0.0 for level in naics_levels},\n",
    "                **{f'rural_{level}': 0.0 for level in naics_levels},\n",
    "                **{f'urban_{level}': 0.0 for level in naics_levels}\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Count PUMAs by metro status\n",
    "        puma_counts_by_metro = all_puma_pop[all_puma_pop['pop_label'] == pop_bucket]['metro_status'].value_counts()\n",
    "        total_pumas = puma_counts_by_metro.sum()\n",
    "        rural_pumas = puma_counts_by_metro.get('Non-metro/Rural', 0)\n",
    "        urban_pumas = puma_counts_by_metro.get('Metropolitan', 0)\n",
    "        \n",
    "        # Calculate coverage for each group\n",
    "        row_data = {\n",
    "            'pop_label': pop_bucket,\n",
    "            'total_pumas': total_pumas,\n",
    "            'rural_pumas': rural_pumas,\n",
    "            'urban_pumas': urban_pumas\n",
    "        }\n",
    "        \n",
    "        # Total coverage (all areas)\n",
    "        for level in naics_levels:\n",
    "            total_employment = bucket_data['PERWT'].sum()\n",
    "            classifiable_employment = bucket_data[bucket_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "            coverage_pct = (classifiable_employment / total_employment * 100) if total_employment > 0 else 0\n",
    "            row_data[f'total_{level}'] = round(coverage_pct, 1)\n",
    "        \n",
    "        # Rural coverage\n",
    "        rural_data = bucket_data[bucket_data['metro_status'] == 'Non-metro/Rural']\n",
    "        for level in naics_levels:\n",
    "            if len(rural_data) > 0:\n",
    "                rural_employment = rural_data['PERWT'].sum()\n",
    "                rural_classifiable = rural_data[rural_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "                rural_coverage = (rural_classifiable / rural_employment * 100) if rural_employment > 0 else 0\n",
    "                row_data[f'rural_{level}'] = round(rural_coverage, 1)\n",
    "            else:\n",
    "                row_data[f'rural_{level}'] = 0.0\n",
    "        \n",
    "        # Urban coverage\n",
    "        urban_data = bucket_data[bucket_data['metro_status'] == 'Metropolitan']\n",
    "        for level in naics_levels:\n",
    "            if len(urban_data) > 0:\n",
    "                urban_employment = urban_data['PERWT'].sum()\n",
    "                urban_classifiable = urban_data[urban_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "                urban_coverage = (urban_classifiable / urban_employment * 100) if urban_employment > 0 else 0\n",
    "                row_data[f'urban_{level}'] = round(urban_coverage, 1)\n",
    "            else:\n",
    "                row_data[f'urban_{level}'] = 0.0\n",
    "        \n",
    "        coverage_breakdown.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    combined_detailed = pd.DataFrame(coverage_breakdown)\n",
    "    \n",
    "    # Sort by population bucket order\n",
    "    bucket_order = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "    combined_detailed['pop_label'] = pd.Categorical(combined_detailed['pop_label'], categories=bucket_order, ordered=True)\n",
    "    combined_detailed = combined_detailed.sort_values('pop_label').reset_index(drop=True)\n",
    "    \n",
    "    return combined_detailed\n",
    "\n",
    "combined_detailed_coverage = create_combined_coverage_with_split()\n",
    "\n",
    "# STEP 4: Display Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RURAL COVERAGE BY NAICS DETAIL LEVEL\")\n",
    "print(\"=\"*80)\n",
    "if len(rural_coverage) > 0:\n",
    "    print(rural_coverage.to_string(index=False))\n",
    "else:\n",
    "    print(\"No rural data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"URBAN COVERAGE BY NAICS DETAIL LEVEL\") \n",
    "print(\"=\"*80)\n",
    "if len(urban_coverage) > 0:\n",
    "    print(urban_coverage.to_string(index=False))\n",
    "else:\n",
    "    print(\"No urban data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINED DETAILED COVERAGE (WITH RURAL/URBAN BREAKDOWN)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Shows total, rural, and urban coverage within each population bucket\")\n",
    "\n",
    "# Display key columns for readability\n",
    "display_cols = ['pop_label', 'total_pumas', 'rural_pumas', 'urban_pumas', \n",
    "               'total_naics_2digit', 'rural_naics_2digit', 'urban_naics_2digit',\n",
    "               'total_naics_5digit', 'rural_naics_5digit', 'urban_naics_5digit']\n",
    "\n",
    "if all(col in combined_detailed_coverage.columns for col in display_cols):\n",
    "    print(\"Coverage Summary (2-digit and 5-digit NAICS):\")\n",
    "    print(combined_detailed_coverage[display_cols].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nFull detailed breakdown with all NAICS levels available in DataFrame\")\n",
    "else:\n",
    "    # Fallback to showing available columns\n",
    "    print(\"Available columns:\", combined_detailed_coverage.columns.tolist())\n",
    "    print(combined_detailed_coverage.head())\n",
    "\n",
    "# STEP 5: Summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RURAL vs URBAN COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(rural_coverage) > 0 and len(urban_coverage) > 0:\n",
    "    # Calculate averages\n",
    "    rural_avg = rural_coverage[['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']].mean()\n",
    "    urban_avg = urban_coverage[['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']].mean()\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'NAICS_Level': ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit'],\n",
    "        'Rural_Avg': rural_avg.round(1).values,\n",
    "        'Urban_Avg': urban_avg.round(1).values\n",
    "    })\n",
    "    comparison_df['Difference'] = (comparison_df['Urban_Avg'] - comparison_df['Rural_Avg']).round(1)\n",
    "    \n",
    "    print(\"Average coverage percentages:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Summary stats\n",
    "    rural_pumas = rural_coverage['n_pumas'].sum()\n",
    "    urban_pumas = urban_coverage['n_pumas'].sum()\n",
    "    total_pumas = combined_coverage['n_pumas'].sum()\n",
    "    \n",
    "    print(f\"\\nPUMA Distribution:\")\n",
    "    print(f\"  Rural PUMAs: {rural_pumas}\")\n",
    "    print(f\"  Urban PUMAs: {urban_pumas}\")\n",
    "    print(f\"  Total PUMAs: {total_pumas}\")\n",
    "\n",
    "# Save results\n",
    "rural_coverage.to_csv(\"rural_naics_coverage.csv\", index=False)\n",
    "urban_coverage.to_csv(\"urban_naics_coverage.csv\", index=False)\n",
    "combined_detailed_coverage.to_csv(\"detailed_rural_urban_coverage.csv\", index=False)\n",
    "\n",
    "print(f\"\\nResults saved:\")\n",
    "print(f\"  - rural_naics_coverage.csv (rural only)\")\n",
    "print(f\"  - urban_naics_coverage.csv (urban only)\") \n",
    "print(f\"  - detailed_rural_urban_coverage.csv (with rural/urban breakdown)\")\n",
    "\n",
    "print(f\"\\nFinal DataFrames:\")\n",
    "print(f\"  - rural_coverage: Rural areas only\")\n",
    "print(f\"  - urban_coverage: Urban areas only\")\n",
    "print(f\"  - combined_detailed_coverage: Shows total + rural/urban splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f253eba-246b-4030-9eda-0f2889b4b466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501df62-92e2-40db-a58d-7adfb869a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac20475c-806d-4b0c-b1d3-144d0f76442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create separate coverage analysis by metro status\n",
    "def create_coverage_by_metro_status(employed_data, puma_data, metro_type):\n",
    "    \"\"\"Create coverage analysis for specific metro status\"\"\"\n",
    "    \n",
    "    # Filter data\n",
    "    metro_employed = employed_data[employed_data['metro_status'] == metro_type]\n",
    "    metro_pumas = puma_data[puma_data['metro_status'] == metro_type]\n",
    "    \n",
    "    if len(metro_employed) == 0:\n",
    "        print(f\"No data for {metro_type}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    print(f\"Analyzing {metro_type}: {len(metro_employed):,} employment records\")\n",
    "    \n",
    "    # Apply detailed NAICS mapping if not already done\n",
    "    if 'naics_2digit' not in metro_employed.columns:\n",
    "        def create_naics_detail_levels(ind_code):\n",
    "            if pd.isna(ind_code) or ind_code == 0:\n",
    "                return {\n",
    "                    'naics_2digit': 'Unclassified',\n",
    "                    'naics_3digit': 'Unclassified',\n",
    "                    'naics_4digit': 'Unclassified', \n",
    "                    'naics_5digit': 'Unclassified',\n",
    "                    'naics_6digit': 'Unclassified'\n",
    "                }\n",
    "            \n",
    "            ind_str = str(int(ind_code)).zfill(4)\n",
    "            return {\n",
    "                'naics_2digit': ind_str[0] + '0',\n",
    "                'naics_3digit': ind_str[:2] + '0',\n",
    "                'naics_4digit': ind_str[:3] + '0',\n",
    "                'naics_5digit': ind_str,\n",
    "                'naics_6digit': ind_str + str(ind_code % 10)\n",
    "            }\n",
    "  \n",
    "        naics_detail_mapping = metro_employed['IND'].apply(create_naics_detail_levels)\n",
    "        naics_detail_df = pd.DataFrame(naics_detail_mapping.tolist())\n",
    "        \n",
    "        for col in naics_detail_df.columns:\n",
    "            metro_employed[col] = naics_detail_df[col]\n",
    "    \n",
    "    # Calculate coverage for each NAICS level\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    coverage_results = {}\n",
    "    \n",
    "    for level in naics_levels:\n",
    "        coverage_by_pop = []\n",
    "        \n",
    "        # Only analyze population buckets that actually exist\n",
    "        existing_pop_buckets = metro_employed['pop_label'].dropna().unique()\n",
    "        \n",
    "        for pop_bucket in existing_pop_buckets:\n",
    "            bucket_data = metro_employed[metro_employed['pop_label'] == pop_bucket]\n",
    "            \n",
    "            total_employment = bucket_data['PERWT'].sum()\n",
    "            classifiable_employment = bucket_data[bucket_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "            coverage_pct = (classifiable_employment / total_employment * 100) if total_employment > 0 else 0\n",
    "            \n",
    "            coverage_by_pop.append({\n",
    "                'pop_label': pop_bucket,\n",
    "                'level': level,\n",
    "                'coverage_percent': coverage_pct,\n",
    "                'metro_status': metro_type\n",
    "            })\n",
    "        \n",
    "        coverage_results[level] = pd.DataFrame(coverage_by_pop)\n",
    "    \n",
    "    # Combine coverage results\n",
    "    all_coverage = pd.concat(coverage_results.values(), ignore_index=True)\n",
    "    \n",
    "    # Pivot to get coverage by level and population bucket\n",
    "    coverage_pivot = all_coverage.pivot(index='pop_label', columns='level', values='coverage_percent').round(1)\n",
    "    \n",
    "    # Add PUMA counts (keep all population buckets, show 0 for empty ones)\n",
    "    puma_counts = metro_pumas['pop_label'].value_counts().sort_index()\n",
    "    \n",
    "    # Create complete population bucket list (including empty ones)\n",
    "    all_possible_buckets = pd.Index(['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+'])\n",
    "    puma_counts = puma_counts.reindex(all_possible_buckets, fill_value=0)\n",
    "    \n",
    "    puma_counts_df = puma_counts.reset_index()\n",
    "    puma_counts_df.columns = ['pop_label', 'n_pumas']\n",
    "    \n",
    "    # Merge and fill coverage values\n",
    "    coverage_pivot = coverage_pivot.reset_index().merge(puma_counts_df, on='pop_label', how='right')\n",
    "    \n",
    "    # Fill NaN coverage values with 0 for population buckets with no PUMAs\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    for level in naics_levels:\n",
    "        coverage_pivot[level] = coverage_pivot[level].fillna(0)\n",
    "    \n",
    "    # Reorder columns and sort by population bucket\n",
    "    cols = ['pop_label', 'n_pumas'] + naics_levels\n",
    "    coverage_pivot = coverage_pivot[cols]\n",
    "    \n",
    "    # Sort by population bucket order\n",
    "    bucket_order = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "    coverage_pivot['pop_label'] = pd.Categorical(coverage_pivot['pop_label'], categories=bucket_order, ordered=True)\n",
    "    coverage_pivot = coverage_pivot.sort_values('pop_label').reset_index(drop=True)\n",
    "    \n",
    "    return coverage_pivot, puma_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d65b9c29-2144-4d71-a878-6ef3b85f6a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating coverage analysis for rural areas...\n",
      "Analyzing Non-metro/Rural: 1,766,302 employment records\n",
      "Creating coverage analysis for urban areas...\n",
      "Analyzing Metropolitan: 5,615,175 employment records\n"
     ]
    }
   ],
   "source": [
    "# Create coverage for Rural, Urban, and Combined\n",
    "print(\"Creating coverage analysis for rural areas...\")\n",
    "rural_coverage, rural_puma_counts = create_coverage_by_metro_status(\n",
    "    all_employed_with_pop, all_puma_pop, 'Non-metro/Rural'\n",
    ")\n",
    "\n",
    "print(\"Creating coverage analysis for urban areas...\")\n",
    "urban_coverage, urban_puma_counts = create_coverage_by_metro_status(\n",
    "    all_employed_with_pop, all_puma_pop, 'Metropolitan'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "264ccf4b-a3e2-4352-8275-a64b782aaf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined totals...\n"
     ]
    }
   ],
   "source": [
    "# Create combined total\n",
    "print(\"Creating combined totals...\")\n",
    "\n",
    "# Combine PUMA counts\n",
    "all_puma_counts = all_puma_pop['pop_label'].value_counts().sort_index()\n",
    "\n",
    "# Create combined coverage analysis\n",
    "def create_combined_coverage():\n",
    "    \"\"\"Create coverage analysis for all areas combined\"\"\"\n",
    "    \n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    coverage_results = {}\n",
    "    \n",
    "    for level in naics_levels:\n",
    "        coverage_by_pop = []\n",
    "        \n",
    "        existing_pop_buckets = all_employed_with_pop['pop_label'].dropna().unique()\n",
    "        \n",
    "        for pop_bucket in existing_pop_buckets:\n",
    "            bucket_data = all_employed_with_pop[all_employed_with_pop['pop_label'] == pop_bucket]\n",
    "            \n",
    "            total_employment = bucket_data['PERWT'].sum()\n",
    "            classifiable_employment = bucket_data[bucket_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "            coverage_pct = (classifiable_employment / total_employment * 100) if total_employment > 0 else 0\n",
    "            \n",
    "            coverage_by_pop.append({\n",
    "                'pop_label': pop_bucket,\n",
    "                'level': level,\n",
    "                'coverage_percent': coverage_pct\n",
    "            })\n",
    "        \n",
    "        coverage_results[level] = pd.DataFrame(coverage_by_pop)\n",
    "    \n",
    "    # Combine and pivot\n",
    "    all_coverage = pd.concat(coverage_results.values(), ignore_index=True)\n",
    "    coverage_pivot = all_coverage.pivot(index='pop_label', columns='level', values='coverage_percent').round(1)\n",
    "    \n",
    "    # Add PUMA counts (keep all population buckets, show 0 for empty ones)\n",
    "    all_possible_buckets = pd.Index(['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+'])\n",
    "    puma_counts_df = all_puma_counts.reindex(all_possible_buckets, fill_value=0).reset_index()\n",
    "    puma_counts_df.columns = ['pop_label', 'n_pumas'] \n",
    "    \n",
    "    coverage_pivot = coverage_pivot.reset_index().merge(puma_counts_df, on='pop_label', how='right')\n",
    "    \n",
    "    # Fill NaN coverage values with 0 for population buckets with no PUMAs\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    for level in naics_levels:\n",
    "        coverage_pivot[level] = coverage_pivot[level].fillna(0)\n",
    "    \n",
    "    # Reorder and sort\n",
    "    cols = ['pop_label', 'n_pumas'] + naics_levels\n",
    "    coverage_pivot = coverage_pivot[cols]\n",
    "    \n",
    "    bucket_order = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', \n",
    "                   '175-200K', '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "    coverage_pivot['pop_label'] = pd.Categorical(coverage_pivot['pop_label'], categories=bucket_order, ordered=True)\n",
    "    coverage_pivot = coverage_pivot.sort_values('pop_label').reset_index(drop=True)\n",
    "    \n",
    "    return coverage_pivot\n",
    "\n",
    "combined_coverage = create_combined_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657b20a-8d40-4808-b186-54ace9c72f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RURAL COVERAGE BY NAICS DETAIL LEVEL\")\n",
    "print(\"=\"*80)\n",
    "if len(rural_coverage) > 0:\n",
    "    print(rural_coverage.to_string(index=False))\n",
    "else:\n",
    "    print(\"No rural data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"URBAN COVERAGE BY NAICS DETAIL LEVEL\") \n",
    "print(\"=\"*80)\n",
    "if len(urban_coverage) > 0:\n",
    "    print(urban_coverage.to_string(index=False))\n",
    "else:\n",
    "    print(\"No urban data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINED TOTAL COVERAGE BY NAICS DETAIL LEVEL\")\n",
    "print(\"=\"*80)\n",
    "print(combined_coverage.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bae92e-b927-4d67-964f-ffb51695462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RURAL vs URBAN COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(rural_coverage) > 0 and len(urban_coverage) > 0:\n",
    "    # Calculate averages\n",
    "    rural_avg = rural_coverage[['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']].mean()\n",
    "    urban_avg = urban_coverage[['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']].mean()\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'NAICS_Level': ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit'],\n",
    "        'Rural_Avg': rural_avg.round(1).values,\n",
    "        'Urban_Avg': urban_avg.round(1).values\n",
    "    })\n",
    "    comparison_df['Difference'] = (comparison_df['Urban_Avg'] - comparison_df['Rural_Avg']).round(1)\n",
    "    \n",
    "    print(\"Average coverage percentages:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Summary stats\n",
    "    rural_pumas = rural_coverage['n_pumas'].sum()\n",
    "    urban_pumas = urban_coverage['n_pumas'].sum()\n",
    "    total_pumas = combined_coverage['n_pumas'].sum()\n",
    "    \n",
    "    print(f\"\\nPUMA Distribution:\")\n",
    "    print(f\"  Rural PUMAs: {rural_pumas}\")\n",
    "    print(f\"  Urban PUMAs: {urban_pumas}\")\n",
    "    print(f\"  Total PUMAs: {total_pumas}\")\n",
    "\n",
    "# # Save results\n",
    "# rural_coverage.to_csv(\"rural_naics_coverage.csv\", index=False)\n",
    "# urban_coverage.to_csv(\"urban_naics_coverage.csv\", index=False)\n",
    "# combined_coverage.to_csv(\"combined_naics_coverage.csv\", index=False)\n",
    "\n",
    "print(f\"\\nResults saved:\")\n",
    "print(f\"  - rural_naics_coverage.csv\")\n",
    "print(f\"  - urban_naics_coverage.csv\") \n",
    "print(f\"  - combined_naics_coverage.csv\")\n",
    "\n",
    "print(f\"\\nFinal DataFrames:\")\n",
    "print(f\"  - rural_coverage: Rural areas only\")\n",
    "print(f\"  - urban_coverage: Urban areas only\")\n",
    "print(f\"  - combined_coverage: All areas together (no NaN rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49113d16-1f3d-453b-ae1c-1ef4f3ba757a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>n_pumas</th>\n",
       "      <th>naics_2digit</th>\n",
       "      <th>naics_3digit</th>\n",
       "      <th>naics_4digit</th>\n",
       "      <th>naics_5digit</th>\n",
       "      <th>naics_6digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-75K</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75-100K</td>\n",
       "      <td>34</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100-125K</td>\n",
       "      <td>1058</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125-150K</td>\n",
       "      <td>728</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150-175K</td>\n",
       "      <td>408</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175-200K</td>\n",
       "      <td>199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200-250K</td>\n",
       "      <td>34</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250-300K</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300-400K</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400-500K</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500K+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pop_label  n_pumas  naics_2digit  naics_3digit  naics_4digit  naics_5digit  \\\n",
       "0      0-75K        0           0.0           0.0           0.0           0.0   \n",
       "1    75-100K       34         100.0         100.0         100.0         100.0   \n",
       "2   100-125K     1058         100.0         100.0         100.0         100.0   \n",
       "3   125-150K      728         100.0         100.0         100.0         100.0   \n",
       "4   150-175K      408         100.0         100.0         100.0         100.0   \n",
       "5   175-200K      199         100.0         100.0         100.0         100.0   \n",
       "6   200-250K       34         100.0         100.0         100.0         100.0   \n",
       "7   250-300K        1         100.0         100.0         100.0         100.0   \n",
       "8   300-400K        0           0.0           0.0           0.0           0.0   \n",
       "9   400-500K        0           0.0           0.0           0.0           0.0   \n",
       "10     500K+        0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "    naics_6digit  \n",
       "0            0.0  \n",
       "1          100.0  \n",
       "2          100.0  \n",
       "3          100.0  \n",
       "4          100.0  \n",
       "5          100.0  \n",
       "6          100.0  \n",
       "7          100.0  \n",
       "8            0.0  \n",
       "9            0.0  \n",
       "10           0.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8aa59995-6c47-4470-be82-b1e470a4de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating employment coverage at each NAICS detail level...\n",
      "Analyzing naics_2digit...\n",
      "Analyzing naics_3digit...\n",
      "Analyzing naics_4digit...\n",
      "Analyzing naics_5digit...\n",
      "Analyzing naics_6digit...\n"
     ]
    }
   ],
   "source": [
    "# Calculate employment coverage at each detail level\n",
    "print(\"Calculating employment coverage at each NAICS detail level...\")\n",
    "\n",
    "naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "coverage_results = {}\n",
    "\n",
    "for level in naics_levels:\n",
    "    print(f\"Analyzing {level}...\")\n",
    "    \n",
    "    # Count unique categories at this detail level\n",
    "    unique_categories = all_employed_with_pop[level].nunique()\n",
    "    \n",
    "    # Employment by category at this level\n",
    "    employment_by_category = all_employed_with_pop.groupby(['pop_label', level], observed=True)['PERWT'].sum().reset_index()\n",
    "    \n",
    "    # Coverage by population bucket\n",
    "    coverage_by_pop = []\n",
    "    \n",
    "    for pop_bucket in all_employed_with_pop['pop_label'].dropna().unique():\n",
    "        bucket_data = all_employed_with_pop[all_employed_with_pop['pop_label'] == pop_bucket]\n",
    "        \n",
    "        total_employment = bucket_data['PERWT'].sum()\n",
    "        \n",
    "        # Count categories with meaningful employment (>1% of bucket total)\n",
    "        bucket_categories = bucket_data.groupby(level)['PERWT'].sum()\n",
    "        meaningful_categories = (bucket_categories > total_employment * 0.01).sum()\n",
    "        \n",
    "        # Employment in classifiable categories (not \"Unclassified\") \n",
    "        classifiable_employment = bucket_data[bucket_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "        coverage_pct = (classifiable_employment / total_employment * 100) if total_employment > 0 else 0\n",
    "        \n",
    "        coverage_by_pop.append({\n",
    "            'pop_label': pop_bucket,\n",
    "            'level': level,\n",
    "            'total_employment': total_employment,\n",
    "            'classifiable_employment': classifiable_employment,\n",
    "            'coverage_percent': coverage_pct,\n",
    "            'total_categories': len(bucket_categories),\n",
    "            'meaningful_categories': meaningful_categories,\n",
    "            'unique_categories_overall': unique_categories\n",
    "        })\n",
    "    \n",
    "    coverage_results[level] = pd.DataFrame(coverage_by_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26c01c6e-bd71-46b3-bccb-662c15bd26a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating coverage summary...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>n_pumas</th>\n",
       "      <th>naics_2digit</th>\n",
       "      <th>naics_3digit</th>\n",
       "      <th>naics_4digit</th>\n",
       "      <th>naics_5digit</th>\n",
       "      <th>naics_6digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-125K</td>\n",
       "      <td>212.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125-150K</td>\n",
       "      <td>163.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150-175K</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175-200K</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200-250K</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250-300K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75-100K</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  n_pumas  naics_2digit  naics_3digit  naics_4digit  naics_5digit  \\\n",
       "0  100-125K    212.0         100.0         100.0         100.0         100.0   \n",
       "1  125-150K    163.0         100.0         100.0         100.0         100.0   \n",
       "2  150-175K     80.0         100.0         100.0         100.0         100.0   \n",
       "3  175-200K     45.0         100.0         100.0         100.0         100.0   \n",
       "4  200-250K      6.0         100.0         100.0         100.0         100.0   \n",
       "5  250-300K      NaN         100.0         100.0         100.0         100.0   \n",
       "6   75-100K      3.0         100.0         100.0         100.0         100.0   \n",
       "\n",
       "   naics_6digit  \n",
       "0         100.0  \n",
       "1         100.0  \n",
       "2         100.0  \n",
       "3         100.0  \n",
       "4         100.0  \n",
       "5         100.0  \n",
       "6         100.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summary table of coverage by detail level\n",
    "print(\"Creating coverage summary...\")\n",
    "\n",
    "# Combine all coverage results\n",
    "all_coverage = pd.concat(coverage_results.values(), ignore_index=True)\n",
    "\n",
    "# Pivot to get coverage by level and population bucket\n",
    "coverage_pivot = all_coverage.pivot(index='pop_label', columns='level', values='coverage_percent').round(1)\n",
    "\n",
    "# Add PUMA counts\n",
    "if 'puma_counts' in locals():\n",
    "    puma_counts_df = puma_counts.reset_index()\n",
    "    puma_counts_df.columns = ['pop_label', 'n_pumas']\n",
    "    coverage_pivot = coverage_pivot.reset_index().merge(puma_counts_df, on='pop_label', how='left')\n",
    "    \n",
    "    # Reorder columns\n",
    "    cols = ['pop_label', 'n_pumas'] + naics_levels\n",
    "    coverage_pivot = coverage_pivot[cols]\n",
    "else:\n",
    "    coverage_pivot = coverage_pivot.reset_index()\n",
    "\n",
    "coverage_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc230def-5a8d-446b-875e-5b343f241727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category diversity at each detail level...\n",
      "NAICS DETAIL LEVEL DIVERSITY ANALYSIS\n",
      "============================================================\n",
      "detail_level  avg_coverage_percent  avg_categories_per_area  avg_meaningful_categories  total_unique_categories\n",
      "naics_2digit                 100.0                     10.0                        9.7                       10\n",
      "naics_3digit                 100.0                     93.1                       31.3                       94\n",
      "naics_4digit                 100.0                    246.7                       21.4                      255\n",
      "naics_5digit                 100.0                    255.7                       21.1                      264\n",
      "naics_6digit                 100.0                    255.7                       21.1                      264\n",
      "\n",
      "Column definitions:\n",
      "- avg_coverage_percent: Average % of employment classifiable at this level\n",
      "- avg_categories_per_area: Average number of industry categories per area\n",
      "- avg_meaningful_categories: Average categories with >1% employment\n",
      "- total_unique_categories: Total unique industry categories found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Category diversity analysis\n",
    "print(\"Category diversity at each detail level...\")\n",
    "\n",
    "diversity_summary = []\n",
    "for level in naics_levels:\n",
    "    level_data = coverage_results[level]\n",
    "    \n",
    "    avg_coverage = level_data['coverage_percent'].mean()\n",
    "    avg_total_categories = level_data['total_categories'].mean()\n",
    "    avg_meaningful_categories = level_data['meaningful_categories'].mean()\n",
    "    overall_unique = level_data['unique_categories_overall'].iloc[0]\n",
    "    \n",
    "    diversity_summary.append({\n",
    "        'detail_level': level,\n",
    "        'avg_coverage_percent': round(avg_coverage, 1),\n",
    "        'avg_categories_per_area': round(avg_total_categories, 1),\n",
    "        'avg_meaningful_categories': round(avg_meaningful_categories, 1),\n",
    "        'total_unique_categories': overall_unique\n",
    "    })\n",
    "\n",
    "diversity_df = pd.DataFrame(diversity_summary)\n",
    "\n",
    "print(\"NAICS DETAIL LEVEL DIVERSITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(diversity_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Column definitions:\")\n",
    "print(\"- avg_coverage_percent: Average % of employment classifiable at this level\")\n",
    "print(\"- avg_categories_per_area: Average number of industry categories per area\")\n",
    "print(\"- avg_meaningful_categories: Average categories with >1% employment\")\n",
    "print(\"- total_unique_categories: Total unique industry categories found\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed6014e1-53a3-4f38-89ac-285f39b6ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage by metro status and detail level...\n",
      "Coverage by Metro Status and NAICS Detail Level:\n",
      "naics_level      naics_2digit  naics_3digit  naics_4digit  naics_5digit  naics_6digit\n",
      "metro_status                                                                         \n",
      "Metropolitan            100.0         100.0         100.0         100.0         100.0\n",
      "Non-metro/Rural         100.0         100.0         100.0         100.0         100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detail level comparison by metro status\n",
    "print(\"Coverage by metro status and detail level...\")\n",
    "\n",
    "if 'metro_status' in all_employed_with_pop.columns:\n",
    "    metro_coverage = []\n",
    "    \n",
    "    for metro_type in all_employed_with_pop['metro_status'].unique():\n",
    "        metro_data = all_employed_with_pop[all_employed_with_pop['metro_status'] == metro_type]\n",
    "        \n",
    "        for level in naics_levels:\n",
    "            total_emp = metro_data['PERWT'].sum()\n",
    "            classifiable_emp = metro_data[metro_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "            coverage = (classifiable_emp / total_emp * 100) if total_emp > 0 else 0\n",
    "            \n",
    "            metro_coverage.append({\n",
    "                'metro_status': metro_type,\n",
    "                'naics_level': level,\n",
    "                'coverage_percent': round(coverage, 1),\n",
    "                'unique_categories': metro_data[level].nunique()\n",
    "            })\n",
    "    \n",
    "    metro_coverage_df = pd.DataFrame(metro_coverage)\n",
    "    metro_pivot = metro_coverage_df.pivot(index='metro_status', columns='naics_level', values='coverage_percent')\n",
    "    \n",
    "    print(\"Coverage by Metro Status and NAICS Detail Level:\")\n",
    "    print(metro_pivot.to_string())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f81589d1-c68b-43a9-8ba5-32efc44aa161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if coverage decreases as detail increases...\n",
      "Average coverage by detail level:\n",
      "  naics_2digit: 100.0%\n",
      "  naics_3digit: 100.0%\n",
      "  naics_4digit: 100.0%\n",
      "  naics_5digit: 100.0%\n",
      "  naics_6digit: 100.0%\n",
      "\n",
      "Pattern check: False\n",
      "Unexpected: Some detailed levels have higher coverage\n"
     ]
    }
   ],
   "source": [
    "# Expected pattern analysis (simplified)\n",
    "print(\"Checking if coverage decreases as detail increases...\")\n",
    "\n",
    "expected_pattern = coverage_pivot[naics_levels].mean()\n",
    "print(\"Average coverage by detail level:\")\n",
    "for level, avg_cov in expected_pattern.items():\n",
    "    print(f\"  {level}: {avg_cov:.1f}%\")\n",
    "\n",
    "# Simple pattern check\n",
    "decreasing_pattern = True\n",
    "for i in range(len(naics_levels)-1):\n",
    "    if expected_pattern[naics_levels[i]] <= expected_pattern[naics_levels[i+1]]:\n",
    "        decreasing_pattern = False\n",
    "        break\n",
    "\n",
    "print(f\"\\nPattern check: {decreasing_pattern}\")\n",
    "if decreasing_pattern:\n",
    "    print(\"Good: Coverage decreases as detail increases (as expected)\")\n",
    "else:\n",
    "    print(\"Unexpected: Some detailed levels have higher coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15873bd-7b5e-4ee4-bc8e-b0f2a3451b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e6961-c570-4982-82e0-50988abd27a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78515657-4553-497b-9d79-a37732325dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ALL PUMAs analysis (rural + non-rural)...\n",
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Total PUMAs data: 15,912,393 records\n",
      "Total population: 332,387,543\n",
      "  Metropolitan: 263,263,875 (79.2%)\n",
      "  Non-metro/Rural: 69,123,668 (20.8%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create All PUMAs (Rural + Non-Rural)\n",
    "print(\"Creating ALL PUMAs analysis (rural + non-rural)...\")\n",
    "\n",
    "# All PUMAs with PUMA identification\n",
    "all_puma_df = df[df['PUMA'] != 0].copy()\n",
    "\n",
    "# Add metro status classification\n",
    "all_puma_df['metro_status'] = all_puma_df['MET2013'].apply(\n",
    "    lambda x: 'Non-metro/Rural' if x == 0 else 'Metropolitan'\n",
    ")\n",
    "\n",
    "print(f\"Total PUMAs data: {len(all_puma_df):,} records\")\n",
    "print(f\"Total population: {all_puma_df['PERWT'].sum():,.0f}\")\n",
    "\n",
    "# Check metro status distribution\n",
    "metro_distribution = all_puma_df.groupby('metro_status')['PERWT'].sum()\n",
    "for status, pop in metro_distribution.items():\n",
    "    pct = pop / metro_distribution.sum() * 100\n",
    "    print(f\"  {status}: {pop:,.0f} ({pct:.1f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37b58ec3-2fb2-402b-a344-ef972c3490fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUMA population analysis for ALL areas...\n",
      "Total PUMAs: 2462\n",
      "Rural PUMAs: 509\n",
      "Metro PUMAs: 1953\n",
      "\n",
      "PUMAs by population size and metro status:\n",
      "metro_status  Metropolitan  Non-metro/Rural\n",
      "pop_label                                  \n",
      "0-75K                    0                0\n",
      "75-100K                 31                3\n",
      "100-125K               846              212\n",
      "125-150K               565              163\n",
      "150-175K               328               80\n",
      "175-200K               154               45\n",
      "200-250K                28                6\n",
      "250-300K                 1                0\n",
      "300-400K                 0                0\n",
      "400-500K                 0                0\n",
      "500K+                    0                0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1389/2499526816.py:34: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  puma_counts_by_metro = all_puma_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "#PUMA Population Analysis for ALL PUMAs\n",
    "print(\"PUMA population analysis for ALL areas...\")\n",
    "\n",
    "# Create unique PUMA identifier\n",
    "all_puma_df['unique_puma'] = all_puma_df['STATEFIP'].astype(str) + '_' + all_puma_df['PUMA'].astype(str)\n",
    "\n",
    "# Calculate PUMA populations by metro status\n",
    "all_puma_pop = all_puma_df.groupby('unique_puma').agg({\n",
    "    'PERWT': 'sum',\n",
    "    'STATEFIP': 'first',\n",
    "    'PUMA': 'first',\n",
    "    'MET2013': 'first'\n",
    "}).reset_index()\n",
    "all_puma_pop.columns = ['unique_puma', 'population', 'STATEFIP', 'PUMA', 'MET2013']\n",
    "\n",
    "# Add metro status\n",
    "all_puma_pop['metro_status'] = all_puma_pop['MET2013'].apply(\n",
    "    lambda x: 'Non-metro/Rural' if x == 0 else 'Metropolitan'\n",
    ")\n",
    "\n",
    "# Create population bins\n",
    "pop_bins = [0, 75000, 100000, 125000, 150000, 175000, 200000, 250000, 300000, 400000, 500000, np.inf]\n",
    "pop_labels = ['0-75K', '75-100K', '100-125K', '125-150K', '150-175K', '175-200K', \n",
    "              '200-250K', '250-300K', '300-400K', '400-500K', '500K+']\n",
    "\n",
    "all_puma_pop['pop_label'] = pd.cut(all_puma_pop['population'], bins=pop_bins, labels=pop_labels, right=False)\n",
    "\n",
    "print(f\"Total PUMAs: {len(all_puma_pop)}\")\n",
    "print(f\"Rural PUMAs: {(all_puma_pop['metro_status'] == 'Non-metro/Rural').sum()}\")\n",
    "print(f\"Metro PUMAs: {(all_puma_pop['metro_status'] == 'Metropolitan').sum()}\")\n",
    "print()\n",
    "\n",
    "# PUMAs by population size and metro status\n",
    "puma_counts_by_metro = all_puma_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
    "print(\"PUMAs by population size and metro status:\")\n",
    "print(puma_counts_by_metro)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b46edea5-ee27-4097-9129-8b5d34eea6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment analysis for ALL PUMAs...\n",
      "Total employed persons: 160,913,396\n",
      "Employment by metro status:\n",
      "  Metropolitan: 129,714,051 (80.6%)\n",
      "  Non-metro/Rural: 31,199,345 (19.4%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Employment Analysis for ALL PUMAs\n",
    "print(\"Employment analysis for ALL PUMAs...\")\n",
    "\n",
    "# Get employed persons from all PUMAs\n",
    "all_employed = all_puma_df[all_puma_df['EMPSTAT'] == 1].copy()\n",
    "print(f\"Total employed persons: {all_employed['PERWT'].sum():,.0f}\")\n",
    "\n",
    "# Apply NAICS mapping (same function as before)\n",
    "def map_to_naics_2digit(ind_code):\n",
    "    if pd.isna(ind_code) or ind_code == 0:\n",
    "        return 'Other'\n",
    "    \n",
    "    ind_str = str(int(ind_code)).zfill(4)\n",
    "    \n",
    "    if ind_str.startswith(('017', '018', '019', '027', '028', '029')):\n",
    "        return 'NAICS_11'\n",
    "    elif ind_str.startswith(('067', '068', '069', '077', '078', '079')):\n",
    "        return 'NAICS_23'\n",
    "    elif ind_str.startswith(('107', '108', '109', '117', '118', '119', '127', '128', '129',\n",
    "                             '137', '138', '139', '147', '148', '149', '157', '158', '159',\n",
    "                             '167', '168', '169', '177', '178', '179', '187', '188', '189',\n",
    "                             '197', '198', '199', '207', '208', '209', '217', '218', '219',\n",
    "                             '227', '228', '229', '237', '238', '239', '247', '248', '249',\n",
    "                             '257', '258', '259', '267', '268', '269', '277', '278', '279',\n",
    "                             '287', '288', '289', '297', '298', '299', '307', '308', '309',\n",
    "                             '317', '318', '319', '327', '328', '329', '337', '338', '339',\n",
    "                             '347', '348', '349', '357', '358', '359', '367', '368', '369',\n",
    "                             '377', '378', '379', '387', '388', '389', '397', '398', '399')):\n",
    "        return 'NAICS_31-33'\n",
    "    elif ind_str.startswith(('447', '448', '449', '457', '458', '459', '467', '468', '469',\n",
    "                             '477', '478', '479', '487', '488', '489', '497', '498', '499',\n",
    "                             '507', '508', '509', '517', '518', '519', '527', '528', '529',\n",
    "                             '537', '538', '539', '547', '548', '549', '557', '558', '559',\n",
    "                             '567', '568', '569', '577', '578', '579', '587', '588', '589',\n",
    "                             '597', '598', '599')):\n",
    "        return 'NAICS_44-45'\n",
    "    elif ind_str.startswith(('827', '828', '829', '837', '838', '839', '847', '848', '849',\n",
    "                             '857', '858', '859', '867', '868', '869')):\n",
    "        return 'NAICS_62'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "all_employed['naics_2digit'] = all_employed['IND'].apply(map_to_naics_2digit)\n",
    "all_employed['unique_puma'] = all_employed['STATEFIP'].astype(str) + '_' + all_employed['PUMA'].astype(str)\n",
    "\n",
    "# Drop metro_status from all_employed before merging\n",
    "all_employed_clean = all_employed.drop(columns=['metro_status'])\n",
    "\n",
    "# Then merge\n",
    "all_employed_with_pop = all_employed_clean.merge(\n",
    "    all_puma_pop[['unique_puma', 'pop_label', 'metro_status']], \n",
    "    on='unique_puma', how='left'\n",
    ")\n",
    "print(\"Employment by metro status:\")\n",
    "emp_by_metro = all_employed_with_pop.groupby('metro_status')['PERWT'].sum()\n",
    "for status, emp in emp_by_metro.items():\n",
    "    pct = emp / emp_by_metro.sum() * 100\n",
    "    print(f\"  {status}: {emp:,.0f} ({pct:.1f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6188c0b7-8068-40a4-97d1-84d094e59190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating separate rural and metro analyses...\n",
      "Creating employment summaries...\n"
     ]
    }
   ],
   "source": [
    "# Create Separate Analyses\n",
    "print(\"Creating separate rural and metro analyses...\")\n",
    "\n",
    "# A. RURAL ONLY Analysis\n",
    "rural_employed_with_pop = all_employed_with_pop[all_employed_with_pop['metro_status'] == 'Non-metro/Rural']\n",
    "rural_puma_pop = all_puma_pop[all_puma_pop['metro_status'] == 'Non-metro/Rural']\n",
    "\n",
    "# B. METRO ONLY Analysis  \n",
    "metro_employed_with_pop = all_employed_with_pop[all_employed_with_pop['metro_status'] == 'Metropolitan']\n",
    "metro_puma_pop = all_puma_pop[all_puma_pop['metro_status'] == 'Metropolitan']\n",
    "\n",
    "# C. COMBINED Analysis by Metro Status\n",
    "def create_employment_summary(employed_data, puma_data, analysis_name):\n",
    "    \"\"\"Create employment summary for a given dataset\"\"\"\n",
    "    \n",
    "    if len(employed_data) == 0:\n",
    "        print(f\"No data for {analysis_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Calculate employment by population bucket and NAICS sector\n",
    "    employment_by_pop_naics = employed_data.groupby(['pop_label', 'naics_2digit'], observed=True)['PERWT'].sum().unstack(fill_value=0)\n",
    "    \n",
    "    # Calculate employment percentages\n",
    "    total_employment_by_pop = employment_by_pop_naics.sum(axis=1)\n",
    "    employment_percentages = employment_by_pop_naics.div(total_employment_by_pop, axis=0) * 100\n",
    "   \n",
    "    # Population summary\n",
    "    population_summary = puma_data.groupby('pop_label', observed=True).agg({\n",
    "        'population': 'sum',\n",
    "        'unique_puma': 'count'\n",
    "    }).rename(columns={'unique_puma': 'n_pumas'}).reset_index()\n",
    "    \n",
    "    employed_summary = employed_data.groupby('pop_label', observed=True)['PERWT'].sum().reset_index()\n",
    "    employed_summary.columns = ['pop_label', 'total_employed']\n",
    "    \n",
    "    pop_emp_summary = population_summary.merge(employed_summary, on='pop_label', how='left')\n",
    "    pop_emp_summary['total_employed'] = pop_emp_summary['total_employed'].fillna(0)\n",
    "    \n",
    "    # Create complete summary\n",
    "    all_sectors = [col for col in employment_percentages.columns if col.startswith('NAICS') or col == 'Other']\n",
    "    complete_summary = employment_percentages[all_sectors].fillna(0).round(0).astype(int)\n",
    "    complete_summary = complete_summary.reset_index()\n",
    "    complete_summary = complete_summary.merge(pop_emp_summary, on='pop_label', how='left')\n",
    "    \n",
    "    # Reorder columns\n",
    "    key_cols = ['pop_label', 'n_pumas', 'population', 'total_employed'] \n",
    "    sector_cols = [col for col in complete_summary.columns if col.startswith('NAICS') or col == 'Other']\n",
    "    complete_summary = complete_summary[key_cols + sector_cols]\n",
    "    \n",
    "    return complete_summary\n",
    "\n",
    "# Create all three analyses\n",
    "print(\"Creating employment summaries...\")\n",
    "rural_summary = create_employment_summary(rural_employed_with_pop, rural_puma_pop, \"Rural\")\n",
    "metro_summary = create_employment_summary(metro_employed_with_pop, metro_puma_pop, \"Metro\") \n",
    "all_puma_summary = create_employment_summary(all_employed_with_pop, all_puma_pop, \"All PUMAs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbdfe792-89f9-4067-92fb-c65473fb86f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>n_pumas</th>\n",
       "      <th>population</th>\n",
       "      <th>total_employed</th>\n",
       "      <th>NAICS_11</th>\n",
       "      <th>NAICS_23</th>\n",
       "      <th>NAICS_31-33</th>\n",
       "      <th>NAICS_44-45</th>\n",
       "      <th>NAICS_62</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75-100K</td>\n",
       "      <td>3</td>\n",
       "      <td>299001.0</td>\n",
       "      <td>117644.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-125K</td>\n",
       "      <td>212</td>\n",
       "      <td>23947937.0</td>\n",
       "      <td>10832676.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125-150K</td>\n",
       "      <td>163</td>\n",
       "      <td>22141412.0</td>\n",
       "      <td>10003378.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150-175K</td>\n",
       "      <td>80</td>\n",
       "      <td>13052213.0</td>\n",
       "      <td>5901389.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175-200K</td>\n",
       "      <td>45</td>\n",
       "      <td>8399756.0</td>\n",
       "      <td>3752598.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200-250K</td>\n",
       "      <td>6</td>\n",
       "      <td>1283349.0</td>\n",
       "      <td>591660.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  n_pumas  population  total_employed  NAICS_11  NAICS_23  \\\n",
       "0   75-100K        3    299001.0        117644.0         8         9   \n",
       "1  100-125K      212  23947937.0      10832676.0         3         8   \n",
       "2  125-150K      163  22141412.0      10003378.0         3         8   \n",
       "3  150-175K       80  13052213.0       5901389.0         3         8   \n",
       "4  175-200K       45   8399756.0       3752598.0         2         8   \n",
       "5  200-250K        6   1283349.0        591660.0         2         8   \n",
       "\n",
       "   NAICS_31-33  NAICS_44-45  NAICS_62  Other  \n",
       "0            5           12        12     54  \n",
       "1           13           12        12     51  \n",
       "2           13           12        12     52  \n",
       "3           12           12        12     53  \n",
       "4           12           12        12     55  \n",
       "5            8           12        12     57  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rural_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38aae55-7c1a-438b-afab-fea163fe1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# STEP 1: Create detailed NAICS mappings from IND codes\n",
    "print(\"\\nStep 1: Creating detailed NAICS mappings...\")\n",
    "\n",
    "def create_naics_detail_levels(ind_code):\n",
    "    \"\"\"\n",
    "    Create different levels of NAICS detail from IND codes\n",
    "    This simulates increasing detail levels\n",
    "    \"\"\"\n",
    "    if pd.isna(ind_code) or ind_code == 0:\n",
    "        return {\n",
    "            'naics_2digit': 'Unclassified',\n",
    "            'naics_3digit': 'Unclassified',\n",
    "            'naics_4digit': 'Unclassified', \n",
    "            'naics_5digit': 'Unclassified',\n",
    "            'naics_6digit': 'Unclassified'\n",
    "        }\n",
    "    \n",
    "    # Convert to string for digit extraction\n",
    "    ind_str = str(int(ind_code)).zfill(4)\n",
    "    \n",
    "    # Create progressively more detailed NAICS codes\n",
    "    # This simulates how detail increases with more digits\n",
    "    return {\n",
    "        'naics_2digit': ind_str[0] + '0',           # First digit + 0 (e.g., '10', '20', '30')\n",
    "        'naics_3digit': ind_str[:2] + '0',          # First 2 digits + 0 (e.g., '110', '230') \n",
    "        'naics_4digit': ind_str[:3] + '0',          # First 3 digits + 0 (e.g., '1110', '2380')\n",
    "        'naics_5digit': ind_str,                    # All 4 digits (e.g., '1111', '2381')\n",
    "        'naics_6digit': ind_str + str(ind_code % 10) # Add variation for 6-digit\n",
    "    }\n",
    "\n",
    "# Apply to all employed data (assuming all_employed_with_pop exists)\n",
    "print(\"Applying NAICS detail mapping to employment data...\")\n",
    "\n",
    "# Get the detailed NAICS mappings\n",
    "naics_detail_mapping = all_employed_with_pop['IND'].apply(create_naics_detail_levels)\n",
    "naics_detail_df = pd.DataFrame(naics_detail_mapping.tolist())\n",
    "\n",
    "# Add detail columns to employment data\n",
    "for col in naics_detail_df.columns:\n",
    "    all_employed_with_pop[col] = naics_detail_df[col]\n",
    "\n",
    "print(\"Sample of NAICS detail levels:\")\n",
    "sample_cols = ['IND', 'naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit']\n",
    "print(all_employed_with_pop[sample_cols].head(10))\n",
    "print()\n",
    "\n",
    "# STEP 2: Calculate employment coverage at each detail level\n",
    "print(\"Step 2: Calculating employment coverage at each NAICS detail level...\")\n",
    "\n",
    "naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "coverage_results = {}\n",
    "\n",
    "for level in naics_levels:\n",
    "    print(f\"Analyzing {level}...\")\n",
    "    \n",
    "    # Count unique categories at this detail level\n",
    "    unique_categories = all_employed_with_pop[level].nunique()\n",
    "    \n",
    "    # Employment by category at this level\n",
    "    employment_by_category = all_employed_with_pop.groupby(['pop_label', level], observed=True)['PERWT'].sum().reset_index()\n",
    "    \n",
    "    # Coverage by population bucket\n",
    "    coverage_by_pop = []\n",
    "    \n",
    "    for pop_bucket in all_employed_with_pop['pop_label'].dropna().unique():\n",
    "        bucket_data = all_employed_with_pop[all_employed_with_pop['pop_label'] == pop_bucket]\n",
    "        \n",
    "        total_employment = bucket_data['PERWT'].sum()\n",
    "        \n",
    "        # Count categories with meaningful employment (>1% of bucket total)\n",
    "        bucket_categories = bucket_data.groupby(level)['PERWT'].sum()\n",
    "        meaningful_categories = (bucket_categories > total_employment * 0.01).sum()\n",
    "        \n",
    "        # Employment in classifiable categories (not \"Unclassified\") \n",
    "        classifiable_employment = bucket_data[bucket_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "        coverage_pct = (classifiable_employment / total_employment * 100) if total_employment > 0 else 0\n",
    "        \n",
    "        coverage_by_pop.append({\n",
    "            'pop_label': pop_bucket,\n",
    "            'level': level,\n",
    "            'total_employment': total_employment,\n",
    "            'classifiable_employment': classifiable_employment,\n",
    "            'coverage_percent': coverage_pct,\n",
    "            'total_categories': len(bucket_categories),\n",
    "            'meaningful_categories': meaningful_categories,\n",
    "            'unique_categories_overall': unique_categories\n",
    "        })\n",
    "    \n",
    "    coverage_results[level] = pd.DataFrame(coverage_by_pop)\n",
    "\n",
    "# STEP 3: Create summary table of coverage by detail level\n",
    "print(\"\\nStep 3: Creating coverage summary...\")\n",
    "\n",
    "# Combine all coverage results\n",
    "all_coverage = pd.concat(coverage_results.values(), ignore_index=True)\n",
    "\n",
    "# Pivot to get coverage by level and population bucket\n",
    "coverage_pivot = all_coverage.pivot(index='pop_label', columns='level', values='coverage_percent').round(1)\n",
    "\n",
    "# Add PUMA counts\n",
    "if 'puma_counts' in locals():\n",
    "    puma_counts_df = puma_counts.reset_index()\n",
    "    puma_counts_df.columns = ['pop_label', 'n_pumas']\n",
    "    coverage_pivot = coverage_pivot.reset_index().merge(puma_counts_df, on='pop_label', how='left')\n",
    "    \n",
    "    # Reorder columns\n",
    "    cols = ['pop_label', 'n_pumas'] + naics_levels\n",
    "    coverage_pivot = coverage_pivot[cols]\n",
    "else:\n",
    "    coverage_pivot = coverage_pivot.reset_index()\n",
    "\n",
    "print(\"EMPLOYMENT COVERAGE BY NAICS DETAIL LEVEL\")\n",
    "print(\"=\"*70)\n",
    "print(\"Percentage of employment that can be classified at each detail level\")\n",
    "print(coverage_pivot.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# STEP 4: Category diversity analysis\n",
    "print(\"Step 4: Category diversity at each detail level...\")\n",
    "\n",
    "diversity_summary = []\n",
    "for level in naics_levels:\n",
    "    level_data = coverage_results[level]\n",
    "    \n",
    "    avg_coverage = level_data['coverage_percent'].mean()\n",
    "    avg_total_categories = level_data['total_categories'].mean()\n",
    "    avg_meaningful_categories = level_data['meaningful_categories'].mean()\n",
    "    overall_unique = level_data['unique_categories_overall'].iloc[0]\n",
    "    \n",
    "    diversity_summary.append({\n",
    "        'detail_level': level,\n",
    "        'avg_coverage_percent': round(avg_coverage, 1),\n",
    "        'avg_categories_per_area': round(avg_total_categories, 1),\n",
    "        'avg_meaningful_categories': round(avg_meaningful_categories, 1),\n",
    "        'total_unique_categories': overall_unique\n",
    "    })\n",
    "\n",
    "diversity_df = pd.DataFrame(diversity_summary)\n",
    "\n",
    "print(\"NAICS DETAIL LEVEL DIVERSITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(diversity_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Column definitions:\")\n",
    "print(\"- avg_coverage_percent: Average % of employment classifiable at this level\")\n",
    "print(\"- avg_categories_per_area: Average number of industry categories per area\")\n",
    "print(\"- avg_meaningful_categories: Average categories with >1% employment\")\n",
    "print(\"- total_unique_categories: Total unique industry categories found\")\n",
    "print()\n",
    "\n",
    "# STEP 5: Detail level comparison by metro status\n",
    "print(\"Step 5: Coverage by metro status and detail level...\")\n",
    "\n",
    "if 'metro_status' in all_employed_with_pop.columns:\n",
    "    metro_coverage = []\n",
    "    \n",
    "    for metro_type in all_employed_with_pop['metro_status'].unique():\n",
    "        metro_data = all_employed_with_pop[all_employed_with_pop['metro_status'] == metro_type]\n",
    "        \n",
    "        for level in naics_levels:\n",
    "            total_emp = metro_data['PERWT'].sum()\n",
    "            classifiable_emp = metro_data[metro_data[level] != 'Unclassified']['PERWT'].sum()\n",
    "            coverage = (classifiable_emp / total_emp * 100) if total_emp > 0 else 0\n",
    "            \n",
    "            metro_coverage.append({\n",
    "                'metro_status': metro_type,\n",
    "                'naics_level': level,\n",
    "                'coverage_percent': round(coverage, 1),\n",
    "                'unique_categories': metro_data[level].nunique()\n",
    "            })\n",
    "    \n",
    "    metro_coverage_df = pd.DataFrame(metro_coverage)\n",
    "    metro_pivot = metro_coverage_df.pivot(index='metro_status', columns='naics_level', values='coverage_percent')\n",
    "    \n",
    "    print(\"Coverage by Metro Status and NAICS Detail Level:\")\n",
    "    print(metro_pivot.to_string())\n",
    "    print()\n",
    "\n",
    "# STEP 6: Expected pattern analysis\n",
    "print(\"Step 6: Analysis of expected patterns...\")\n",
    "\n",
    "expected_pattern = coverage_pivot[naics_levels].mean()\n",
    "print(\"Expected pattern: Coverage should decrease as detail increases\")\n",
    "print(\"Average coverage across all areas:\")\n",
    "for level, avg_cov in expected_pattern.items():\n",
    "    print(f\"  {level}: {avg_cov:.1f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Check if pattern holds\n",
    "pattern_check = []\n",
    "for i in range(len(naics_levels)-1):\n",
    "    current_level = naics_levels[i]\n",
    "    next_level = naics_levels[i+1]\n",
    "    \n",
    "    current_avg = expected_pattern[current_level]\n",
    "    next_avg = expected_pattern[next_level]\n",
    "    \n",
    "    decreases = current_avg > next_avg\n",
    "    pattern_check.append(decreases)\n",
    "    \n",
    "    print(f\"{current_level} > {next_level}: {decreases} ({current_avg:.1f}% vs {next_avg:.1f}%)\")\n",
    "\n",
    "all_decreasing = all(pattern_check)\n",
    "print(f\"\\nPattern holds (each level > next level): {all_decreasing}\")\n",
    "\n",
    "if all_decreasing:\n",
    "    print(\"✓ Expected pattern confirmed: More detailed levels have lower coverage\")\n",
    "else:\n",
    "    print(\"⚠ Unexpected pattern: Some detailed levels have higher coverage than broader levels\")\n",
    "\n",
    "# STEP 7: Save results\n",
    "print(\"\\nStep 7: Saving results...\")\n",
    "\n",
    "coverage_pivot.to_csv(\"naics_detail_coverage_by_population.csv\", index=False)\n",
    "diversity_df.to_csv(\"naics_detail_diversity_analysis.csv\", index=False)\n",
    "\n",
    "if 'metro_coverage_df' in locals():\n",
    "    metro_coverage_df.to_csv(\"naics_detail_coverage_by_metro_status.csv\", index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"  - naics_detail_coverage_by_population.csv (main coverage table)\")\n",
    "print(\"  - naics_detail_diversity_analysis.csv (diversity analysis)\")\n",
    "if 'metro_coverage_df' in locals():\n",
    "    print(\"  - naics_detail_coverage_by_metro_status.csv (rural vs urban coverage)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"NAICS DETAIL LEVEL ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"Key Findings:\")\n",
    "print(\"1. Coverage percentages show what % of employment can be classified at each detail level\")\n",
    "print(\"2. Diversity shows how many industry categories exist at each level\")\n",
    "print(\"3. Pattern analysis confirms if finer detail levels have expected lower coverage\")\n",
    "print(\"4. Rural vs urban comparison shows geographic differences in industry detail\")\n",
    "\n",
    "print(f\"\\nFinal DataFrames:\")\n",
    "print(f\"- coverage_pivot: Coverage by population bucket and NAICS detail level\")\n",
    "print(f\"- diversity_df: Summary of category diversity at each detail level\")\n",
    "if 'metro_coverage_df' in locals():\n",
    "    print(f\"- metro_coverage_df: Coverage by metro status and detail level\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
