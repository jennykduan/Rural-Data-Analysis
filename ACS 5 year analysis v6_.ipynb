{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6874a4-1823-4ae3-881f-f9cd508297a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import config\n",
    "from pathlib import Path\n",
    "import snowflake.connector as snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75bcfe1-30f1-4339-94b6-839d15283e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: XlsxWriter in /home/ubuntu/.local/lib/python3.10/site-packages (3.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install XlsxWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770dff82-d4c9-406e-8478-826458b060db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your connection parameters\n",
    "user = config.credentials['USERNAME']\n",
    "password = config.credentials['PASSWORD']\n",
    "account = 'PCA67849'\n",
    "warehouse = config.credentials['WAREHOUSE']\n",
    "\n",
    "# Connect to Snowflake\n",
    "conn = snow.connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database='',\n",
    "    schema=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80de2545-b428-443f-85a3-d6bc342e0124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/1000114304.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  NAICS_CROSSWALK = pd.read_sql(combined_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#  LOAD CROSSWALK ONCE AT STARTUP\n",
    "# ============================================================================\n",
    "# Query NAICS 2017 and 2022 crosswalk\n",
    "combined_query = f\"\"\"\n",
    "SELECT*\n",
    "FROM\n",
    "CROSSWALKS.RAW.NAICS_2017_NAICS_2022\n",
    "\"\"\"\n",
    "# Execute query and get data\n",
    "NAICS_CROSSWALK = pd.read_sql(combined_query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e23952-4da5-47bd-83e5-94dd8ce0d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/3271382745.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  NAICS_CROSSWALK_2017 = pd.read_sql(combined_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#  LOAD CROSSWALK ONCE AT STARTUP\n",
    "# ============================================================================\n",
    "# Query NAICS 2017 and 2022 crosswalk\n",
    "combined_query = f\"\"\"\n",
    "SELECT*\n",
    "FROM\n",
    "CROSSWALKS.CUSTOM.NAICS_2017_LIST\n",
    "\"\"\"\n",
    "# Execute query and get data\n",
    "NAICS_CROSSWALK_2017 = pd.read_sql(combined_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd75b93c-175d-47b2-93ec-0b619b7445c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/1996322609.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  NAICS_CROSSWALK_2022 = pd.read_sql(combined_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#  LOAD CROSSWALK ONCE AT STARTUP\n",
    "# ============================================================================\n",
    "# Query NAICS 2017 and 2022 crosswalk\n",
    "combined_query = f\"\"\"\n",
    "SELECT*\n",
    "FROM\n",
    "CROSSWALKS.CUSTOM.NAICS_2022_LIST\n",
    "\"\"\"\n",
    "# Execute query and get data\n",
    "NAICS_CROSSWALK_2022 = pd.read_sql(combined_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac689bc8-d8b0-4c49-a9fc-c0f3f6085ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAICS_2022</th>\n",
       "      <th>NAICS_Title_2022</th>\n",
       "      <th>NAICS_2017</th>\n",
       "      <th>NAICS_Title_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111110.0</td>\n",
       "      <td>Soybean Farming</td>\n",
       "      <td>111110.0</td>\n",
       "      <td>Soybean Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928120.0</td>\n",
       "      <td>International Affairs</td>\n",
       "      <td>928120.0</td>\n",
       "      <td>International Affairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928110.0</td>\n",
       "      <td>National Security</td>\n",
       "      <td>928110.0</td>\n",
       "      <td>National Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927110.0</td>\n",
       "      <td>Space Research and Technology</td>\n",
       "      <td>927110.0</td>\n",
       "      <td>Space Research and Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>926150.0</td>\n",
       "      <td>Regulation, Licensing, and Inspection of Misce...</td>\n",
       "      <td>926150.0</td>\n",
       "      <td>Regulation, Licensing, and Inspection of Misce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>111160.0</td>\n",
       "      <td>Rice Farming</td>\n",
       "      <td>111160.0</td>\n",
       "      <td>Rice Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>111150.0</td>\n",
       "      <td>Corn Farming</td>\n",
       "      <td>111150.0</td>\n",
       "      <td>Corn Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>111140.0</td>\n",
       "      <td>Wheat Farming</td>\n",
       "      <td>111140.0</td>\n",
       "      <td>Wheat Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>111130.0</td>\n",
       "      <td>Dry Pea and Bean Farming</td>\n",
       "      <td>111130.0</td>\n",
       "      <td>Dry Pea and Bean Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>111120.0</td>\n",
       "      <td>Oilseed (except Soybean) Farming</td>\n",
       "      <td>111120.0</td>\n",
       "      <td>Oilseed (except Soybean) Farming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAICS_2022                                   NAICS_Title_2022  \\\n",
       "0       111110.0                                    Soybean Farming   \n",
       "1       928120.0                              International Affairs   \n",
       "2       928110.0                                  National Security   \n",
       "3       927110.0                      Space Research and Technology   \n",
       "4       926150.0  Regulation, Licensing, and Inspection of Misce...   \n",
       "...          ...                                                ...   \n",
       "1145    111160.0                                       Rice Farming   \n",
       "1146    111150.0                                       Corn Farming   \n",
       "1147    111140.0                                      Wheat Farming   \n",
       "1148    111130.0                           Dry Pea and Bean Farming   \n",
       "1149    111120.0                   Oilseed (except Soybean) Farming   \n",
       "\n",
       "      NAICS_2017                                   NAICS_Title_2017  \n",
       "0       111110.0                                    Soybean Farming  \n",
       "1       928120.0                              International Affairs  \n",
       "2       928110.0                                  National Security  \n",
       "3       927110.0                      Space Research and Technology  \n",
       "4       926150.0  Regulation, Licensing, and Inspection of Misce...  \n",
       "...          ...                                                ...  \n",
       "1145    111160.0                                       Rice Farming  \n",
       "1146    111150.0                                       Corn Farming  \n",
       "1147    111140.0                                      Wheat Farming  \n",
       "1148    111130.0                           Dry Pea and Bean Farming  \n",
       "1149    111120.0                   Oilseed (except Soybean) Farming  \n",
       "\n",
       "[1150 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAICS_CROSSWALK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4741c556-70d4-420c-8f30-4f3f1f5bb3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/542162206.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  county_population_df  = pd.read_sql(combined_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#  LOAD FULL COUNTY COUNT\n",
    "# ============================================================================\n",
    "# Load County from Scott's database\n",
    "combined_query = f\"\"\"\n",
    "SELECT*\n",
    "FROM \n",
    "temporary_data.sspitze.county_population_2020_2023\n",
    "\"\"\"\n",
    "# Execute query and get data\n",
    "county_population_df  = pd.read_sql(combined_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d180c6b5-f514-488c-8da3-782da195dcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>cbsa_status</th>\n",
       "      <th>county_population_2020</th>\n",
       "      <th>county_population_2021</th>\n",
       "      <th>county_population_2022</th>\n",
       "      <th>county_population_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58915.0</td>\n",
       "      <td>59203.0</td>\n",
       "      <td>59726.0</td>\n",
       "      <td>60342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56045</td>\n",
       "      <td>Weston County, Wyoming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6816.0</td>\n",
       "      <td>6746.0</td>\n",
       "      <td>6858.0</td>\n",
       "      <td>6808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56043</td>\n",
       "      <td>Washakie County, Wyoming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7657.0</td>\n",
       "      <td>7719.0</td>\n",
       "      <td>7724.0</td>\n",
       "      <td>7710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56041</td>\n",
       "      <td>Uinta County, Wyoming</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20457.0</td>\n",
       "      <td>20681.0</td>\n",
       "      <td>20727.0</td>\n",
       "      <td>20745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56039</td>\n",
       "      <td>Teton County, Wyoming</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23379.0</td>\n",
       "      <td>23605.0</td>\n",
       "      <td>23297.0</td>\n",
       "      <td>23232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>01011</td>\n",
       "      <td>Bullock County, Alabama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10229.0</td>\n",
       "      <td>10143.0</td>\n",
       "      <td>10143.0</td>\n",
       "      <td>9897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>01009</td>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59107.0</td>\n",
       "      <td>59079.0</td>\n",
       "      <td>59516.0</td>\n",
       "      <td>59816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>01007</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22188.0</td>\n",
       "      <td>22359.0</td>\n",
       "      <td>21986.0</td>\n",
       "      <td>21868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>01005</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24969.0</td>\n",
       "      <td>24533.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>24585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233227.0</td>\n",
       "      <td>239439.0</td>\n",
       "      <td>246531.0</td>\n",
       "      <td>253507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_fips_code               county_name  cbsa_status  \\\n",
       "0               01001   Autauga County, Alabama          1.0   \n",
       "1               56045    Weston County, Wyoming          0.0   \n",
       "2               56043  Washakie County, Wyoming          0.0   \n",
       "3               56041     Uinta County, Wyoming          1.0   \n",
       "4               56039     Teton County, Wyoming          1.0   \n",
       "...               ...                       ...          ...   \n",
       "3139            01011   Bullock County, Alabama          0.0   \n",
       "3140            01009    Blount County, Alabama          1.0   \n",
       "3141            01007      Bibb County, Alabama          1.0   \n",
       "3142            01005   Barbour County, Alabama          0.0   \n",
       "3143            01003   Baldwin County, Alabama          1.0   \n",
       "\n",
       "      county_population_2020  county_population_2021  county_population_2022  \\\n",
       "0                    58915.0                 59203.0                 59726.0   \n",
       "1                     6816.0                  6746.0                  6858.0   \n",
       "2                     7657.0                  7719.0                  7724.0   \n",
       "3                    20457.0                 20681.0                 20727.0   \n",
       "4                    23379.0                 23605.0                 23297.0   \n",
       "...                      ...                     ...                     ...   \n",
       "3139                 10229.0                 10143.0                 10143.0   \n",
       "3140                 59107.0                 59079.0                 59516.0   \n",
       "3141                 22188.0                 22359.0                 21986.0   \n",
       "3142                 24969.0                 24533.0                 24700.0   \n",
       "3143                233227.0                239439.0                246531.0   \n",
       "\n",
       "      county_population_2023  \n",
       "0                    60342.0  \n",
       "1                     6808.0  \n",
       "2                     7710.0  \n",
       "3                    20745.0  \n",
       "4                    23232.0  \n",
       "...                      ...  \n",
       "3139                  9897.0  \n",
       "3140                 59816.0  \n",
       "3141                 21868.0  \n",
       "3142                 24585.0  \n",
       "3143                253507.0  \n",
       "\n",
       "[3144 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_population_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9917bb71-286e-4057-9bb0-10380b9279a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_standardized_county_fips(employed_data):\n",
    "    \"\"\"\n",
    "    Create standardized county FIPS codes, handling historical discrepancies\n",
    "    between IPUMS COUNTYFIP codes and standard FIPS codes.\n",
    "    \"\"\"\n",
    "    # Known discrepancies between IPUMS COUNTYFIP and standard FIPS codes\n",
    "    # fips_mapping = {\n",
    "    #     # Miami-Dade County, Florida: IPUMS uses 025, standard FIPS uses 086\n",
    "    #     '12025': '12086'\n",
    "    # }\n",
    "    \n",
    "    # Create IPUMS-style FIPS codes first\n",
    "    employed_data['county_fips_ipums'] = (\n",
    "        employed_data['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "        employed_data['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "    )\n",
    "    \n",
    "    # Map to standard FIPS codes\n",
    "    # employed_data['county_fips'] = employed_data['county_fips_ipums'].map(\n",
    "    #     lambda x: fips_mapping.get(x, x)  # Use mapping if exists, otherwise keep original\n",
    "    # )\n",
    "    \n",
    "    # Just use the IPUMS codes as final codes (no mapping needed)\n",
    "    employed_data['county_fips'] = employed_data['county_fips_ipums']\n",
    "    \n",
    "    # Log the mapping results\n",
    "    # mapped_counties = employed_data[employed_data['county_fips'] != employed_data['county_fips_ipums']]\n",
    "    # if len(mapped_counties) > 0:\n",
    "    #     print(f\"FIPS mapping applied to {len(mapped_counties)} records:\")\n",
    "    #     for ipums_fips, standard_fips in fips_mapping.items():\n",
    "    #         count = len(mapped_counties[mapped_counties['county_fips_ipums'] == ipums_fips])\n",
    "    #         if count > 0:\n",
    "    #             print(f\"  {ipums_fips} → {standard_fips}: {count} records\")\n",
    "    \n",
    "    print(\"FIPS codes created - no mapping applied\")\n",
    "    \n",
    "    return employed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e7f8f6-230a-49dd-8398-2651c6ec02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_county_universe(county_population_df):\n",
    "    \"\"\"\n",
    "    Create complete county universe with population buckets from Snowflake data.\n",
    "    \n",
    "    Args:\n",
    "        county_population_df: DataFrame from Snowflake with columns:\n",
    "            - county_fips_code: 5-digit FIPS (string)\n",
    "            - county_name: County name  \n",
    "            - county_population_2023: Most recent population\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with county_fips, county_name, pop_label for ALL counties\n",
    "    \"\"\"\n",
    "    print(\"Creating full county universe from Snowflake data...\")\n",
    "    \n",
    "    # Population buckets (same as your ACS analysis)\n",
    "    POPULATION_BUCKETS = [\n",
    "        (0, 25000, '0-25K'),\n",
    "        (25000, 50000, '25K-50K'), \n",
    "        (50000, 75000, '50K-75K'),\n",
    "        (75000, 100000, '75K-100K'),\n",
    "        (100000, 1000000, '100K-1M'),\n",
    "        (1000000, float('inf'), '1M+')\n",
    "    ]\n",
    "    \n",
    "    # Use 2023 population for bucketing\n",
    "    df = county_population_df[['county_fips_code', 'county_name', 'county_population_2023']].copy()\n",
    "    df = df.rename(columns={\n",
    "        'county_fips_code': 'county_fips',\n",
    "        'county_population_2023': 'total_population'\n",
    "    })\n",
    "    \n",
    "    # Assign population buckets\n",
    "    conditions = [df['total_population'] < bucket[1] for bucket in POPULATION_BUCKETS[:-1]]\n",
    "    choices = [bucket[2] for bucket in POPULATION_BUCKETS[:-1]]\n",
    "    df['pop_label'] = np.select(conditions, choices, default=POPULATION_BUCKETS[-1][2])\n",
    "    \n",
    "    print(f\"✓ Full county universe created: {len(df)} counties\")\n",
    "    print(\"Population bucket distribution (all US counties):\")\n",
    "    bucket_dist = df['pop_label'].value_counts().sort_index()\n",
    "    for bucket, count in bucket_dist.items():\n",
    "        print(f\"  {bucket}: {count} counties\")\n",
    "    \n",
    "    return df[['county_fips', 'county_name', 'pop_label']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6ed2e92-3b57-466a-9914-849e36a97b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pop_label_metro_only(df):\n",
    "    \"\"\"Create pop_label_metro for downstream analysis (e.g., Step 10).\"\"\"\n",
    "    if 'metro_status' not in df.columns or 'pop_label' not in df.columns:\n",
    "        raise ValueError(\"Both 'metro_status' and 'pop_label' must exist to create 'pop_label_metro'\")\n",
    "    \n",
    "    df['pop_label_metro'] = df['pop_label'].astype(str) + ' ' + df['metro_status'].astype(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34fe4f9-c106-4c4f-8d9e-e59cb015b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# HELPER FUNCTIONS FOR REPRESENTATION ANALYSIS\n",
    "# --------------------------------------------\n",
    "\n",
    "def create_geographic_presence_matrix_stacked(df, unit_col, code_levels, title_levels, is_soc=False):\n",
    "    \"\"\"\n",
    "    Final: Calculate % of geographic units (PUMA or County) where each code is present,\n",
    "    stacked across levels, and reshaped into wide format by pop+metro group.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure required grouping field exists\n",
    "    assert 'pop_label' in df.columns and 'metro_status' in df.columns, \\\n",
    "        \"Missing 'pop_label' or 'metro_status' columns\"\n",
    "\n",
    "    df_valid = df[df[unit_col].notna()].copy()\n",
    "\n",
    "    # Combined group for reshaping: e.g. \"50K-75K Metro:1\"\n",
    "    df_valid['group'] = df_valid['pop_label'] + ' Metro:' + df_valid['metro_status'].map({\n",
    "        'Metropolitan': '1',\n",
    "        'Non-metro/Rural': '0'\n",
    "    })\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for code_col, title_col in zip(code_levels, title_levels):\n",
    "        level_df = df_valid[df_valid[code_col].notna() & (df_valid[code_col] != 'Unclassified')].copy()\n",
    "\n",
    "        # Count number of unique units where the code appears in each group\n",
    "        unit_counts = (\n",
    "            level_df.groupby([code_col, title_col, 'group'])[unit_col]\n",
    "            .nunique()\n",
    "            .reset_index(name='num_units')\n",
    "        )\n",
    "\n",
    "        # Total number of unique units per group\n",
    "        total_units = (\n",
    "            df_valid.groupby('group')[unit_col]\n",
    "            .nunique()\n",
    "            .reset_index(name='total_units')\n",
    "        )\n",
    "\n",
    "        # Merge + compute % presence\n",
    "        merged = unit_counts.merge(total_units, on='group', how='left')\n",
    "        merged['representation_pct'] = round(100 * merged['num_units'] / merged['total_units'], 1)\n",
    "\n",
    "        # Pivot to wide format\n",
    "        wide = merged.pivot_table(index=[code_col, title_col], columns='group', values='representation_pct').reset_index()\n",
    "\n",
    "        # Rename columns for SOC vs NAICS\n",
    "        if is_soc:\n",
    "            wide = wide.rename(columns={\n",
    "                code_col: 'occupation_code',\n",
    "                title_col: 'occupation_title'\n",
    "            })\n",
    "        else:\n",
    "            wide = wide.rename(columns={\n",
    "                code_col: 'industry_code',\n",
    "                title_col: 'industry_title'\n",
    "            })\n",
    "\n",
    "        results.append(wide)\n",
    "\n",
    "    # Combine all levels (already stacked, no level col needed)\n",
    "    final = pd.concat(results, axis=0, ignore_index=True)\n",
    "\n",
    "    # Order columns: ID + pop-metro groups in population ascending order\n",
    "    ordered_groups = [\n",
    "        '0-25K Metro:0', '0-25K Metro:1',\n",
    "        '25K-50K Metro:0', '25K-50K Metro:1',\n",
    "        '50K-75K Metro:0', '50K-75K Metro:1',\n",
    "        '75K-100K Metro:0', '75K-100K Metro:1',\n",
    "        '100K-1M Metro:0', '100K-1M Metro:1',\n",
    "        '1M+ Metro:0', '1M+ Metro:1',\n",
    "        'Unknown County Metro:0', 'Unknown County Metro:1'\n",
    "    ]\n",
    "    id_cols = ['occupation_code', 'occupation_title'] if is_soc else ['industry_code', 'industry_title']\n",
    "    existing_groups = [col for col in ordered_groups if col in final.columns]\n",
    "    final = final[id_cols + existing_groups]\n",
    "\n",
    "    return final\n",
    "\n",
    "def create_naics_representation_matrix(employed_data, unit='PUMA', full_county_universe=None):\n",
    "    \"\"\"\n",
    "    VECTORIZED version: Create NAICS representation matrix with pure ACS denominators.\n",
    "    \"\"\"\n",
    "    print(f\"Creating NAICS representation matrix for {unit} (vectorized)...\")\n",
    "    \n",
    "    # All expected population buckets and levels\n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']\n",
    "    metro_statuses = ['Rural', 'Urban']\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "    \n",
    "    # Create geographic identifier\n",
    "    if unit == 'County':\n",
    "        if 'county_fips' not in employed_data.columns:\n",
    "            employed_data['county_fips'] = (\n",
    "                employed_data['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "                employed_data['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "            )\n",
    "        geo_id_col = 'county_fips'\n",
    "    else:\n",
    "        geo_id_col = 'geo_id'\n",
    "    \n",
    "    # Create metro label mapping\n",
    "    employed_data['metro_label'] = employed_data['metro_status'].map({\n",
    "        'Non-metro/Rural': 'Rural',\n",
    "        'Metropolitan': 'Urban'\n",
    "    })\n",
    "    \n",
    "    # Always use pure ACS denominators - no merge, no filtering\n",
    "    print(\"Using pure ACS denominators (all counties with employment data)...\")\n",
    "    total_counts = employed_data.groupby(['pop_label', 'metro_label'])[geo_id_col].nunique().reset_index(name='total_units')\n",
    "    print(f\"Total ACS counties: {len(employed_data[geo_id_col].unique())}\")\n",
    "    \n",
    "    # Show denominator breakdown\n",
    "    print(\"ACS denominator breakdown:\")\n",
    "    for _, row in total_counts.iterrows():\n",
    "        print(f\"  {row['pop_label']} {row['metro_label']}: {row['total_units']} counties\")\n",
    "    \n",
    "    # Create lookup for total counts\n",
    "    total_counts_dict = {}\n",
    "    for _, row in total_counts.iterrows():\n",
    "        key = (row['pop_label'], row['metro_label'])\n",
    "        total_counts_dict[key] = row['total_units']\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each NAICS level\n",
    "    for level in naics_levels:\n",
    "        code_col = level\n",
    "        title_col = f\"{level}_title\"\n",
    "        \n",
    "        if code_col not in employed_data.columns:\n",
    "            continue\n",
    "            \n",
    "        # Filter to classified data for this level\n",
    "        level_data = employed_data[employed_data[code_col] != 'Unclassified'].copy()\n",
    "        if len(level_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Count unique units with each code by bucket+metro\n",
    "        industry_counts = level_data.groupby([code_col, 'pop_label', 'metro_label'])[geo_id_col].nunique().reset_index()\n",
    "        industry_counts = industry_counts.rename(columns={geo_id_col: 'units_with_industry'})\n",
    "        \n",
    "        # Get titles\n",
    "        title_map = level_data[[code_col, title_col]].drop_duplicates().set_index(code_col)[title_col].to_dict()\n",
    "        \n",
    "        # Create all combinations of codes and bucket+metro\n",
    "        unique_codes = level_data[code_col].unique()\n",
    "        combinations = []\n",
    "        for code in unique_codes:\n",
    "            for bucket in all_buckets:\n",
    "                for metro in metro_statuses:\n",
    "                    combinations.append({\n",
    "                        code_col: code,\n",
    "                        'pop_label': bucket,\n",
    "                        'metro_label': metro\n",
    "                    })\n",
    "        \n",
    "        combo_df = pd.DataFrame(combinations)\n",
    "        \n",
    "        # Merge with counts (left join to keep all combinations)\n",
    "        merged = combo_df.merge(industry_counts, on=[code_col, 'pop_label', 'metro_label'], how='left')\n",
    "        merged['units_with_industry'] = merged['units_with_industry'].fillna(0)\n",
    "        \n",
    "        # Add total counts and calculate percentages\n",
    "        merged['total_units'] = merged.apply(lambda row: total_counts_dict.get((row['pop_label'], row['metro_label']), 0), axis=1)\n",
    "        merged['percentage'] = (merged['units_with_industry'] / merged['total_units'] * 100).fillna(0).round(1)\n",
    "        \n",
    "        # Reshape to wide format\n",
    "        pivot = merged.pivot_table(\n",
    "            index=code_col,\n",
    "            columns=['pop_label', 'metro_label'],\n",
    "            values='percentage',\n",
    "            fill_value=0\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Flatten MultiIndex columns properly\n",
    "        if isinstance(pivot.columns, pd.MultiIndex):\n",
    "            # Flatten the MultiIndex columns\n",
    "            new_cols = []\n",
    "            for col in pivot.columns:\n",
    "                if col[0] == code_col:  # This is the index column\n",
    "                    new_cols.append(code_col)\n",
    "                else:\n",
    "                    # This is a data column, format as \"bucket metro\"\n",
    "                    new_cols.append(f\"{col[0]} {col[1]}\")\n",
    "            pivot.columns = new_cols\n",
    "        \n",
    "        # Ensure all expected columns exist\n",
    "        expected_cols = [code_col]\n",
    "        for bucket in all_buckets:\n",
    "            for metro in metro_statuses:\n",
    "                col_name = f\"{bucket} {metro}\"\n",
    "                expected_cols.append(col_name)\n",
    "                if col_name not in pivot.columns:\n",
    "                    pivot[col_name] = 0.0\n",
    "        \n",
    "        # Add titles and rename columns\n",
    "        pivot['industry_title'] = pivot[code_col].map(title_map)\n",
    "        pivot = pivot.rename(columns={code_col: 'industry_code'})\n",
    "        \n",
    "        # Reorder columns properly\n",
    "        final_columns = ['industry_code', 'industry_title']\n",
    "        for bucket in all_buckets:\n",
    "            for metro in metro_statuses:\n",
    "                col_name = f\"{bucket} {metro}\"\n",
    "                if col_name in pivot.columns:\n",
    "                    final_columns.append(col_name)\n",
    "        \n",
    "        pivot = pivot[final_columns]\n",
    "        \n",
    "        all_results.append(pivot)\n",
    "        print(f\"  {level}: {len(pivot)} codes processed\")\n",
    "    \n",
    "    if not all_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all levels\n",
    "    result_df = pd.concat(all_results, ignore_index=True)\n",
    "    result_df = result_df.sort_values('industry_code').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"✓ NAICS representation matrix (pure ACS denominators): {len(result_df)} total codes\")\n",
    "    return result_df\n",
    "\n",
    "def create_soc_representation_matrix(employed_data, unit='PUMA', full_county_universe=None):\n",
    "    \"\"\"\n",
    "    VECTORIZED version: Create SOC representation matrix with pure ACS denominators.\n",
    "    \"\"\"\n",
    "    print(f\"Creating SOC representation matrix for {unit} (vectorized)...\")\n",
    "    \n",
    "    # All expected population buckets and levels\n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']\n",
    "    metro_statuses = ['Rural', 'Urban']\n",
    "    soc_levels = ['soc_2digit', 'soc_3digit', 'soc_4digit', 'soc_5digit', 'soc_6digit']\n",
    "    \n",
    "    # Create geographic identifier\n",
    "    if unit == 'County':\n",
    "        if 'county_fips' not in employed_data.columns:\n",
    "            employed_data['county_fips'] = (\n",
    "                employed_data['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "                employed_data['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "            )\n",
    "        geo_id_col = 'county_fips'\n",
    "    else:\n",
    "        geo_id_col = 'geo_id'\n",
    "    \n",
    "    # Create metro label mapping\n",
    "    employed_data['metro_label'] = employed_data['metro_status'].map({\n",
    "        'Non-metro/Rural': 'Rural',\n",
    "        'Metropolitan': 'Urban'\n",
    "    })\n",
    "    \n",
    "    # Always use pure ACS denominators - no merge, no filtering\n",
    "    print(\"Using pure ACS denominators (all counties with employment data)...\")\n",
    "    total_counts = employed_data.groupby(['pop_label', 'metro_label'])[geo_id_col].nunique().reset_index(name='total_units')\n",
    "    \n",
    "    # Create lookup for total counts\n",
    "    total_counts_dict = {}\n",
    "    for _, row in total_counts.iterrows():\n",
    "        key = (row['pop_label'], row['metro_label'])\n",
    "        total_counts_dict[key] = row['total_units']\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each SOC level\n",
    "    for level in soc_levels:\n",
    "        code_col = level\n",
    "        title_col = f\"{level}_title\"\n",
    "        \n",
    "        if code_col not in employed_data.columns:\n",
    "            continue\n",
    "            \n",
    "        # Filter to classified data for this level\n",
    "        level_data = employed_data[employed_data[code_col] != 'Unclassified'].copy()\n",
    "        if len(level_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Count unique units with each code by bucket+metro\n",
    "        occupation_counts = level_data.groupby([code_col, 'pop_label', 'metro_label'])[geo_id_col].nunique().reset_index()\n",
    "        occupation_counts = occupation_counts.rename(columns={geo_id_col: 'units_with_occupation'})\n",
    "        \n",
    "        # Get titles\n",
    "        title_map = level_data[[code_col, title_col]].drop_duplicates().set_index(code_col)[title_col].to_dict()\n",
    "        \n",
    "        # Create all combinations of codes and bucket+metro\n",
    "        unique_codes = level_data[code_col].unique()\n",
    "        combinations = []\n",
    "        for code in unique_codes:\n",
    "            for bucket in all_buckets:\n",
    "                for metro in metro_statuses:\n",
    "                    combinations.append({\n",
    "                        code_col: code,\n",
    "                        'pop_label': bucket,\n",
    "                        'metro_label': metro\n",
    "                    })\n",
    "        \n",
    "        combo_df = pd.DataFrame(combinations)\n",
    "        \n",
    "        # Merge with counts (left join to keep all combinations)\n",
    "        merged = combo_df.merge(occupation_counts, on=[code_col, 'pop_label', 'metro_label'], how='left')\n",
    "        merged['units_with_occupation'] = merged['units_with_occupation'].fillna(0)\n",
    "        \n",
    "        # Add total counts and calculate percentages\n",
    "        merged['total_units'] = merged.apply(lambda row: total_counts_dict.get((row['pop_label'], row['metro_label']), 0), axis=1)\n",
    "        merged['percentage'] = (merged['units_with_occupation'] / merged['total_units'] * 100).fillna(0).round(1)\n",
    "        \n",
    "        # Reshape to wide format\n",
    "        pivot = merged.pivot_table(\n",
    "            index=code_col,\n",
    "            columns=['pop_label', 'metro_label'],\n",
    "            values='percentage',\n",
    "            fill_value=0\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Flatten MultiIndex columns properly\n",
    "        if isinstance(pivot.columns, pd.MultiIndex):\n",
    "            # Flatten the MultiIndex columns\n",
    "            new_cols = []\n",
    "            for col in pivot.columns:\n",
    "                if col[0] == code_col:  # This is the index column\n",
    "                    new_cols.append(code_col)\n",
    "                else:\n",
    "                    # This is a data column, format as \"bucket metro\"\n",
    "                    new_cols.append(f\"{col[0]} {col[1]}\")\n",
    "            pivot.columns = new_cols\n",
    "        \n",
    "        # Ensure all expected columns exist\n",
    "        expected_cols = [code_col]\n",
    "        for bucket in all_buckets:\n",
    "            for metro in metro_statuses:\n",
    "                col_name = f\"{bucket} {metro}\"\n",
    "                expected_cols.append(col_name)\n",
    "                if col_name not in pivot.columns:\n",
    "                    pivot[col_name] = 0.0\n",
    "        \n",
    "        # Add titles and rename columns\n",
    "        pivot['occupation_title'] = pivot[code_col].map(title_map)\n",
    "        pivot = pivot.rename(columns={code_col: 'occupation_code'})\n",
    "        \n",
    "        # Reorder columns properly\n",
    "        final_columns = ['occupation_code', 'occupation_title']\n",
    "        for bucket in all_buckets:\n",
    "            for metro in metro_statuses:\n",
    "                col_name = f\"{bucket} {metro}\"\n",
    "                if col_name in pivot.columns:\n",
    "                    final_columns.append(col_name)\n",
    "        \n",
    "        pivot = pivot[final_columns]\n",
    "        \n",
    "        all_results.append(pivot)\n",
    "        print(f\"  {level}: {len(pivot)} codes processed\")\n",
    "    \n",
    "    if not all_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all levels\n",
    "    result_df = pd.concat(all_results, ignore_index=True)\n",
    "    result_df = result_df.sort_values('occupation_code').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"✓ SOC representation matrix (pure ACS denominators): {len(result_df)} total codes\")\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf3d74e0-1165-44f3-9f66-59ae900e317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZED NAICS CROSSWALK WITH CONSOLIDATION RULES\n",
    "# ============================================================================\n",
    "\n",
    "def load_excel_naics_crosswalk(crosswalk_path):\n",
    "    \"\"\"OPTIMIZED: Load and process the NAICS crosswalk Excel file using vectorized operations\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading Excel crosswalk from {crosswalk_path}...\")\n",
    "        crosswalk_df = pd.read_excel(crosswalk_path)\n",
    "        \n",
    "        # Use the correct columns for 2023-2027 data\n",
    "        naics_col = '2023-2027 ACS/PRCS INDNAICS CODE'  \n",
    "        title_col = 'Industry Title'  \n",
    "        \n",
    "        # OPTIMIZATION: Vectorized data cleaning instead of iterrows()\n",
    "        # Filter out invalid rows first\n",
    "        valid_mask = (\n",
    "            crosswalk_df[naics_col].notna() & \n",
    "            crosswalk_df[title_col].notna() &\n",
    "            (crosswalk_df[naics_col].astype(str).str.strip() != '0') &\n",
    "            (crosswalk_df[naics_col].astype(str).str.strip() != 'nan')\n",
    "        )\n",
    "        \n",
    "        valid_df = crosswalk_df[valid_mask].copy()\n",
    "        \n",
    "        if len(valid_df) == 0:\n",
    "            print(\"No valid NAICS codes found in Excel file\")\n",
    "            return {}\n",
    "        \n",
    "        # OPTIMIZATION: Vectorized string cleaning\n",
    "        valid_df['naics_clean'] = valid_df[naics_col].astype(str).str.strip()\n",
    "        valid_df['title_clean'] = valid_df[title_col].astype(str).str.strip()\n",
    "        \n",
    "        # OPTIMIZATION: Use to_dict() instead of iterrows()\n",
    "        excel_mapping = dict(zip(valid_df['naics_clean'], valid_df['title_clean']))\n",
    "        \n",
    "        print(f\"Excel NAICS crosswalk loaded: {len(excel_mapping)} codes\")\n",
    "        return excel_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Excel crosswalk: {e}\")\n",
    "        return {}\n",
    "\n",
    "def create_combined_naics_mapping(naics_crosswalk_df, excel_crosswalk_path):\n",
    "    \"\"\"OPTIMIZED: Create NAICS mapping from Snowflake with Excel fallback and consolidation rules\"\"\"\n",
    "    \n",
    "    print(\"Creating combined NAICS mapping...\")\n",
    "    \n",
    "    # OPTIMIZATION: Vectorized cleaning instead of iterrows()\n",
    "    snowflake_df = naics_crosswalk_df.copy()\n",
    "    \n",
    "    # Clean all columns at once\n",
    "    for col in ['NAICS_2017', 'NAICS_2022', 'NAICS_Title_2017', 'NAICS_Title_2022']:\n",
    "        if col in snowflake_df.columns:\n",
    "            snowflake_df[f'{col}_clean'] = (\n",
    "                snowflake_df[col]\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .replace(['0', 'nan', 'NaN', ''], None)\n",
    "            )\n",
    "    \n",
    "    # OPTIMIZATION: Process 2017 codes vectorized\n",
    "    snowflake_mapping = {}\n",
    "    \n",
    "    # 2017 mappings\n",
    "    valid_2017_mask = (\n",
    "        snowflake_df['NAICS_2017_clean'].notna() & \n",
    "        snowflake_df['NAICS_Title_2017_clean'].notna()\n",
    "    )\n",
    "    \n",
    "    if valid_2017_mask.any():\n",
    "        valid_2017 = snowflake_df[valid_2017_mask]\n",
    "        mapping_2017 = dict(zip(valid_2017['NAICS_2017_clean'], valid_2017['NAICS_Title_2017_clean']))\n",
    "        snowflake_mapping.update(mapping_2017)\n",
    "    \n",
    "    # 2022 mappings (only add if not already present)\n",
    "    valid_2022_mask = (\n",
    "        snowflake_df['NAICS_2022_clean'].notna() & \n",
    "        snowflake_df['NAICS_Title_2022_clean'].notna()\n",
    "    )\n",
    "    \n",
    "    if valid_2022_mask.any():\n",
    "        valid_2022 = snowflake_df[valid_2022_mask]\n",
    "        \n",
    "        # Only add codes not already in snowflake_mapping\n",
    "        new_2022_codes = ~valid_2022['NAICS_2022_clean'].isin(snowflake_mapping.keys())\n",
    "        if new_2022_codes.any():\n",
    "            new_2022_df = valid_2022[new_2022_codes]\n",
    "            mapping_2022 = dict(zip(new_2022_df['NAICS_2022_clean'], new_2022_df['NAICS_Title_2022_clean']))\n",
    "            snowflake_mapping.update(mapping_2022)\n",
    "    \n",
    "    # Load Excel fallback mapping\n",
    "    excel_mapping = load_excel_naics_crosswalk(excel_crosswalk_path)\n",
    "    \n",
    "    # OPTIMIZATION: Efficient combination using set operations\n",
    "    combined_mapping = snowflake_mapping.copy()\n",
    "    \n",
    "    # Add Excel codes that aren't in Snowflake\n",
    "    snowflake_codes = set(combined_mapping.keys())\n",
    "    excel_only_codes = set(excel_mapping.keys()) - snowflake_codes\n",
    "    excel_only_count = len(excel_only_codes)\n",
    "    \n",
    "    for code in excel_only_codes:\n",
    "        combined_mapping[code] = excel_mapping[code]\n",
    "    \n",
    "    # OPTIMIZATION: Pre-defined sector mappings with consolidation rules\n",
    "    SECTOR_MAPPINGS = {\n",
    "        '11': 'Agriculture, Forestry, Fishing and Hunting',\n",
    "        '21': 'Mining, Quarrying, and Oil and Gas Extraction',\n",
    "        '22': 'Utilities',\n",
    "        '23': 'Construction',\n",
    "        '31': 'Manufacturing',  # Consolidated: includes 31, 32, 33, 3M\n",
    "        '42': 'Wholesale Trade',\n",
    "        '44': 'Retail Trade',   # Consolidated: includes 44, 45\n",
    "        '48': 'Transportation and Warehousing',  # Consolidated: includes 48, 49\n",
    "        '51': 'Information',\n",
    "        '52': 'Finance and Insurance',\n",
    "        '53': 'Real Estate and Rental and Leasing',\n",
    "        '54': 'Professional, Scientific, and Technical Services',\n",
    "        '55': 'Management of Companies and Enterprises',\n",
    "        '56': 'Administrative and Support and Waste Management Services',\n",
    "        '61': 'Educational Services',\n",
    "        '62': 'Health Care and Social Assistance',\n",
    "        '71': 'Arts, Entertainment, and Recreation',\n",
    "        '72': 'Accommodation and Food Services',\n",
    "        '81': 'Other Services (except Public Administration)',\n",
    "        '92': 'Public Administration'\n",
    "    }\n",
    "    \n",
    "    # Add sector mappings only if not already present\n",
    "    existing_codes = set(combined_mapping.keys())\n",
    "    missing_sectors = set(SECTOR_MAPPINGS.keys()) - existing_codes\n",
    "    sector_added_count = len(missing_sectors)\n",
    "    \n",
    "    for code in missing_sectors:\n",
    "        combined_mapping[code] = SECTOR_MAPPINGS[code]\n",
    "    \n",
    "    # CONSOLIDATION: Map the variants to consolidated codes\n",
    "    consolidation_mappings = {\n",
    "        '32': ('31', 'Manufacturing'),\n",
    "        '33': ('31', 'Manufacturing'), \n",
    "        '3M': ('31', 'Manufacturing'),\n",
    "        '45': ('44', 'Retail Trade'),\n",
    "        '49': ('48', 'Transportation and Warehousing')\n",
    "    }\n",
    "    \n",
    "    consolidation_added_count = 0\n",
    "    for old_code, (new_code, title) in consolidation_mappings.items():\n",
    "        if old_code not in combined_mapping:\n",
    "            combined_mapping[old_code] = title\n",
    "            consolidation_added_count += 1\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Combined NAICS crosswalk created: {len(combined_mapping)} total codes\")\n",
    "    print(f\"  - From Snowflake: {len(snowflake_mapping)} codes\")\n",
    "    print(f\"  - From Excel (additional): {excel_only_count} codes\")\n",
    "    print(f\"  - From 2-digit sectors (additional): {sector_added_count} codes\")\n",
    "    print(f\"  - Consolidation mappings added: {consolidation_added_count} codes\")\n",
    "    print(\"  - Consolidation rules: 32/33/3M→31, 45→44, 49→48\")\n",
    "    \n",
    "    return combined_mapping\n",
    "\n",
    "def get_naics_info_with_fallback(indnaics_code, combined_naics_mapping):\n",
    "    \"\"\"OPTIMIZED: Get NAICS title with efficient string operations and sector consolidation\"\"\"\n",
    "    \n",
    "    # OPTIMIZATION: Early returns for common cases\n",
    "    if not indnaics_code or pd.isna(indnaics_code):\n",
    "        return 'Unclassified', 'Unclassified'\n",
    "    \n",
    "    # Convert to string once\n",
    "    code_str = str(indnaics_code).strip()\n",
    "    \n",
    "    # OPTIMIZATION: Fast check for unclassified codes\n",
    "    if not code_str or code_str in {'0', 'nan', 'NaN'} or code_str.startswith('99'):\n",
    "        return 'Unclassified', 'Unclassified'\n",
    "    \n",
    "    # SECTOR CONSOLIDATION: Apply 2-digit consolidation rules (3+ digits unaffected)\n",
    "    if len(code_str) == 2:\n",
    "        if code_str in ['32', '33', '3M']:  # Manufacturing consolidation\n",
    "            code_str = '31'\n",
    "        elif code_str == '45':  # Retail consolidation\n",
    "            code_str = '44'\n",
    "        elif code_str == '49':  # Transportation consolidation\n",
    "            code_str = '48'\n",
    "    \n",
    "    # OPTIMIZATION: Direct lookup first (most common case)\n",
    "    if code_str in combined_naics_mapping:\n",
    "        return code_str, combined_naics_mapping[code_str]\n",
    "    \n",
    "    # OPTIMIZATION: Generate test codes more efficiently\n",
    "    test_codes = []\n",
    "    \n",
    "    # Handle decimal points\n",
    "    if '.' in code_str:\n",
    "        clean_code = code_str.split('.')[0]\n",
    "        if clean_code != code_str:\n",
    "            test_codes.append(clean_code)\n",
    "    \n",
    "    # Handle numeric codes with leading zeros\n",
    "    if code_str.isdigit() and len(code_str) > 1:\n",
    "        int_code = str(int(code_str))\n",
    "        if int_code != code_str:\n",
    "            test_codes.append(int_code)\n",
    "    \n",
    "    # Generate truncated versions efficiently\n",
    "    if len(code_str) > 2:\n",
    "        for length in [5, 4, 3, 2]:\n",
    "            if len(code_str) > length:\n",
    "                truncated = code_str[:length]\n",
    "                # Apply consolidation to truncated 2-digit codes\n",
    "                if len(truncated) == 2:\n",
    "                    if truncated in ['32', '33', '3M']:\n",
    "                        truncated = '31'\n",
    "                    elif truncated == '45':\n",
    "                        truncated = '44'\n",
    "                    elif truncated == '49':\n",
    "                        truncated = '48'\n",
    "                \n",
    "                if truncated not in test_codes:\n",
    "                    test_codes.append(truncated)\n",
    "    \n",
    "    # OPTIMIZATION: Check all test codes efficiently\n",
    "    for test_code in test_codes:\n",
    "        if test_code in combined_naics_mapping:\n",
    "            return code_str, combined_naics_mapping[test_code]\n",
    "    \n",
    "    # If not found, return with ACS prefix\n",
    "    return code_str, f'ACS INDNAICS {code_str}'\n",
    "\n",
    "def initialize_naics_mapping(naics_crosswalk_df, excel_crosswalk_path):\n",
    "    \"\"\"Initialize the NAICS mapping with error handling and validation\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Initializing NAICS mapping...\")\n",
    "        \n",
    "        # Validate inputs\n",
    "        if naics_crosswalk_df is None or len(naics_crosswalk_df) == 0:\n",
    "            print(\"Warning: No Snowflake crosswalk data provided\")\n",
    "            naics_crosswalk_df = pd.DataFrame()  # Empty DataFrame\n",
    "        \n",
    "        # Create the mapping\n",
    "        naics_mapping = create_combined_naics_mapping(naics_crosswalk_df, excel_crosswalk_path)\n",
    "        \n",
    "        if len(naics_mapping) == 0:\n",
    "            print(\"Error: No NAICS mappings created. Check your input files.\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"NAICS mapping initialized successfully: {len(naics_mapping)} codes available\")\n",
    "        return naics_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing NAICS mapping: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3784dcb8-b08e-475f-906e-c3178285f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Occupation Crosswalk\n",
    "# ============================================================================\n",
    "\n",
    "def create_occupation_crosswalk(acs_onet, onet_soc2019):\n",
    "    \"\"\"Create ACS OCCSOC → Full SOC 2019 hierarchy mapping using ONET join\"\"\"\n",
    "    print(\"Creating occupation crosswalk...\")\n",
    "\n",
    "    # Validate input columns\n",
    "    required_acs_cols = ['SOC_2019_5_ACS', 'ONET_2019']\n",
    "    required_onet_cols = ['ONET_2019', 'SOC_2019_2', 'SOC_2019_2_NAME', 'SOC_2019_3',\n",
    "                          'SOC_2019_3_NAME', 'SOC_2019_4', 'SOC_2019_4_NAME',\n",
    "                          'SOC_2019_5', 'SOC_2019_5_NAME']\n",
    "    \n",
    "    for col in required_acs_cols:\n",
    "        if col not in acs_onet.columns:\n",
    "            raise ValueError(f\"Missing required column in acs_onet: {col}\")\n",
    "    for col in required_onet_cols:\n",
    "        if col not in onet_soc2019.columns:\n",
    "            raise ValueError(f\"Missing required column in onet_soc2019: {col}\")\n",
    "    \n",
    "    # Clean ONET_2019 columns\n",
    "    acs_onet['ONET_2019'] = acs_onet['ONET_2019'].astype(str).str.strip()\n",
    "    onet_soc2019['ONET_2019'] = onet_soc2019['ONET_2019'].astype(str).str.strip()\n",
    "\n",
    "    # Merge to get full SOC hierarchy\n",
    "    merged = acs_onet.merge(\n",
    "        onet_soc2019,\n",
    "        on='ONET_2019',\n",
    "        how='left',\n",
    "        validate='many_to_one'\n",
    "    )\n",
    "\n",
    "    # Clean ACS code key\n",
    "    merged['SOC_2019_5_ACS'] = merged['SOC_2019_5_ACS'].astype(str).str.strip()\n",
    "\n",
    "    # Build mapping from ACS 6-digit code to full SOC hierarchy\n",
    "    soc_mapping = {}\n",
    "    for _, row in merged.iterrows():\n",
    "        acs_code = row['SOC_2019_5_ACS']\n",
    "        if pd.isna(acs_code) or not acs_code:\n",
    "            continue\n",
    "        \n",
    "        soc5 = str(row['SOC_2019_5']).strip()\n",
    "\n",
    "        if '-' in soc5 and len(soc5) == 7:\n",
    "            # Correct 7-character SOC code, like \"17-2011\"\n",
    "            soc2 = soc5[:2]\n",
    "            soc3 = soc5[:4]\n",
    "            soc4 = soc5[:5] + '0'  # Always pad SOC-4 with final 0\n",
    "        else:\n",
    "            soc2, soc3, soc4 = 'Unclassified', 'Unclassified', 'Unclassified'\n",
    "        \n",
    "        soc_mapping[acs_code] = {\n",
    "            'soc2_code': soc2,\n",
    "            'soc2_title': row['SOC_2019_2_NAME'],\n",
    "            'soc3_code': soc3,\n",
    "            'soc3_title': row['SOC_2019_3_NAME'],\n",
    "            'soc4_code': soc4,\n",
    "            'soc4_title': row['SOC_2019_4_NAME'],\n",
    "            'soc5_code': soc5,\n",
    "            'soc5_title': row['SOC_2019_5_NAME']\n",
    "        }\n",
    "\n",
    "    print(f\"✓ Created {len(soc_mapping):,} ACS SOC → SOC 2019 mappings\")\n",
    "    return soc_mapping\n",
    "\n",
    "\n",
    "def create_soc_level_summary(occ_mapping):\n",
    "    \"\"\"Create summary of available SOC levels\"\"\"\n",
    "    \n",
    "    if not occ_mapping:\n",
    "        return {}\n",
    "    \n",
    "    soc_levels = ['soc2_code', 'soc3_code', 'soc4_code', 'soc5_code', 'soc6_code']\n",
    "    level_summary = {}\n",
    "    \n",
    "    for level in soc_levels:\n",
    "        unique_codes = set()\n",
    "        for soc_hierarchy in occ_mapping.values():\n",
    "            code = soc_hierarchy.get(level)\n",
    "            if code and code != 'Unclassified':\n",
    "                unique_codes.add(code)\n",
    "        \n",
    "        level_summary[level] = {\n",
    "            'unique_codes': len(unique_codes),\n",
    "            'sample_codes': list(unique_codes)[:5]\n",
    "        }\n",
    "    \n",
    "    return level_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd377e4-528f-4cf1-8583-bf306d7e02d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/4177053719.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  acs_onet = pd.read_sql(combined_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Query ACS crosswalk to ONET\n",
    "combined_query = f\"\"\"\n",
    "SELECT*\n",
    "FROM\n",
    "CROSSWALKS.CUSTOM.ONET_2019_ACS_SOC_CROSSWALK\n",
    "\"\"\"\n",
    "# Execute query and get data\n",
    "acs_onet = pd.read_sql(combined_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86aef02c-bb09-45cb-b1af-7313299abfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ONET_2019</th>\n",
       "      <th>ONET_2019_NAME</th>\n",
       "      <th>SOC_2019_5_OEWS</th>\n",
       "      <th>SOC_2019_5_OEWS_NAME</th>\n",
       "      <th>SOC_2019_5_ACS</th>\n",
       "      <th>SOC_2019_5_ACS_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43-4051.00</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "      <td>43-4051</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "      <td>434051</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43-4199.00</td>\n",
       "      <td>Information and Record Clerks, All Other</td>\n",
       "      <td>43-4199</td>\n",
       "      <td>Information and Record Clerks, All Other</td>\n",
       "      <td>434XXX</td>\n",
       "      <td>Correspondent clerks and order clerks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43-4151.00</td>\n",
       "      <td>Order Clerks</td>\n",
       "      <td>43-4151</td>\n",
       "      <td>Order Clerks</td>\n",
       "      <td>434XXX</td>\n",
       "      <td>Correspondent clerks and order clerks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43-4021.00</td>\n",
       "      <td>Correspondence Clerks</td>\n",
       "      <td>43-4021</td>\n",
       "      <td>Correspondence Clerks</td>\n",
       "      <td>434XXX</td>\n",
       "      <td>Correspondent clerks and order clerks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43-4011.00</td>\n",
       "      <td>Brokerage Clerks</td>\n",
       "      <td>43-4011</td>\n",
       "      <td>Brokerage Clerks</td>\n",
       "      <td>434XXX</td>\n",
       "      <td>Correspondent clerks and order clerks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>53-7062.00</td>\n",
       "      <td>Laborers and Freight, Stock, and Material Move...</td>\n",
       "      <td>53-7062</td>\n",
       "      <td>Laborers and Freight, Stock, and Material Move...</td>\n",
       "      <td>537062</td>\n",
       "      <td>Laborers and Freight, Stock, and Material Move...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>47-2061.00</td>\n",
       "      <td>Construction Laborers</td>\n",
       "      <td>47-2061</td>\n",
       "      <td>Construction Laborers</td>\n",
       "      <td>472061</td>\n",
       "      <td>Construction Laborers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>25-3041.00</td>\n",
       "      <td>Tutors</td>\n",
       "      <td>25-3041</td>\n",
       "      <td>Tutors</td>\n",
       "      <td>253041</td>\n",
       "      <td>Tutors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>35-9031.00</td>\n",
       "      <td>Hosts and Hostesses, Restaurant, Lounge, and C...</td>\n",
       "      <td>35-9031</td>\n",
       "      <td>Hosts and Hostesses, Restaurant, Lounge, and C...</td>\n",
       "      <td>359031</td>\n",
       "      <td>Host and Hostesses, Restaurant, Lounge, and Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>31-1122.00</td>\n",
       "      <td>Personal Care Aides</td>\n",
       "      <td>31-1122</td>\n",
       "      <td>Personal Care Aides</td>\n",
       "      <td>311122</td>\n",
       "      <td>Personal Care Aides</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ONET_2019                                     ONET_2019_NAME  \\\n",
       "0     43-4051.00                   Customer Service Representatives   \n",
       "1     43-4199.00           Information and Record Clerks, All Other   \n",
       "2     43-4151.00                                       Order Clerks   \n",
       "3     43-4021.00                              Correspondence Clerks   \n",
       "4     43-4011.00                                   Brokerage Clerks   \n",
       "...          ...                                                ...   \n",
       "1040  53-7062.00  Laborers and Freight, Stock, and Material Move...   \n",
       "1041  47-2061.00                              Construction Laborers   \n",
       "1042  25-3041.00                                             Tutors   \n",
       "1043  35-9031.00  Hosts and Hostesses, Restaurant, Lounge, and C...   \n",
       "1044  31-1122.00                                Personal Care Aides   \n",
       "\n",
       "     SOC_2019_5_OEWS                               SOC_2019_5_OEWS_NAME  \\\n",
       "0            43-4051                   Customer Service Representatives   \n",
       "1            43-4199           Information and Record Clerks, All Other   \n",
       "2            43-4151                                       Order Clerks   \n",
       "3            43-4021                              Correspondence Clerks   \n",
       "4            43-4011                                   Brokerage Clerks   \n",
       "...              ...                                                ...   \n",
       "1040         53-7062  Laborers and Freight, Stock, and Material Move...   \n",
       "1041         47-2061                              Construction Laborers   \n",
       "1042         25-3041                                             Tutors   \n",
       "1043         35-9031  Hosts and Hostesses, Restaurant, Lounge, and C...   \n",
       "1044         31-1122                                Personal Care Aides   \n",
       "\n",
       "     SOC_2019_5_ACS                                SOC_2019_5_ACS_NAME  \n",
       "0            434051                   Customer Service Representatives  \n",
       "1            434XXX              Correspondent clerks and order clerks  \n",
       "2            434XXX              Correspondent clerks and order clerks  \n",
       "3            434XXX              Correspondent clerks and order clerks  \n",
       "4            434XXX              Correspondent clerks and order clerks  \n",
       "...             ...                                                ...  \n",
       "1040         537062  Laborers and Freight, Stock, and Material Move...  \n",
       "1041         472061                              Construction Laborers  \n",
       "1042         253041                                             Tutors  \n",
       "1043         359031  Host and Hostesses, Restaurant, Lounge, and Co...  \n",
       "1044         311122                                Personal Care Aides  \n",
       "\n",
       "[1045 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_onet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55b8200d-c517-4b40-8b8f-6f4e67464563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/3848419268.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  onet_soc2019 = pd.read_sql(combined_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Query ONET 2019 to SOC 2019\n",
    "combined_query = f\"\"\"\n",
    "SELECT*\n",
    "FROM\n",
    "CROSSWALKS.CUSTOM.ONET_2019_SOC_2019_CROSSWALK_FULL\n",
    "\"\"\"\n",
    "# Execute query and get data\n",
    "onet_soc2019 = pd.read_sql(combined_query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7d8acd-124d-4cbb-b15e-b593ba356f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOC_2019_2</th>\n",
       "      <th>SOC_2019_2_NAME</th>\n",
       "      <th>SOC_2019_3</th>\n",
       "      <th>SOC_2019_3_NAME</th>\n",
       "      <th>SOC_2019_4</th>\n",
       "      <th>SOC_2019_4_NAME</th>\n",
       "      <th>SOC_2019_5</th>\n",
       "      <th>SOC_2019_5_NAME</th>\n",
       "      <th>ONET_2019</th>\n",
       "      <th>ONET_2019_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55-0000</td>\n",
       "      <td>Military Specific Occupations</td>\n",
       "      <td>55-3000</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3010</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3019</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3019.00</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55-0000</td>\n",
       "      <td>Military Specific Occupations</td>\n",
       "      <td>55-3000</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3010</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3018</td>\n",
       "      <td>Special Forces</td>\n",
       "      <td>55-3018.00</td>\n",
       "      <td>Special Forces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55-0000</td>\n",
       "      <td>Military Specific Occupations</td>\n",
       "      <td>55-3000</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3010</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3016</td>\n",
       "      <td>Infantry</td>\n",
       "      <td>55-3016.00</td>\n",
       "      <td>Infantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55-0000</td>\n",
       "      <td>Military Specific Occupations</td>\n",
       "      <td>55-3000</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3010</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>55-3015</td>\n",
       "      <td>Command and Control Center Specialists</td>\n",
       "      <td>55-3015.00</td>\n",
       "      <td>Command and Control Center Specialists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-2000</td>\n",
       "      <td>Advertising, Marketing, Promotions, Public Rel...</td>\n",
       "      <td>11-2020</td>\n",
       "      <td>Marketing and Sales Managers</td>\n",
       "      <td>11-2021</td>\n",
       "      <td>Marketing Managers</td>\n",
       "      <td>11-2021.00</td>\n",
       "      <td>Marketing Managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-2000</td>\n",
       "      <td>Advertising, Marketing, Promotions, Public Rel...</td>\n",
       "      <td>11-2010</td>\n",
       "      <td>Advertising and Promotions Managers</td>\n",
       "      <td>11-2011</td>\n",
       "      <td>Advertising and Promotions Managers</td>\n",
       "      <td>11-2011.00</td>\n",
       "      <td>Advertising and Promotions Managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1030</td>\n",
       "      <td>Legislators</td>\n",
       "      <td>11-1031</td>\n",
       "      <td>Legislators</td>\n",
       "      <td>11-1031.00</td>\n",
       "      <td>Legislators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1020</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>11-1021.00</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011.03</td>\n",
       "      <td>Chief Sustainability Officers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SOC_2019_2                SOC_2019_2_NAME SOC_2019_3  \\\n",
       "0       11-0000         Management Occupations    11-1000   \n",
       "1       55-0000  Military Specific Occupations    55-3000   \n",
       "2       55-0000  Military Specific Occupations    55-3000   \n",
       "3       55-0000  Military Specific Occupations    55-3000   \n",
       "4       55-0000  Military Specific Occupations    55-3000   \n",
       "...         ...                            ...        ...   \n",
       "1011    11-0000         Management Occupations    11-2000   \n",
       "1012    11-0000         Management Occupations    11-2000   \n",
       "1013    11-0000         Management Occupations    11-1000   \n",
       "1014    11-0000         Management Occupations    11-1000   \n",
       "1015    11-0000         Management Occupations    11-1000   \n",
       "\n",
       "                                        SOC_2019_3_NAME SOC_2019_4  \\\n",
       "0                                        Top Executives    11-1010   \n",
       "1     Military Enlisted Tactical Operations and Air/...    55-3010   \n",
       "2     Military Enlisted Tactical Operations and Air/...    55-3010   \n",
       "3     Military Enlisted Tactical Operations and Air/...    55-3010   \n",
       "4     Military Enlisted Tactical Operations and Air/...    55-3010   \n",
       "...                                                 ...        ...   \n",
       "1011  Advertising, Marketing, Promotions, Public Rel...    11-2020   \n",
       "1012  Advertising, Marketing, Promotions, Public Rel...    11-2010   \n",
       "1013                                     Top Executives    11-1030   \n",
       "1014                                     Top Executives    11-1020   \n",
       "1015                                     Top Executives    11-1010   \n",
       "\n",
       "                                        SOC_2019_4_NAME SOC_2019_5  \\\n",
       "0                                      Chief Executives    11-1011   \n",
       "1     Military Enlisted Tactical Operations and Air/...    55-3019   \n",
       "2     Military Enlisted Tactical Operations and Air/...    55-3018   \n",
       "3     Military Enlisted Tactical Operations and Air/...    55-3016   \n",
       "4     Military Enlisted Tactical Operations and Air/...    55-3015   \n",
       "...                                                 ...        ...   \n",
       "1011                       Marketing and Sales Managers    11-2021   \n",
       "1012                Advertising and Promotions Managers    11-2011   \n",
       "1013                                        Legislators    11-1031   \n",
       "1014                    General and Operations Managers    11-1021   \n",
       "1015                                   Chief Executives    11-1011   \n",
       "\n",
       "                                        SOC_2019_5_NAME   ONET_2019  \\\n",
       "0                                      Chief Executives  11-1011.00   \n",
       "1     Military Enlisted Tactical Operations and Air/...  55-3019.00   \n",
       "2                                        Special Forces  55-3018.00   \n",
       "3                                              Infantry  55-3016.00   \n",
       "4                Command and Control Center Specialists  55-3015.00   \n",
       "...                                                 ...         ...   \n",
       "1011                                 Marketing Managers  11-2021.00   \n",
       "1012                Advertising and Promotions Managers  11-2011.00   \n",
       "1013                                        Legislators  11-1031.00   \n",
       "1014                    General and Operations Managers  11-1021.00   \n",
       "1015                                   Chief Executives  11-1011.03   \n",
       "\n",
       "                                         ONET_2019_NAME  \n",
       "0                                      Chief Executives  \n",
       "1     Military Enlisted Tactical Operations and Air/...  \n",
       "2                                        Special Forces  \n",
       "3                                              Infantry  \n",
       "4                Command and Control Center Specialists  \n",
       "...                                                 ...  \n",
       "1011                                 Marketing Managers  \n",
       "1012                Advertising and Promotions Managers  \n",
       "1013                                        Legislators  \n",
       "1014                    General and Operations Managers  \n",
       "1015                      Chief Sustainability Officers  \n",
       "\n",
       "[1016 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onet_soc2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7483b3e4-543c-49c7-aa29-dfa3fc4f2943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NAICS mapping...\n",
      "Creating combined NAICS mapping...\n",
      "Loading Excel crosswalk from indnaics_crosswalk_2023.xlsx...\n",
      "Excel NAICS crosswalk loaded: 265 codes\n",
      "Combined NAICS crosswalk created: 1439 total codes\n",
      "  - From Snowflake: 1151 codes\n",
      "  - From Excel (additional): 265 codes\n",
      "  - From 2-digit sectors (additional): 18 codes\n",
      "  - Consolidation mappings added: 5 codes\n",
      "  - Consolidation rules: 32/33/3M→31, 45→44, 49→48\n",
      "NAICS mapping initialized successfully: 1439 codes available\n",
      "Creating occupation crosswalk...\n",
      "✓ Created 528 ACS SOC → SOC 2019 mappings\n",
      "Enhancing NAICS mapping with 2017 and 2022 crosswalks...\n",
      "✓ Enhanced NAICS mapping: 3625 codes (2186 added)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD CROSSWALKS WITH FALLBACK\n",
    "# ============================================================================\n",
    "\n",
    "# Usage example (assuming NAICS_CROSSWALK DataFrame exists):\n",
    "EXCEL_CROSSWALK_PATH = \"indnaics_crosswalk_2023.xlsx\"\n",
    "NAICS_MAPPING = initialize_naics_mapping(NAICS_CROSSWALK, EXCEL_CROSSWALK_PATH)\n",
    "SOC_MAPPING = create_occupation_crosswalk(acs_onet, onet_soc2019)\n",
    "\n",
    "\n",
    "# ADD THIS: Enhance with 2017 and 2022 crosswalks\n",
    "print(\"Enhancing NAICS mapping with 2017 and 2022 crosswalks...\")\n",
    "initial_count = len(NAICS_MAPPING)\n",
    "\n",
    "# Add 2017 codes\n",
    "naics_levels = ['NAICS2', 'NAICS3', 'NAICS4', 'NAICS5', 'NAICS6']\n",
    "title_levels = ['NAICS2_NAME', 'NAICS3_NAME', 'NAICS4_NAME', 'NAICS5_NAME', 'NAICS6_NAME']\n",
    "\n",
    "for code_col, title_col in zip(naics_levels, title_levels):\n",
    "    if code_col in NAICS_CROSSWALK_2017.columns and title_col in NAICS_CROSSWALK_2017.columns:\n",
    "        valid_2017 = NAICS_CROSSWALK_2017[\n",
    "            NAICS_CROSSWALK_2017[code_col].notna() & \n",
    "            NAICS_CROSSWALK_2017[title_col].notna()\n",
    "        ]\n",
    "        for idx, row in valid_2017.iterrows():\n",
    "            code = str(row[code_col]).strip()\n",
    "            title = str(row[title_col]).strip()\n",
    "            if code and title and code not in NAICS_MAPPING:\n",
    "                NAICS_MAPPING[code] = title\n",
    "\n",
    "# Add 2022 codes\n",
    "for code_col, title_col in zip(naics_levels, title_levels):\n",
    "    if code_col in NAICS_CROSSWALK_2022.columns and title_col in NAICS_CROSSWALK_2022.columns:\n",
    "        valid_2022 = NAICS_CROSSWALK_2022[\n",
    "            NAICS_CROSSWALK_2022[code_col].notna() & \n",
    "            NAICS_CROSSWALK_2022[title_col].notna()\n",
    "        ]\n",
    "        for idx, row in valid_2022.iterrows():\n",
    "            code = str(row[code_col]).strip()\n",
    "            title = str(row[title_col]).strip()\n",
    "            if code and title and code not in NAICS_MAPPING:\n",
    "                NAICS_MAPPING[code] = title\n",
    "\n",
    "print(f\"✓ Enhanced NAICS mapping: {len(NAICS_MAPPING)} codes ({len(NAICS_MAPPING) - initial_count} added)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d0c95c1-d6ee-4d4f-9a82-8cc28c6b2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "POPULATION_BUCKETS = [\n",
    "    (0, 25000, '0-25K'),\n",
    "    (25000, 50000, '25K-50K'),\n",
    "    (50000, 75000, '50K-75K'),\n",
    "    (75000, 100000, '75K-100K'),\n",
    "    (100000, 1000000, '100K-1M'),\n",
    "    (1000000, float('inf'), '1M+')\n",
    "]\n",
    "\n",
    "BUCKET_ORDER = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "NAICS_LEVELS = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "SOC_LEVELS = ['soc_2digit', 'soc_3digit', 'soc_4digit', 'soc_5digit', 'soc_6digit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "146613e0-b29a-4672-9789-e490967d6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(csv_path):\n",
    "    \"\"\"Load and do basic data preparation\"\"\"\n",
    "    print(f\"Loading data from {csv_path}...\")\n",
    "    df = pd.read_csv(csv_path, compression='gzip')\n",
    "    print(f\"Loaded {len(df):,} records\")\n",
    "    \n",
    "    # Basic data cleaning\n",
    "    df['INDNAICS'] = df['INDNAICS'].fillna('0').astype(str).str.strip()\n",
    "    df['OCCSOC'] = df['OCCSOC'].fillna('0').astype(str).str.strip()\n",
    "    \n",
    "    # Fix float-like strings\n",
    "    float_mask = df['INDNAICS'].str.contains(r'\\.0$', na=False)\n",
    "    if float_mask.any():\n",
    "        df.loc[float_mask, 'INDNAICS'] = df.loc[float_mask, 'INDNAICS'].str.replace('.0', '', regex=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d68878-8562-4109-80f4-8fd1970d195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from usa_00052.csv.gz...\n",
      "Loaded 15,912,393 records\n"
     ]
    }
   ],
   "source": [
    "df = load_and_prepare_data(\"usa_00052.csv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d33a5756-0f73-4b48-988c-93d94825c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/1664825217.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['county_fips'] = df_valid['STATEFIP'].astype(int).astype(str).str.zfill(2) + \\\n"
     ]
    }
   ],
   "source": [
    "# Combine STATEFIP and COUNTYICP to form unique county identifiers\n",
    "df_valid = df[df['COUNTYICP'].notna() & (df['COUNTYICP'] != 0)]\n",
    "\n",
    "# Create a full county FIPS code\n",
    "df_valid['county_fips'] = df_valid['STATEFIP'].astype(int).astype(str).str.zfill(2) + \\\n",
    "                          df_valid['COUNTYICP'].astype(int).astype(str).str.zfill(3)\n",
    "\n",
    "# Calculate population by county_fips\n",
    "county_pop = (\n",
    "    df_valid\n",
    "    .groupby('county_fips')['PERWT']\n",
    "    .sum()\n",
    "    .reset_index(name='population')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f01b44b-c6ae-4831-b741-312de006b200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of counties with population ≥ 1 million: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>06370</td>\n",
       "      <td>9846959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>17310</td>\n",
       "      <td>5185799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>482010</td>\n",
       "      <td>4758253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04130</td>\n",
       "      <td>4491638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>06730</td>\n",
       "      <td>3283122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>06590</td>\n",
       "      <td>3164099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>36470</td>\n",
       "      <td>2643951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>481130</td>\n",
       "      <td>2603698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>06650</td>\n",
       "      <td>2450683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>36810</td>\n",
       "      <td>2328854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>32030</td>\n",
       "      <td>2293694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>53330</td>\n",
       "      <td>2263027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>06710</td>\n",
       "      <td>2188283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>484390</td>\n",
       "      <td>2135529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>48290</td>\n",
       "      <td>2037473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>12110</td>\n",
       "      <td>1945855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>06850</td>\n",
       "      <td>1903896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>261630</td>\n",
       "      <td>1773662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>06010</td>\n",
       "      <td>1651990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>36610</td>\n",
       "      <td>1627676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>25170</td>\n",
       "      <td>1622360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>06670</td>\n",
       "      <td>1583592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>421010</td>\n",
       "      <td>1583276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>361030</td>\n",
       "      <td>1525348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>12990</td>\n",
       "      <td>1507394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>12570</td>\n",
       "      <td>1489526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>12950</td>\n",
       "      <td>1438679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>36050</td>\n",
       "      <td>1416267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>36590</td>\n",
       "      <td>1388617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>39490</td>\n",
       "      <td>1321231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>484530</td>\n",
       "      <td>1308105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>261250</td>\n",
       "      <td>1271941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>27530</td>\n",
       "      <td>1268135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>39350</td>\n",
       "      <td>1249199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>42030</td>\n",
       "      <td>1239704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>49350</td>\n",
       "      <td>1184531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>06130</td>\n",
       "      <td>1161231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>371830</td>\n",
       "      <td>1151251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>371190</td>\n",
       "      <td>1130909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>48850</td>\n",
       "      <td>1116565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>131210</td>\n",
       "      <td>1067768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>24310</td>\n",
       "      <td>1057422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>06190</td>\n",
       "      <td>1011642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>12310</td>\n",
       "      <td>1007850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>15030</td>\n",
       "      <td>1003612.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county_fips  population\n",
       "25        06370   9846959.0\n",
       "126       17310   5185799.0\n",
       "374      482010   4758253.0\n",
       "7         04130   4491638.0\n",
       "35        06730   3283122.0\n",
       "30        06590   3164099.0\n",
       "257       36470   2643951.0\n",
       "365      481130   2603698.0\n",
       "32        06650   2450683.0\n",
       "264       36810   2328854.0\n",
       "229       32030   2293694.0\n",
       "420       53330   2263027.0\n",
       "34        06710   2188283.0\n",
       "393      484390   2135529.0\n",
       "381       48290   2037473.0\n",
       "66        12110   1945855.0\n",
       "41        06850   1903896.0\n",
       "199      261630   1773662.0\n",
       "13        06010   1651990.0\n",
       "260       36610   1627676.0\n",
       "186       25170   1622360.0\n",
       "33        06670   1583592.0\n",
       "324      421010   1583276.0\n",
       "252      361030   1525348.0\n",
       "92        12990   1507394.0\n",
       "81        12570   1489526.0\n",
       "90        12950   1438679.0\n",
       "251       36050   1416267.0\n",
       "259       36590   1388617.0\n",
       "305       39490   1321231.0\n",
       "396      484530   1308105.0\n",
       "194      261250   1271941.0\n",
       "214       27530   1268135.0\n",
       "302       39350   1249199.0\n",
       "323       42030   1239704.0\n",
       "404       49350   1184531.0\n",
       "18        06130   1161231.0\n",
       "277      371830   1151251.0\n",
       "272      371190   1130909.0\n",
       "401       48850   1116565.0\n",
       "95       131210   1067768.0\n",
       "179       24310   1057422.0\n",
       "20        06190   1011642.0\n",
       "77        12310   1007850.0\n",
       "116       15030   1003612.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Filter counties with population over 1 million\n",
    "high_pop_counties = county_pop[county_pop['population'] >= 1_000_000]\n",
    "\n",
    "# Count how many counties meet that threshold\n",
    "num_high_pop_counties = len(high_pop_counties)\n",
    "\n",
    "# Display\n",
    "print(f\"Number of counties with population ≥ 1 million: {num_high_pop_counties}\")\n",
    "display(high_pop_counties.sort_values(by='population', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb69d817-a0a6-49f4-9ae3-cfe61134f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_naics_consolidation(naics_code):\n",
    "    \"\"\"\n",
    "    Apply NAICS 2-digit consolidation rules to standardize industry groupings.\n",
    "    \n",
    "    Consolidation rules:\n",
    "    - Manufacturing: 31, 32, 33, 3M → 31\n",
    "    - Retail Trade: 44, 45 → 44  \n",
    "    - Transportation: 48, 49 → 48\n",
    "    - 3+ digit codes are unchanged\n",
    "    \"\"\"\n",
    "    \n",
    "    if not naics_code or pd.isna(naics_code):\n",
    "        return naics_code\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    code_str = str(naics_code).strip()\n",
    "    \n",
    "    # Only apply consolidation to 2-digit codes\n",
    "    if len(code_str) == 2:\n",
    "        if code_str in ['32', '33', '3M']:  # Manufacturing consolidation\n",
    "            return '31'\n",
    "        elif code_str == '45':  # Retail consolidation  \n",
    "            return '44'\n",
    "        elif code_str == '49':  # Transportation consolidation\n",
    "            return '48'\n",
    "    \n",
    "    # Return original code for all other cases (3+ digits, other 2-digits, etc.)\n",
    "    return code_str\n",
    "\n",
    "def add_classifications(df):\n",
    "    \"\"\"Add NAICS and SOC classification columns + titles to dataframe with NAICS consolidation.\"\"\"\n",
    "    print(\"  Processing NAICS with consolidation...\")\n",
    "\n",
    "    # Flag unclassified NAICS codes\n",
    "    naics_unclassified_mask = (\n",
    "        (df['INDNAICS'] == '0') |\n",
    "        (df['INDNAICS'] == '') |\n",
    "        (df['INDNAICS'].astype(str).str.startswith('99', na=False))\n",
    "    )\n",
    "\n",
    "    # Initialize NAICS levels\n",
    "    for level in ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']:\n",
    "        df[level] = 'Unclassified'\n",
    "\n",
    "    # Apply valid NAICS slicing WITH CONSOLIDATION\n",
    "    naics_classified_df = df[~naics_unclassified_mask].copy()\n",
    "    if len(naics_classified_df) > 0:\n",
    "        full_codes = naics_classified_df['INDNAICS'].astype(str).str.strip()\n",
    "        code_lengths = full_codes.str.len()\n",
    "\n",
    "        # Process each level with consolidation for 2-digit only\n",
    "        for min_len, level in [(2, 'naics_2digit'), (3, 'naics_3digit'),\n",
    "                               (4, 'naics_4digit'), (5, 'naics_5digit'), (6, 'naics_6digit')]:\n",
    "            mask = code_lengths >= min_len\n",
    "            \n",
    "            if level == 'naics_2digit':\n",
    "                # Apply consolidation to 2-digit codes\n",
    "                codes_to_assign = full_codes[mask].str[:min_len].apply(apply_naics_consolidation)\n",
    "            else:\n",
    "                # No consolidation for 3+ digit codes\n",
    "                codes_to_assign = full_codes[mask].str[:min_len]\n",
    "            \n",
    "            df.loc[naics_classified_df.index[mask], level] = codes_to_assign\n",
    "\n",
    "    # Show consolidation results\n",
    "    consolidation_counts = {}\n",
    "    if len(naics_classified_df) > 0:\n",
    "        for old_code in ['32', '33', '3M']:\n",
    "            count = (naics_classified_df['INDNAICS'].astype(str).str[:2] == old_code).sum()\n",
    "            if count > 0:\n",
    "                consolidation_counts[f'{old_code}→31'] = count\n",
    "        \n",
    "        for old_code in ['45']:\n",
    "            count = (naics_classified_df['INDNAICS'].astype(str).str[:2] == old_code).sum()\n",
    "            if count > 0:\n",
    "                consolidation_counts[f'{old_code}→44'] = count\n",
    "        \n",
    "        for old_code in ['49']:\n",
    "            count = (naics_classified_df['INDNAICS'].astype(str).str[:2] == old_code).sum()\n",
    "            if count > 0:\n",
    "                consolidation_counts[f'{old_code}→48'] = count\n",
    "        \n",
    "        if consolidation_counts:\n",
    "            print(\"  NAICS consolidation applied:\")\n",
    "            for consolidation, count in consolidation_counts.items():\n",
    "                print(f\"    {consolidation}: {count:,} records\")\n",
    "\n",
    "    # Assign NAICS titles using your NAICS_MAPPING dict\n",
    "    for level in ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']:\n",
    "        df[f\"{level}_title\"] = df[level].map(NAICS_MAPPING).fillna('Unclassified')\n",
    "\n",
    "    print(\"  Processing SOC...\")\n",
    "\n",
    "    # Flag unclassified SOC\n",
    "    soc_unclassified_mask = (\n",
    "        (df['OCCSOC'] == '0') |\n",
    "        (df['OCCSOC'] == '') |\n",
    "        (df['OCCSOC'].astype(str).str.startswith('99', na=False))\n",
    "    )\n",
    "\n",
    "    for level in ['soc_2digit', 'soc_3digit', 'soc_4digit', 'soc_5digit', 'soc_6digit']:\n",
    "        df[level] = 'Unclassified'\n",
    "        df[f\"{level}_title\"] = 'Unclassified'\n",
    "\n",
    "    soc_classified_df = df[~soc_unclassified_mask].copy()\n",
    "\n",
    "    if len(soc_classified_df) > 0 and SOC_MAPPING:\n",
    "        print(f\"    Processing {len(soc_classified_df):,} SOC records with mapping...\")\n",
    "\n",
    "        level_map = {\n",
    "            'soc2_code': 'soc_2digit',\n",
    "            'soc3_code': 'soc_3digit',\n",
    "            'soc4_code': 'soc_4digit',\n",
    "            'soc5_code': 'soc_5digit',\n",
    "            'soc6_code': 'soc_6digit'\n",
    "        }\n",
    "\n",
    "        # Create mapping dictionaries\n",
    "        soc_code_maps = {v: {} for v in level_map.values()}\n",
    "        soc_title_maps = {v: {} for v in level_map.values()}\n",
    "\n",
    "        for acs_code, soc_data in SOC_MAPPING.items():\n",
    "            for soc_key, final_col in level_map.items():\n",
    "                title_col = final_col + '_title'\n",
    "                soc_code_maps[final_col][acs_code] = soc_data.get(soc_key, 'Unclassified')\n",
    "                soc_title_maps[final_col][acs_code] = soc_data.get(soc_key.replace(\"code\", \"title\"), 'Unclassified')\n",
    "\n",
    "        occsoc_clean = soc_classified_df['OCCSOC'].astype(str).str.strip()\n",
    "\n",
    "        for col in level_map.values():\n",
    "            df.loc[soc_classified_df.index, col] = occsoc_clean.map(soc_code_maps[col]).fillna('Unclassified')\n",
    "            df.loc[soc_classified_df.index, col + '_title'] = occsoc_clean.map(soc_title_maps[col]).fillna('Unclassified')\n",
    "\n",
    "    print(\"  ✓ NAICS classifications created with consolidation\")\n",
    "    print(\"  ✓ SOC classifications created\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_employment_data(df, geo_type='PUMA'):\n",
    "    \"\"\"Filter data for employed records with valid classifications.\"\"\"\n",
    "    print(f\"\\nSTEP 3A: Filtering {geo_type} employment data...\")\n",
    "    \n",
    "    # Common employment filter\n",
    "    employed_mask = (\n",
    "        (df['EMPSTAT'] == 1) & \n",
    "        (df['INDNAICS'] != '0') & \n",
    "        (df['OCCSOC'] != '0') & \n",
    "        (df['PERWT'] > 0) &\n",
    "        (df['naics_2digit'] != 'Unclassified') &  # Must have valid NAICS\n",
    "        (df['soc_2digit'] != 'Unclassified')      # Must have valid SOC\n",
    "    )\n",
    "    \n",
    "    # Additional filters based on geography type\n",
    "    if geo_type == 'PUMA':\n",
    "        employed_mask &= (df['PUMA'] != 0)\n",
    "    \n",
    "    employed = df[employed_mask].copy()\n",
    "    \n",
    "    print(f\"✓ {geo_type} employment records with valid classifications: {len(employed):,}\")\n",
    "    print(f\"  (Filtered out INDNAICS=0 and OCCSOC=0 as unemployed/not applicable)\")\n",
    "    \n",
    "    return employed\n",
    "\n",
    "\n",
    "def add_geographic_features(employed, geo_type='PUMA', full_dataset=None):\n",
    "    \"\"\"\n",
    "    Add geographic identifiers and population buckets to employment data.\n",
    "    \n",
    "    Args:\n",
    "        employed: Filtered employment data (for analysis)\n",
    "        geo_type: 'PUMA' or 'County'  \n",
    "        full_dataset: Complete ACS data (for population bucketing). If None, uses employed data.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSTEP 3B: Adding geographic features for {geo_type}...\")\n",
    "\n",
    "    # Set geography-specific parameters\n",
    "    if geo_type == 'PUMA':\n",
    "        geo_col = 'PUMA'\n",
    "        geo_digits = 5\n",
    "    else:  # County\n",
    "        geo_col = 'COUNTYICP'\n",
    "        geo_digits = 4\n",
    "\n",
    "    # Add geographic identifiers to employment data\n",
    "    employed['geo_id'] = (\n",
    "        employed['STATEFIP'].astype(str).str.zfill(2) +\n",
    "        '_' +\n",
    "        employed[geo_col].astype(str).str.zfill(geo_digits)\n",
    "    )\n",
    "\n",
    "    # Add metro status using MET2013\n",
    "    employed['metro_status'] = np.where(\n",
    "        employed['MET2013'] == 0, 'Non-metro/Rural', 'Metropolitan'\n",
    "    )\n",
    "\n",
    "    # Choose dataset for population calculation\n",
    "    if full_dataset is not None:\n",
    "        print(f\"    Using full dataset for population bucketing (total population)...\")\n",
    "        pop_dataset = full_dataset.copy()\n",
    "        \n",
    "        # Create geo_id for full dataset\n",
    "        pop_dataset['geo_id'] = (\n",
    "            pop_dataset['STATEFIP'].astype(str).str.zfill(2) +\n",
    "            '_' +\n",
    "            pop_dataset[geo_col].astype(str).str.zfill(geo_digits)\n",
    "        )\n",
    "        \n",
    "        # Calculate TOTAL population by geographic unit\n",
    "        if geo_type == 'County':\n",
    "            identifiable = pop_dataset[pop_dataset['COUNTYICP'] != 0]\n",
    "            geo_pop = identifiable.groupby('geo_id')['PERWT'].sum() if len(identifiable) > 0 else pd.Series(dtype='float64')\n",
    "        else:\n",
    "            geo_pop = pop_dataset.groupby('geo_id')['PERWT'].sum()\n",
    "        \n",
    "        print(f\"    Total geographic units with population data: {len(geo_pop)}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"    Using employment data for population bucketing (employed population only)...\")\n",
    "        # Original logic - calculate from employment data only\n",
    "        if geo_type == 'County':\n",
    "            identifiable = employed[employed['COUNTYICP'] != 0]\n",
    "            geo_pop = identifiable.groupby('geo_id')['PERWT'].sum() if len(identifiable) > 0 else pd.Series(dtype='float64')\n",
    "        else:\n",
    "            geo_pop = employed.groupby('geo_id')['PERWT'].sum()\n",
    "\n",
    "    # Map population to employment records\n",
    "    employed['area_population'] = employed['geo_id'].map(geo_pop).fillna(0)\n",
    "\n",
    "    # Assign population buckets\n",
    "    conditions = [employed['area_population'] < bucket[1] for bucket in POPULATION_BUCKETS[:-1]]\n",
    "    choices = [bucket[2] for bucket in POPULATION_BUCKETS[:-1]]\n",
    "    employed['pop_label'] = np.select(conditions, choices, default=POPULATION_BUCKETS[-1][2])\n",
    "\n",
    "    # Special handling for unknown counties\n",
    "    if geo_type == 'County':\n",
    "        unknown_mask = employed['COUNTYICP'] == 0\n",
    "        employed.loc[unknown_mask, 'pop_label'] = 'Unknown County'\n",
    "        print(f\"    Assigned {unknown_mask.sum():,} employment records to 'Unknown County'\")\n",
    "\n",
    "    # Print summary\n",
    "    print_distribution_summary(employed, geo_type)\n",
    "\n",
    "    return employed\n",
    "\n",
    "def print_distribution_summary(employed, geo_type):\n",
    "    \"\"\"Print metro status and population bucket distributions.\"\"\"\n",
    "    print(f\"\\n{geo_type} metro status distribution (employment):\")\n",
    "    metro_dist = employed.groupby('metro_status')['PERWT'].sum()\n",
    "    total_emp = metro_dist.sum()\n",
    "    for status, emp in metro_dist.items():\n",
    "        print(f\"  {status}: {emp:,.0f} employed ({emp/total_emp*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{geo_type} population bucket distribution:\")\n",
    "    pop_dist = employed.groupby('pop_label')['PERWT'].sum().sort_index()\n",
    "    for bucket, emp in pop_dist.items():\n",
    "        # Also show how many geographic units in each bucket\n",
    "        units_in_bucket = employed[employed['pop_label'] == bucket]['geo_id'].nunique()\n",
    "        geo_label = 'counties' if geo_type == 'County' else 'PUMAs'\n",
    "        print(f\"  {bucket}: {emp:,.0f} employed in {units_in_bucket} {geo_label} ({emp/total_emp*100:.1f}%)\")\n",
    "    \n",
    "    if geo_type == 'County':\n",
    "        unknown_county = (employed['pop_label'] == 'Unknown County').sum()\n",
    "        unknown_emp = employed[employed['pop_label'] == 'Unknown County']['PERWT'].sum()\n",
    "        print(f\"\\n✓ Unknown County check: {unknown_county:,} employment records, {unknown_emp:,.0f} employment\")\n",
    "\n",
    "def create_combined_dataframe(employed_data, analysis_type):\n",
    "    \"\"\"Create combined dataframe for either NAICS or SOC analysis.\"\"\"\n",
    "    print(f\"  Creating combined {analysis_type} dataframe...\")\n",
    "    \n",
    "    if analysis_type == 'NAICS':\n",
    "        levels = ['naics_2digit', 'naics_3digit', 'naics_4digit', 'naics_5digit', 'naics_6digit']\n",
    "        code_col = 'industry_code'\n",
    "        title_col = 'industry_title'\n",
    "        level_col = 'naics_level'\n",
    "    else:  # SOC\n",
    "        levels = ['soc_2digit', 'soc_3digit', 'soc_4digit', 'soc_5digit', 'soc_6digit']\n",
    "        code_col = 'occupation_code'\n",
    "        title_col = 'occupation_title'\n",
    "        level_col = 'soc_level'\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for level in levels:\n",
    "        if level not in employed_data.columns:\n",
    "            print(f\"    Warning: {level} not found in data\")\n",
    "            continue\n",
    "        \n",
    "        # Filter out unclassified records\n",
    "        level_data = employed_data[employed_data[level] != 'Unclassified'].copy()\n",
    "        \n",
    "        if len(level_data) == 0:\n",
    "            print(f\"    Warning: No classified data for {level}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate employment shares by code, metro status, and population bucket\n",
    "        grouped = (level_data.groupby([level, 'metro_status', 'pop_label'])['PERWT']\n",
    "                  .sum()\n",
    "                  .reset_index())\n",
    "        \n",
    "        # Get total employment by code and metro status\n",
    "        totals = (level_data.groupby([level, 'metro_status'])['PERWT']\n",
    "                 .sum()\n",
    "                 .reset_index()\n",
    "                 .rename(columns={'PERWT': 'total_employment'}))\n",
    "        \n",
    "        # Merge and calculate percentages\n",
    "        merged = grouped.merge(totals, on=[level, 'metro_status'], how='left')\n",
    "        merged['employment_share'] = (\n",
    "            (merged['PERWT'] / merged['total_employment'] * 100)\n",
    "            .round(1)\n",
    "            .fillna(0)\n",
    "        )\n",
    "        \n",
    "        # Create pivot table\n",
    "        try:\n",
    "            pivot = merged.pivot_table(\n",
    "                index=[level, 'metro_status'],\n",
    "                columns='pop_label',\n",
    "                values='employment_share',\n",
    "                fill_value=0\n",
    "            ).reset_index()\n",
    "        except Exception as e:\n",
    "            print(f\"    Error creating pivot for {level}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure all bucket columns exist\n",
    "        for bucket in BUCKET_ORDER:\n",
    "            if bucket not in pivot.columns:\n",
    "                pivot[bucket] = 0.0\n",
    "        \n",
    "        # Add titles\n",
    "        if analysis_type == 'NAICS' and 'NAICS_MAPPING' in globals() and NAICS_MAPPING:\n",
    "            def get_title(code):\n",
    "                code_str = str(code).strip().upper()  # Ensure consistent case for alphanumeric codes\n",
    "                \n",
    "                # Try direct lookup first\n",
    "                if code_str in NAICS_MAPPING:\n",
    "                    mapping_value = NAICS_MAPPING[code_str]\n",
    "                    if isinstance(mapping_value, dict):\n",
    "                        return mapping_value.get('title', f'NAICS {code_str}')\n",
    "                    elif isinstance(mapping_value, str):\n",
    "                        return mapping_value\n",
    "                \n",
    "                # ENHANCED FALLBACK: Try shorter codes (handles alphanumeric like 611M1)\n",
    "                if len(code_str) > 2:\n",
    "                    for fallback_length in [5, 4, 3, 2]:\n",
    "                        if len(code_str) > fallback_length:\n",
    "                            fallback_code = code_str[:fallback_length]\n",
    "                            if fallback_code in NAICS_MAPPING:\n",
    "                                mapping_value = NAICS_MAPPING[fallback_code]\n",
    "                                if isinstance(mapping_value, str):\n",
    "                                    return f\"{mapping_value} (detailed)\"\n",
    "                \n",
    "                # Special handling for alphanumeric codes - try numeric portion\n",
    "                import re\n",
    "                numeric_match = re.match(r'^(\\d+)', code_str)\n",
    "                if numeric_match:\n",
    "                    numeric_part = numeric_match.group(1)\n",
    "                    if numeric_part in NAICS_MAPPING:\n",
    "                        mapping_value = NAICS_MAPPING[numeric_part]\n",
    "                        if isinstance(mapping_value, str):\n",
    "                            return f\"{mapping_value} (specialized)\"\n",
    "                        elif isinstance(mapping_value, dict):\n",
    "                            title = mapping_value.get('title', f'NAICS {numeric_part}')\n",
    "                            return f\"{title} (specialized)\"\n",
    "                \n",
    "                return f'NAICS {code_str}'\n",
    "        elif analysis_type == 'SOC' and 'SOC_MAPPING' in globals() and SOC_MAPPING:\n",
    "            # Use SOC mapping\n",
    "            def get_title(code):\n",
    "                code_str = str(code).strip()\n",
    "                \n",
    "                # Look for this code in the SOC mapping\n",
    "                for acs_code, soc_hierarchy in SOC_MAPPING.items():\n",
    "                    for soc_level_key in ['soc2_code', 'soc3_code', 'soc4_code', 'soc5_code', 'soc6_code']:\n",
    "                        if soc_hierarchy.get(soc_level_key) == code_str:\n",
    "                            title_key = soc_level_key.replace('_code', '_title')\n",
    "                            title = soc_hierarchy.get(title_key, f'SOC {code_str}')\n",
    "                            if title and title != f'SOC {code_str}':\n",
    "                                return title\n",
    "                \n",
    "                # Fallback to basic SOC titles\n",
    "                basic_soc_titles = {\n",
    "                    '11': 'Management Occupations',\n",
    "                    '13': 'Business and Financial Operations Occupations',\n",
    "                    '15': 'Computer and Mathematical Occupations',\n",
    "                    '17': 'Architecture and Engineering Occupations',\n",
    "                    '19': 'Life, Physical, and Social Science Occupations',\n",
    "                    '21': 'Community and Social Service Occupations',\n",
    "                    '23': 'Legal Occupations',\n",
    "                    '25': 'Educational Instruction and Library Occupations',\n",
    "                    '27': 'Arts, Design, Entertainment, Sports, and Media Occupations',\n",
    "                    '29': 'Healthcare Practitioners and Technical Occupations',\n",
    "                    '31': 'Healthcare Support Occupations',\n",
    "                    '33': 'Protective Service Occupations',\n",
    "                    '35': 'Food Preparation and Serving Related Occupations',\n",
    "                    '37': 'Building and Grounds Cleaning and Maintenance Occupations',\n",
    "                    '39': 'Personal Care and Service Occupations',\n",
    "                    '41': 'Sales and Related Occupations',\n",
    "                    '43': 'Office and Administrative Support Occupations',\n",
    "                    '45': 'Farming, Fishing, and Forestry Occupations',\n",
    "                    '47': 'Construction and Extraction Occupations',\n",
    "                    '49': 'Installation, Maintenance, and Repair Occupations',\n",
    "                    '51': 'Production Occupations',\n",
    "                    '53': 'Transportation and Material Moving Occupations',\n",
    "                    '55': 'Military Specific Occupations'\n",
    "                }\n",
    "                \n",
    "                code_2digit = code_str[:2] if len(code_str) >= 2 else code_str\n",
    "                return basic_soc_titles.get(code_2digit, f'SOC {code_str}')\n",
    "        else:\n",
    "            # Generic titles\n",
    "            def get_title(code):\n",
    "                return f'{analysis_type} {code}'\n",
    "        \n",
    "        unique_codes = pivot[level].unique()\n",
    "        title_mapping = {code: get_title(code) for code in unique_codes}\n",
    "        pivot[title_col] = pivot[level].map(title_mapping)\n",
    "        \n",
    "        # Rename and format columns\n",
    "        pivot = pivot.rename(columns={\n",
    "            level: code_col,\n",
    "            'metro_status': 'rural_urban_status'\n",
    "        })\n",
    "        \n",
    "        # Add level identifier\n",
    "        pivot[level_col] = level\n",
    "        \n",
    "        # Reorder columns\n",
    "        base_columns = [level_col, code_col, title_col, 'rural_urban_status']\n",
    "        final_columns = base_columns + BUCKET_ORDER\n",
    "        existing_columns = [col for col in final_columns if col in pivot.columns]\n",
    "        pivot = pivot[existing_columns]\n",
    "        \n",
    "        # Sort\n",
    "        pivot['rural_urban_status'] = pd.Categorical(\n",
    "            pivot['rural_urban_status'],\n",
    "            categories=['Non-metro/Rural', 'Metropolitan'],\n",
    "            ordered=True\n",
    "        )\n",
    "        pivot = pivot.sort_values([code_col, 'rural_urban_status']).reset_index(drop=True)\n",
    "        \n",
    "        all_results.append(pivot)\n",
    "        print(f\"    {level}: {len(pivot)} records processed\")\n",
    "    \n",
    "    # Combine all levels\n",
    "    if all_results:\n",
    "        combined_df = pd.concat(all_results, ignore_index=True)\n",
    "        print(f\"  Combined {analysis_type} dataframe: {len(combined_df)} total records\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"  No {analysis_type} data available\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def print_sample_data(combined_df, analysis_type, geo_type):\n",
    "    \"\"\"Print sample data for the analysis.\"\"\"\n",
    "    print(f\"\\nSample {geo_type} {analysis_type} data:\")\n",
    "    \n",
    "    if analysis_type == 'NAICS':\n",
    "        sample_cols = ['naics_level', 'industry_code', 'industry_title', 'rural_urban_status', '0-25K', '25K-50K', '50K-75K']\n",
    "    else:  # SOC\n",
    "        sample_cols = ['soc_level', 'occupation_code', 'occupation_title', 'rural_urban_status', '0-25K', '25K-50K']\n",
    "    \n",
    "    available_cols = [col for col in sample_cols if col in combined_df.columns]\n",
    "    print(combined_df[available_cols].head())\n",
    "\n",
    "def verify_percentages(combined_df):\n",
    "    \"\"\"Verify that percentage columns sum to approximately 100.\"\"\"\n",
    "    bucket_cols = [col for col in combined_df.columns if col in BUCKET_ORDER]\n",
    "    combined_df['row_sum'] = combined_df[bucket_cols].sum(axis=1)\n",
    "    print(f\"\\nRow sums (should be ~100): min={combined_df['row_sum'].min():.1f}, max={combined_df['row_sum'].max():.1f}\")\n",
    "    combined_df.drop('row_sum', axis=1, inplace=True)  # Remove verification column\n",
    "\n",
    "def print_final_summary(analysis_results):\n",
    "    \"\"\"Print final analysis summary.\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE - SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for analysis_type, (puma_df, county_df) in analysis_results.items():\n",
    "        print(f\"{analysis_type} Analysis:\")\n",
    "        print(f\"  PUMA tab: {len(puma_df):,} rows\")\n",
    "        print(f\"  County tab: {len(county_df):,} rows\")\n",
    "    \n",
    "    # Show sample of final results\n",
    "    if 'NAICS' in analysis_results and len(analysis_results['NAICS'][0]) > 0:\n",
    "        print(f\"\\nSample PUMA NAICS results:\")\n",
    "        print(analysis_results['NAICS'][0].head(3))\n",
    "    \n",
    "    print(\"\\n✓ Analysis complete! You can now open the Excel files to view results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61d8b72e-a74d-404e-a4c8-d89d1a39ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NAICS COVERAGE ANALYSIS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_naics_coverage_vectorized(employed_with_pop, unit_pop, unit_type, total_us_employment, full_county_universe=None):\n",
    "    \"\"\"\n",
    "    Calculate NAICS coverage using vectorized operations for efficiency.\n",
    "    Updated to support full county universe for accurate county counts.\n",
    "    \"\"\"\n",
    "    print(f\"  Starting optimized NAICS coverage calculation for {unit_type}...\")\n",
    "    \n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']\n",
    "    unit_label = 'pumas' if unit_type == 'PUMA' else 'counties'\n",
    "    \n",
    "    # Determine if using full universe for county counts\n",
    "    use_full_universe = (unit_type == 'County' and full_county_universe is not None)\n",
    "    \n",
    "    if use_full_universe:\n",
    "        print(f\"    Using full county universe for accurate county counts...\")\n",
    "        # Create county_fips if not exists\n",
    "        if 'county_fips' not in employed_with_pop.columns:\n",
    "            employed_with_pop['county_fips'] = (\n",
    "                employed_with_pop['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "                employed_with_pop['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "            )\n",
    "        \n",
    "        # Create metro label mapping\n",
    "        employed_with_pop['metro_label'] = employed_with_pop['metro_status'].map({\n",
    "            'Non-metro/Rural': 'Rural',\n",
    "            'Metropolitan': 'Urban'\n",
    "        })\n",
    "        \n",
    "        # Get metro mapping from ACS data\n",
    "        metro_mapping = employed_with_pop[['county_fips', 'metro_label']].drop_duplicates()\n",
    "        \n",
    "        # FIXED: Use full universe for counts, estimate metro status for missing counties\n",
    "        universe_with_metro = full_county_universe.merge(metro_mapping, on='county_fips', how='left')\n",
    "        \n",
    "        counties_without_metro = universe_with_metro['metro_label'].isna().sum()\n",
    "        print(f\"    Warning: {counties_without_metro} counties have no ACS metro status\")\n",
    "        \n",
    "        # For missing metro status, estimate based on population size (simple heuristic)\n",
    "        # Counties over 50K are more likely to be urban\n",
    "        universe_with_metro.loc[\n",
    "            universe_with_metro['metro_label'].isna() & \n",
    "            universe_with_metro['pop_label'].isin(['75K-100K', '100K-1M', '1M+']), \n",
    "            'metro_label'\n",
    "        ] = 'Urban'\n",
    "        \n",
    "        universe_with_metro.loc[\n",
    "            universe_with_metro['metro_label'].isna(), \n",
    "            'metro_label'\n",
    "        ] = 'Rural'\n",
    "        \n",
    "        # Now use ALL counties for counts\n",
    "        unit_counts_full = universe_with_metro.groupby(['pop_label', 'metro_label']).size().reset_index(name='count')\n",
    "        unit_counts_pivot = unit_counts_full.pivot(index='pop_label', columns='metro_label', values='count').fillna(0)\n",
    "        unit_counts_pivot.columns = ['Non-metro/Rural', 'Metropolitan']  # Standardize column names\n",
    "        unit_totals_full = universe_with_metro.groupby('pop_label').size()\n",
    "        \n",
    "        print(f\"    Using ALL {len(universe_with_metro)} counties for counts (estimated metro status for missing)\")\n",
    "    else:\n",
    "        print(f\"    Using ACS data only for unit counts...\")\n",
    "        # Standardize metro status values\n",
    "        print(f\"    Standardizing metro status values...\")\n",
    "        \n",
    "        employed_with_pop = employed_with_pop.copy()\n",
    "        unit_pop = unit_pop.copy()\n",
    "        \n",
    "        # Map employed data to match unit_pop naming if needed\n",
    "        employed_metro_mapping = {\n",
    "            'Rural': 'Non-metro/Rural',\n",
    "            'Urban': 'Metropolitan'\n",
    "        }\n",
    "        \n",
    "        # Apply mapping if values need to be standardized\n",
    "        if 'Rural' in employed_with_pop['metro_status'].values or 'Urban' in employed_with_pop['metro_status'].values:\n",
    "            employed_with_pop['metro_status'] = employed_with_pop['metro_status'].map(employed_metro_mapping)\n",
    "        \n",
    "        print(f\"    Employment metro status values: {employed_with_pop['metro_status'].unique()}\")\n",
    "        print(f\"    Unit metro status values: {unit_pop['metro_status'].unique()}\")\n",
    "        \n",
    "        # Pre-create bucket categorical to ensure all buckets are present\n",
    "        employed_with_pop['pop_label'] = pd.Categorical(employed_with_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "        unit_pop['pop_label'] = pd.Categorical(unit_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "        \n",
    "        # Vectorized unit counts by bucket and metro status\n",
    "        print(f\"    Computing unit counts...\")\n",
    "        unit_counts_pivot = unit_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
    "        unit_totals_full = unit_pop.groupby('pop_label').size()\n",
    "    \n",
    "    # Vectorized employment totals by bucket and metro status (always from ACS data)\n",
    "    print(f\"    Computing employment totals...\")\n",
    "    emp_by_bucket_metro = employed_with_pop.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "    emp_by_bucket_total = employed_with_pop.groupby('pop_label')['PERWT'].sum()\n",
    "    \n",
    "    # Calculate NAICS coverage by bucket and metro status\n",
    "    print(f\"    Computing NAICS coverage rates...\")\n",
    "    \n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit']\n",
    "    \n",
    "    # Pre-calculate ALL NAICS coverage by bucket and metro status\n",
    "    coverage_data = {}\n",
    "    \n",
    "    for level in naics_levels:\n",
    "        # Validate NAICS level exists\n",
    "        if level not in employed_with_pop.columns:\n",
    "            print(f\"    Warning: {level} not found in data\")\n",
    "            continue\n",
    "            \n",
    "        # Create mask for classified records\n",
    "        classified_mask = employed_with_pop[level] != 'Unclassified'\n",
    "        classified_data = employed_with_pop[classified_mask]\n",
    "        \n",
    "        # Vectorized coverage calculation by bucket and metro status\n",
    "        classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "        classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
    "        \n",
    "        # Calculate coverage percentages - vectorized division\n",
    "        coverage_total = (classified_by_bucket_total / emp_by_bucket_total * 100).fillna(0)\n",
    "        \n",
    "        # Handle metro status coverage (avoid division by zero)\n",
    "        coverage_metro = classified_by_bucket_metro.div(emp_by_bucket_metro, fill_value=0) * 100\n",
    "        coverage_metro = coverage_metro.fillna(0)\n",
    "\n",
    "        coverage_data[level] = {\n",
    "            'total': coverage_total,\n",
    "            'metro': coverage_metro\n",
    "        }\n",
    "    \n",
    "    # Build results DataFrame efficiently\n",
    "    print(f\"    Assembling results...\")\n",
    "    results = []\n",
    "    \n",
    "    for bucket in all_buckets:\n",
    "        # Get unit counts (from full universe if available, otherwise from ACS)\n",
    "        n_units_total = unit_totals_full.get(bucket, 0)\n",
    "        \n",
    "        # Better access to unstacked data for unit counts\n",
    "        if bucket in unit_counts_pivot.index:\n",
    "            n_units_rural = unit_counts_pivot.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in unit_counts_pivot.columns else 0\n",
    "            n_units_urban = unit_counts_pivot.loc[bucket, 'Metropolitan'] if 'Metropolitan' in unit_counts_pivot.columns else 0\n",
    "        else:\n",
    "            n_units_rural = n_units_urban = 0\n",
    "        \n",
    "        # Get employment totals with proper index checking\n",
    "        total_emp_all = emp_by_bucket_total.get(bucket, 0)\n",
    "        \n",
    "        # Better access to employment by metro status\n",
    "        if bucket in emp_by_bucket_metro.index:\n",
    "            total_emp_rural = emp_by_bucket_metro.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in emp_by_bucket_metro.columns else 0\n",
    "            total_emp_urban = emp_by_bucket_metro.loc[bucket, 'Metropolitan'] if 'Metropolitan' in emp_by_bucket_metro.columns else 0\n",
    "        else:\n",
    "            total_emp_rural = total_emp_urban = 0\n",
    "        \n",
    "        # Calculate employment percentages\n",
    "        total_emp_pct = (total_emp_all / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        rural_emp_pct = (total_emp_rural / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        urban_emp_pct = (total_emp_urban / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        \n",
    "        # Build row\n",
    "        row = {\n",
    "            'pop_label': bucket,\n",
    "            f'total_{unit_label}': int(n_units_total),\n",
    "            f'rural_{unit_label}': int(n_units_rural),\n",
    "            f'urban_{unit_label}': int(n_units_urban),\n",
    "            'total_employment_pct': round(total_emp_pct, 2),\n",
    "            'rural_employment_pct': round(rural_emp_pct, 2),\n",
    "            'urban_employment_pct': round(urban_emp_pct, 2),\n",
    "            'total_employment': int(total_emp_all),\n",
    "            'rural_employment': int(total_emp_rural),\n",
    "            'urban_employment': int(total_emp_urban)\n",
    "        }\n",
    "        \n",
    "        # Add NAICS coverage data for ALL levels\n",
    "        for level in naics_levels:\n",
    "            if level not in coverage_data:\n",
    "                # If level doesn't exist, add zeros\n",
    "                row[f'total_{level}_coverage_pct'] = 0.0\n",
    "                row[f'rural_{level}_coverage_pct'] = 0.0\n",
    "                row[f'urban_{level}_coverage_pct'] = 0.0\n",
    "                continue\n",
    "                \n",
    "            coverage_total = coverage_data[level]['total'].get(bucket, 0)\n",
    "            \n",
    "            if bucket in coverage_data[level]['metro'].index:\n",
    "                coverage_rural = coverage_data[level]['metro'].loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in coverage_data[level]['metro'].columns else 0\n",
    "                coverage_urban = coverage_data[level]['metro'].loc[bucket, 'Metropolitan'] if 'Metropolitan' in coverage_data[level]['metro'].columns else 0\n",
    "            else:\n",
    "                coverage_rural = coverage_urban = 0\n",
    "            \n",
    "            row[f'total_{level}_coverage_pct'] = round(float(coverage_total), 2)\n",
    "            row[f'rural_{level}_coverage_pct'] = round(float(coverage_rural), 2)\n",
    "            row[f'urban_{level}_coverage_pct'] = round(float(coverage_urban), 2)\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    coverage_df = pd.DataFrame(results)\n",
    "    coverage_df['pop_label'] = pd.Categorical(coverage_df['pop_label'], categories=all_buckets, ordered=True)\n",
    "    \n",
    "    universe_note = \" with full universe\" if use_full_universe else \"\"\n",
    "    print(f\"    Optimized NAICS coverage calculation{universe_note} complete for {unit_type}\")\n",
    "    return coverage_df.sort_values('pop_label').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def create_unit_population_summary(employed_data, geo_type='PUMA'):\n",
    "    \"\"\"\n",
    "    Create unit population summary for coverage analysis.\n",
    "    This creates the unit_pop dataframe needed for coverage calculations.\n",
    "    \"\"\"\n",
    "    print(f\"Creating {geo_type} unit population summary...\")\n",
    "    \n",
    "    # Group by geographic unit to get one record per unit\n",
    "    if geo_type == 'PUMA':  # ← Fixed: removed \"ACA\"\n",
    "        unit_summary = employed_data.groupby(['geo_id', 'metro_status', 'pop_label']).agg({\n",
    "            'PERWT': 'sum'  # Total employment in this unit\n",
    "        }).reset_index()\n",
    "    else:  # County\n",
    "        unit_summary = employed_data.groupby(['geo_id', 'metro_status', 'pop_label']).agg({\n",
    "            'PERWT': 'sum'  # Total employment in this unit\n",
    "        }).reset_index()\n",
    "    \n",
    "    # Each row represents one geographic unit\n",
    "    unit_pop = unit_summary[['geo_id', 'metro_status', 'pop_label']].drop_duplicates()\n",
    "    \n",
    "    print(f\"✓ {geo_type} unit summary created: {len(unit_pop)} units\")\n",
    "    \n",
    "    return unit_pop\n",
    "\n",
    "def create_coverage_analysis(puma_employed, county_employed, full_county_universe=None):\n",
    "    \"\"\"\n",
    "    Create NAICS coverage analysis for both PUMA and County data.\n",
    "    Updated to use full county universe as denominator for accurate coverage percentages.\n",
    "    \n",
    "    Args:\n",
    "        puma_employed: PUMA employment data\n",
    "        county_employed: County employment data \n",
    "        full_county_universe: Complete county list with pop_labels (optional)\n",
    "    \n",
    "    Returns:\n",
    "        puma_coverage, county_coverage dataframes\n",
    "    \"\"\"\n",
    "    print(\"\\nSTEP 4: Creating NAICS Coverage Analysis...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Calculate total US employment for percentage calculations\n",
    "    total_us_employment_puma = puma_employed['PERWT'].sum()\n",
    "    total_us_employment_county = county_employed['PERWT'].sum()\n",
    "    \n",
    "    print(f\"Total US Employment (PUMA): {total_us_employment_puma:,.0f}\")\n",
    "    print(f\"Total US Employment (County): {total_us_employment_county:,.0f}\")\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # PUMA NAICS Coverage (no change - no full universe available)\n",
    "    # ----------------------------------------\n",
    "    print(f\"\\n--- PUMA NAICS Coverage ---\")\n",
    "    puma_unit_pop = create_unit_population_summary(puma_employed, 'PUMA')\n",
    "    puma_coverage = calculate_naics_coverage_vectorized(\n",
    "        puma_employed, \n",
    "        puma_unit_pop, \n",
    "        'PUMA', \n",
    "        total_us_employment_puma\n",
    "    )\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # County NAICS Coverage with Full Universe Support\n",
    "    # ----------------------------------------\n",
    "    print(f\"\\n--- County NAICS Coverage ---\")\n",
    "    \n",
    "    # Filter to counties with valid COUNTYFIP (using COUNTYFIP now)\n",
    "    unknown_mask = county_employed['COUNTYFIP'] == 0\n",
    "    known_county_df = county_employed[~unknown_mask].copy()\n",
    "    unknown_county_df = county_employed[unknown_mask].copy()\n",
    "    \n",
    "    # Create county_fips using COUNTYFIP if not exists\n",
    "    if 'county_fips' not in known_county_df.columns:\n",
    "        known_county_df['county_fips'] = (\n",
    "            known_county_df['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "            known_county_df['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "        )\n",
    "    \n",
    "    if full_county_universe is not None:\n",
    "        print(\"Using full county universe for accurate coverage percentages...\")\n",
    "        county_coverage = calculate_naics_coverage_with_full_universe(\n",
    "            known_county_df,\n",
    "            full_county_universe, \n",
    "            'County',\n",
    "            total_us_employment_county\n",
    "        )\n",
    "    else:\n",
    "        print(\"Using ACS data only for county coverage...\")\n",
    "        county_unit_pop = create_unit_population_summary(known_county_df, 'County')\n",
    "        county_coverage = calculate_naics_coverage_vectorized(\n",
    "            known_county_df,\n",
    "            county_unit_pop,\n",
    "            'County',\n",
    "            total_us_employment_county\n",
    "        )\n",
    "    \n",
    "    # Add \"Unknown County\" row if relevant\n",
    "    if len(unknown_county_df) > 0:\n",
    "        unknown_weight = unknown_county_df['PERWT'].sum()\n",
    "        unknown_row = {\n",
    "            'pop_label': 'Population Unknown',\n",
    "            'total_counties': 0,\n",
    "            'rural_counties': 0,\n",
    "            'urban_counties': 0,\n",
    "            'total_employment': unknown_weight,\n",
    "            'rural_employment': 0,\n",
    "            'urban_employment': 0,\n",
    "            'total_employment_pct': round(unknown_weight / total_us_employment_county * 100, 2),\n",
    "            'rural_employment_pct': 0.0,\n",
    "            'urban_employment_pct': 0.0,\n",
    "            'total_naics_2digit_coverage_pct': 0.0,\n",
    "            'rural_naics_2digit_coverage_pct': 0.0,\n",
    "            'urban_naics_2digit_coverage_pct': 0.0,\n",
    "            'total_naics_3digit_coverage_pct': 0.0,\n",
    "            'rural_naics_3digit_coverage_pct': 0.0,\n",
    "            'urban_naics_3digit_coverage_pct': 0.0,\n",
    "            'total_naics_4digit_coverage_pct': 0.0,\n",
    "            'rural_naics_4digit_coverage_pct': 0.0,\n",
    "            'urban_naics_4digit_coverage_pct': 0.0,\n",
    "        }\n",
    "        county_coverage = pd.concat([county_coverage, pd.DataFrame([unknown_row])], ignore_index=True)\n",
    "        print(f\"✓ Added Unknown County row: {unknown_weight:,.0f} employment\")\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # Display Summaries\n",
    "    # ----------------------------------------\n",
    "    print(f\"\\n✓ PUMA Coverage Analysis Complete: {len(puma_coverage)} population buckets\")\n",
    "    if len(puma_coverage) > 0:\n",
    "        sample_cols = ['pop_label', 'total_pumas', 'total_employment_pct', 'total_naics_2digit_coverage_pct']\n",
    "        available_cols = [col for col in sample_cols if col in puma_coverage.columns]\n",
    "        print(\"Sample PUMA coverage data:\")\n",
    "        print(puma_coverage[available_cols].head(3))\n",
    "    \n",
    "    print(f\"\\n✓ County Coverage Analysis Complete: {len(county_coverage)} population buckets\")\n",
    "    if len(county_coverage) > 0:\n",
    "        sample_cols = ['pop_label', 'total_counties', 'total_employment_pct', 'total_naics_2digit_coverage_pct']\n",
    "        available_cols = [col for col in sample_cols if col in county_coverage.columns]\n",
    "        print(\"Sample County coverage data:\")\n",
    "        print(county_coverage[available_cols].head(3))\n",
    "    \n",
    "    return puma_coverage, county_coverage\n",
    "\n",
    "def calculate_naics_coverage_with_full_universe(employed_data, full_county_universe, unit_type, total_us_employment):\n",
    "    \"\"\"\n",
    "    Calculate NAICS coverage using full county universe as denominator.\n",
    "    \n",
    "    Args:\n",
    "        employed_data: ACS employment data (filtered)\n",
    "        full_county_universe: Complete county list with pop_labels\n",
    "        unit_type: Should be 'County'\n",
    "        total_us_employment: Total employment for percentage calculations\n",
    "    \"\"\"\n",
    "    print(f\"  Starting NAICS coverage calculation with full universe for {unit_type}...\")\n",
    "    \n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']\n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit']\n",
    "    \n",
    "    # Create metro label mapping\n",
    "    employed_data['metro_label'] = employed_data['metro_status'].map({\n",
    "        'Non-metro/Rural': 'Rural',\n",
    "        'Metropolitan': 'Urban'\n",
    "    })\n",
    "    \n",
    "    # Get metro mapping and merge with full universe\n",
    "    metro_mapping = employed_data[['county_fips', 'metro_label']].drop_duplicates()\n",
    "    universe_with_metro = full_county_universe.merge(metro_mapping, on='county_fips', how='left')\n",
    "    \n",
    "    counties_without_metro = universe_with_metro['metro_label'].isna().sum()\n",
    "    if counties_without_metro > 0:\n",
    "        print(f\"    Warning: {counties_without_metro} counties have no metro status (excluded)\")\n",
    "    \n",
    "    universe_with_metro = universe_with_metro.dropna(subset=['metro_label'])\n",
    "    print(f\"    Counties with metro status: {len(universe_with_metro)} / {len(full_county_universe)}\")\n",
    "    \n",
    "    # Calculate total county counts by bucket+metro from FULL UNIVERSE\n",
    "    total_county_counts = universe_with_metro.groupby(['pop_label', 'metro_label']).size().reset_index(name='total_counties')\n",
    "    total_county_counts_dict = {}\n",
    "    for _, row in total_county_counts.iterrows():\n",
    "        key = (row['pop_label'], row['metro_label'])\n",
    "        total_county_counts_dict[key] = row['total_counties']\n",
    "    \n",
    "    # Also calculate totals by bucket only\n",
    "    total_county_by_bucket = universe_with_metro.groupby('pop_label').size()\n",
    "    \n",
    "    # Calculate employment totals by bucket and metro from ACS data\n",
    "    emp_by_bucket_metro = employed_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().reset_index()\n",
    "    emp_by_bucket_total = employed_data.groupby('pop_label')['PERWT'].sum()\n",
    "    \n",
    "    # Build results\n",
    "    results = []\n",
    "    \n",
    "    for bucket in all_buckets:\n",
    "        # Get county counts from FULL UNIVERSE\n",
    "        n_counties_total = total_county_by_bucket.get(bucket, 0)\n",
    "        \n",
    "        # Get county counts by metro status from full universe\n",
    "        n_counties_rural = total_county_counts_dict.get((bucket, 'Rural'), 0)\n",
    "        n_counties_urban = total_county_counts_dict.get((bucket, 'Urban'), 0)\n",
    "        \n",
    "        # Get employment totals from ACS data\n",
    "        total_emp_all = emp_by_bucket_total.get(bucket, 0)\n",
    "        \n",
    "        # Get employment by metro status\n",
    "        bucket_emp_data = emp_by_bucket_metro[emp_by_bucket_metro['pop_label'] == bucket]\n",
    "        total_emp_rural = bucket_emp_data[bucket_emp_data['metro_status'] == 'Non-metro/Rural']['PERWT'].sum()\n",
    "        total_emp_urban = bucket_emp_data[bucket_emp_data['metro_status'] == 'Metropolitan']['PERWT'].sum()\n",
    "        \n",
    "        # Calculate employment percentages\n",
    "        total_emp_pct = (total_emp_all / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        rural_emp_pct = (total_emp_rural / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        urban_emp_pct = (total_emp_urban / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        \n",
    "        # Build base row\n",
    "        row = {\n",
    "            'pop_label': bucket,\n",
    "            'total_counties': int(n_counties_total),\n",
    "            'rural_counties': int(n_counties_rural),\n",
    "            'urban_counties': int(n_counties_urban),\n",
    "            'total_employment_pct': round(total_emp_pct, 2),\n",
    "            'rural_employment_pct': round(rural_emp_pct, 2),\n",
    "            'urban_employment_pct': round(urban_emp_pct, 2),\n",
    "            'total_employment': int(total_emp_all),\n",
    "            'rural_employment': int(total_emp_rural),\n",
    "            'urban_employment': int(total_emp_urban)\n",
    "        }\n",
    "        \n",
    "        # Calculate NAICS coverage for each level\n",
    "        for level in naics_levels:\n",
    "            if level not in employed_data.columns:\n",
    "                row[f'total_{level}_coverage_pct'] = 0.0\n",
    "                row[f'rural_{level}_coverage_pct'] = 0.0\n",
    "                row[f'urban_{level}_coverage_pct'] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Get classified employment data for this level\n",
    "            classified_data = employed_data[employed_data[level] != 'Unclassified']\n",
    "            \n",
    "            if len(classified_data) == 0:\n",
    "                row[f'total_{level}_coverage_pct'] = 0.0\n",
    "                row[f'rural_{level}_coverage_pct'] = 0.0\n",
    "                row[f'urban_{level}_coverage_pct'] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Calculate coverage by bucket and metro\n",
    "            classified_by_bucket = classified_data.groupby('pop_label')['PERWT'].sum()\n",
    "            classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum()\n",
    "            \n",
    "            # Total coverage for this bucket\n",
    "            classified_total = classified_by_bucket.get(bucket, 0)\n",
    "            coverage_total = (classified_total / total_emp_all * 100) if total_emp_all > 0 else 0\n",
    "            \n",
    "            # Coverage by metro status\n",
    "            classified_rural = classified_by_bucket_metro.get((bucket, 'Non-metro/Rural'), 0)\n",
    "            classified_urban = classified_by_bucket_metro.get((bucket, 'Metropolitan'), 0)\n",
    "            \n",
    "            coverage_rural = (classified_rural / total_emp_rural * 100) if total_emp_rural > 0 else 0\n",
    "            coverage_urban = (classified_urban / total_emp_urban * 100) if total_emp_urban > 0 else 0\n",
    "            \n",
    "            row[f'total_{level}_coverage_pct'] = round(coverage_total, 2)\n",
    "            row[f'rural_{level}_coverage_pct'] = round(coverage_rural, 2) \n",
    "            row[f'urban_{level}_coverage_pct'] = round(coverage_urban, 2)\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    coverage_df = pd.DataFrame(results)\n",
    "    coverage_df['pop_label'] = pd.Categorical(coverage_df['pop_label'], categories=all_buckets, ordered=True)\n",
    "    \n",
    "    print(f\"    NAICS coverage calculation with full universe complete for {unit_type}\")\n",
    "    return coverage_df.sort_values('pop_label').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21b4e9ce-15e5-4e04-bf4c-6a298998cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # FIXED NAICS COVERAGE ANALYSIS FUNCTIONS\n",
    "# # ============================================================================\n",
    "\n",
    "# def calculate_naics_coverage_vectorized(employed_with_pop, unit_pop, unit_type, total_us_employment, full_county_universe=None):\n",
    "#     \"\"\"\n",
    "#     Calculate NAICS coverage using vectorized operations for efficiency.\n",
    "#     FIXED: Always uses pure ACS denominators for consistent coverage calculations.\n",
    "#     \"\"\"\n",
    "#     print(f\"  Starting optimized NAICS coverage calculation for {unit_type}...\")\n",
    "#     print(f\"  Using pure ACS denominators for consistent coverage...\")\n",
    "    \n",
    "#     all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "#     unit_label = 'pumas' if unit_type == 'PUMA' else 'counties'\n",
    "    \n",
    "#     # FIXED: Always use pure ACS denominators - count unique counties by pop+metro\n",
    "#     if unit_type == 'County':\n",
    "#         print(f\"    Using pure ACS denominators - counting ALL counties with employment data...\")\n",
    "        \n",
    "#         # Create metro label mapping for consistency\n",
    "#         employed_with_pop['metro_label'] = employed_with_pop['metro_status'].map({\n",
    "#             'Non-metro/Rural': 'Rural', \n",
    "#             'Metropolitan': 'Urban'\n",
    "#         })\n",
    "        \n",
    "#         # Count unique counties by pop+metro combination from ALL ACS data\n",
    "#         unit_counts_raw = employed_with_pop.groupby(['pop_label', 'metro_label'])['county_fips'].nunique().reset_index(name='count')\n",
    "#         unit_counts_pivot = unit_counts_raw.pivot(index='pop_label', columns='metro_label', values='count').fillna(0)\n",
    "#         unit_counts_pivot.columns = ['Non-metro/Rural', 'Metropolitan']  # Standardize column names\n",
    "#         unit_totals_full = employed_with_pop.groupby('pop_label')['county_fips'].nunique()\n",
    "        \n",
    "#         print(f\"    Total ACS counties: {employed_with_pop['county_fips'].nunique()}\")\n",
    "#         print(f\"    ACS county breakdown:\")\n",
    "#         for pop_label in all_buckets:\n",
    "#             if pop_label in unit_totals_full.index:\n",
    "#                 rural_count = unit_counts_pivot.loc[pop_label, 'Non-metro/Rural'] if pop_label in unit_counts_pivot.index and 'Non-metro/Rural' in unit_counts_pivot.columns else 0\n",
    "#                 urban_count = unit_counts_pivot.loc[pop_label, 'Metropolitan'] if pop_label in unit_counts_pivot.index and 'Metropolitan' in unit_counts_pivot.columns else 0\n",
    "#                 total_count = unit_totals_full[pop_label]\n",
    "#                 print(f\"      {pop_label}: {total_count} total ({rural_count} Rural + {urban_count} Urban)\")\n",
    "        \n",
    "#     else:\n",
    "#         # PUMA logic (unchanged)\n",
    "#         print(f\"    Using ACS data only for unit counts...\")\n",
    "        \n",
    "#         # Standardize metro status values\n",
    "#         employed_with_pop = employed_with_pop.copy()\n",
    "#         unit_pop = unit_pop.copy()\n",
    "        \n",
    "#         # Map employed data to match unit_pop naming if needed\n",
    "#         employed_metro_mapping = {\n",
    "#             'Rural': 'Non-metro/Rural',\n",
    "#             'Urban': 'Metropolitan'\n",
    "#         }\n",
    "        \n",
    "#         # Apply mapping if values need to be standardized\n",
    "#         if 'Rural' in employed_with_pop['metro_status'].values or 'Urban' in employed_with_pop['metro_status'].values:\n",
    "#             employed_with_pop['metro_status'] = employed_with_pop['metro_status'].map(employed_metro_mapping)\n",
    "        \n",
    "#         # Pre-create bucket categorical to ensure all buckets are present\n",
    "#         employed_with_pop['pop_label'] = pd.Categorical(employed_with_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "#         unit_pop['pop_label'] = pd.Categorical(unit_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "        \n",
    "#         # Vectorized unit counts by bucket and metro status (pure ACS)\n",
    "#         print(f\"    Computing unit counts...\")\n",
    "#         unit_counts_pivot = unit_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
    "#         unit_totals_full = unit_pop.groupby('pop_label').size()\n",
    "    \n",
    "#     # Vectorized employment totals by bucket and metro status\n",
    "#     print(f\"    Computing employment totals...\")\n",
    "#     emp_by_bucket_metro = employed_with_pop.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "#     emp_by_bucket_total = employed_with_pop.groupby('pop_label')['PERWT'].sum()\n",
    "    \n",
    "#     # Calculate NAICS coverage by bucket and metro status\n",
    "#     print(f\"    Computing NAICS coverage rates...\")\n",
    "    \n",
    "#     naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit']\n",
    "    \n",
    "#     # Pre-calculate ALL NAICS coverage by bucket and metro status\n",
    "#     coverage_data = {}\n",
    "    \n",
    "#     for level in naics_levels:\n",
    "#         # Validate NAICS level exists\n",
    "#         if level not in employed_with_pop.columns:\n",
    "#             print(f\"    Warning: {level} not found in data\")\n",
    "#             continue\n",
    "            \n",
    "#         # Create mask for classified records\n",
    "#         classified_mask = employed_with_pop[level] != 'Unclassified'\n",
    "#         classified_data = employed_with_pop[classified_mask]\n",
    "        \n",
    "#         # Vectorized coverage calculation by bucket and metro status\n",
    "#         classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "#         classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
    "        \n",
    "#         # Calculate coverage percentages - vectorized division\n",
    "#         coverage_total = (classified_by_bucket_total / emp_by_bucket_total * 100).fillna(0)\n",
    "        \n",
    "#         # Handle metro status coverage (avoid division by zero)\n",
    "#         coverage_metro = classified_by_bucket_metro.div(emp_by_bucket_metro, fill_value=0) * 100\n",
    "#         coverage_metro = coverage_metro.fillna(0)\n",
    "\n",
    "#         coverage_data[level] = {\n",
    "#             'total': coverage_total,\n",
    "#             'metro': coverage_metro\n",
    "#         }\n",
    "    \n",
    "#     # Build results DataFrame efficiently\n",
    "#     print(f\"    Assembling results...\")\n",
    "#     results = []\n",
    "    \n",
    "#     for bucket in all_buckets:\n",
    "#         # Get unit counts (pure ACS)\n",
    "#         n_units_total = unit_totals_full.get(bucket, 0)\n",
    "        \n",
    "#         # Better access to unstacked data for unit counts\n",
    "#         if bucket in unit_counts_pivot.index:\n",
    "#             n_units_rural = unit_counts_pivot.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in unit_counts_pivot.columns else 0\n",
    "#             n_units_urban = unit_counts_pivot.loc[bucket, 'Metropolitan'] if 'Metropolitan' in unit_counts_pivot.columns else 0\n",
    "#         else:\n",
    "#             n_units_rural = n_units_urban = 0\n",
    "        \n",
    "#         # Get employment totals with proper index checking\n",
    "#         total_emp_all = emp_by_bucket_total.get(bucket, 0)\n",
    "        \n",
    "#         # Better access to employment by metro status\n",
    "#         if bucket in emp_by_bucket_metro.index:\n",
    "#             total_emp_rural = emp_by_bucket_metro.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in emp_by_bucket_metro.columns else 0\n",
    "#             total_emp_urban = emp_by_bucket_metro.loc[bucket, 'Metropolitan'] if 'Metropolitan' in emp_by_bucket_metro.columns else 0\n",
    "#         else:\n",
    "#             total_emp_rural = total_emp_urban = 0\n",
    "        \n",
    "#         # Calculate employment percentages\n",
    "#         total_emp_pct = (total_emp_all / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "#         rural_emp_pct = (total_emp_rural / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "#         urban_emp_pct = (total_emp_urban / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        \n",
    "#         # Build row\n",
    "#         row = {\n",
    "#             'pop_label': bucket,\n",
    "#             f'total_{unit_label}': int(n_units_total),\n",
    "#             f'rural_{unit_label}': int(n_units_rural),\n",
    "#             f'urban_{unit_label}': int(n_units_urban),\n",
    "#             'total_employment_pct': round(total_emp_pct, 2),\n",
    "#             'rural_employment_pct': round(rural_emp_pct, 2),\n",
    "#             'urban_employment_pct': round(urban_emp_pct, 2),\n",
    "#             'total_employment': int(total_emp_all),\n",
    "#             'rural_employment': int(total_emp_rural),\n",
    "#             'urban_employment': int(total_emp_urban)\n",
    "#         }\n",
    "        \n",
    "#         # Add NAICS coverage data for ALL levels\n",
    "#         for level in naics_levels:\n",
    "#             if level not in coverage_data:\n",
    "#                 # If level doesn't exist, add zeros\n",
    "#                 row[f'total_{level}_coverage_pct'] = 0.0\n",
    "#                 row[f'rural_{level}_coverage_pct'] = 0.0\n",
    "#                 row[f'urban_{level}_coverage_pct'] = 0.0\n",
    "#                 continue\n",
    "                \n",
    "#             coverage_total = coverage_data[level]['total'].get(bucket, 0)\n",
    "            \n",
    "#             if bucket in coverage_data[level]['metro'].index:\n",
    "#                 coverage_rural = coverage_data[level]['metro'].loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in coverage_data[level]['metro'].columns else 0\n",
    "#                 coverage_urban = coverage_data[level]['metro'].loc[bucket, 'Metropolitan'] if 'Metropolitan' in coverage_data[level]['metro'].columns else 0\n",
    "#             else:\n",
    "#                 coverage_rural = coverage_urban = 0\n",
    "            \n",
    "#             row[f'total_{level}_coverage_pct'] = round(float(coverage_total), 2)\n",
    "#             row[f'rural_{level}_coverage_pct'] = round(float(coverage_rural), 2)\n",
    "#             row[f'urban_{level}_coverage_pct'] = round(float(coverage_urban), 2)\n",
    "        \n",
    "#         results.append(row)\n",
    "    \n",
    "#     coverage_df = pd.DataFrame(results)\n",
    "#     coverage_df['pop_label'] = pd.Categorical(coverage_df['pop_label'], categories=all_buckets, ordered=True)\n",
    "    \n",
    "#     print(f\"    Optimized NAICS coverage calculation complete for {unit_type}\")\n",
    "#     return coverage_df.sort_values('pop_label').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# def create_unit_population_summary(employed_data, geo_type='PUMA'):\n",
    "#     \"\"\"\n",
    "#     Create unit population summary for coverage analysis.\n",
    "#     This creates the unit_pop dataframe needed for coverage calculations.\n",
    "#     \"\"\"\n",
    "#     print(f\"Creating {geo_type} unit population summary...\")\n",
    "    \n",
    "#     # Group by geographic unit to get one record per unit\n",
    "#     if geo_type == 'PUMA':\n",
    "#         unit_summary = employed_data.groupby(['geo_id', 'metro_status', 'pop_label']).agg({\n",
    "#             'PERWT': 'sum'  # Total employment in this unit\n",
    "#         }).reset_index()\n",
    "#     else:  # County\n",
    "#         unit_summary = employed_data.groupby(['geo_id', 'metro_status', 'pop_label']).agg({\n",
    "#             'PERWT': 'sum'  # Total employment in this unit\n",
    "#         }).reset_index()\n",
    "    \n",
    "#     # Each row represents one geographic unit\n",
    "#     unit_pop = unit_summary[['geo_id', 'metro_status', 'pop_label']].drop_duplicates()\n",
    "    \n",
    "#     print(f\"✓ {geo_type} unit summary created: {len(unit_pop)} units\")\n",
    "    \n",
    "#     return unit_pop\n",
    "\n",
    "\n",
    "# def create_coverage_analysis(puma_employed, county_employed, full_county_universe=None):\n",
    "#     \"\"\"\n",
    "#     FIXED: Create NAICS coverage analysis using pure ACS denominators.\n",
    "#     Always uses county_employed data for county counts, ensuring consistency.\n",
    "    \n",
    "#     Args:\n",
    "#         puma_employed: PUMA employment data\n",
    "#         county_employed: County employment data \n",
    "#         full_county_universe: Complete county list (ignored - using pure ACS)\n",
    "    \n",
    "#     Returns:\n",
    "#         puma_coverage, county_coverage dataframes\n",
    "#     \"\"\"\n",
    "#     print(\"\\nSTEP 4: Creating NAICS Coverage Analysis...\")\n",
    "#     print(\"FIXED: Using pure ACS denominators for consistent coverage...\")\n",
    "#     print(\"=\"*50)\n",
    "    \n",
    "#     # Calculate total US employment for percentage calculations\n",
    "#     total_us_employment_puma = puma_employed['PERWT'].sum()\n",
    "#     total_us_employment_county = county_employed['PERWT'].sum()\n",
    "    \n",
    "#     print(f\"Total US Employment (PUMA): {total_us_employment_puma:,.0f}\")\n",
    "#     print(f\"Total US Employment (County): {total_us_employment_county:,.0f}\")\n",
    "    \n",
    "#     # ----------------------------------------\n",
    "#     # PUMA NAICS Coverage\n",
    "#     # ----------------------------------------\n",
    "#     print(f\"\\n--- PUMA NAICS Coverage ---\")\n",
    "#     puma_unit_pop = create_unit_population_summary(puma_employed, 'PUMA')\n",
    "#     puma_coverage = calculate_naics_coverage_vectorized(\n",
    "#         puma_employed, \n",
    "#         puma_unit_pop, \n",
    "#         'PUMA', \n",
    "#         total_us_employment_puma\n",
    "#     )\n",
    "    \n",
    "#     # ----------------------------------------\n",
    "#     # County NAICS Coverage - FIXED to use pure ACS denominators\n",
    "#     # ----------------------------------------\n",
    "#     print(f\"\\n--- County NAICS Coverage ---\")\n",
    "    \n",
    "#     # FIXED: Use the function that now uses pure ACS denominators\n",
    "#     county_unit_pop = create_unit_population_summary(county_employed, 'County')\n",
    "#     county_coverage = calculate_naics_coverage_vectorized(\n",
    "#         county_employed,\n",
    "#         county_unit_pop,\n",
    "#         'County',\n",
    "#         total_us_employment_county,\n",
    "#         full_county_universe=None  # Explicitly ignore this parameter\n",
    "#     )\n",
    "    \n",
    "#     # ----------------------------------------\n",
    "#     # Display Summaries\n",
    "#     # ----------------------------------------\n",
    "#     print(f\"\\n✓ PUMA Coverage Analysis Complete: {len(puma_coverage)} population buckets\")\n",
    "#     if len(puma_coverage) > 0:\n",
    "#         sample_cols = ['pop_label', 'total_pumas', 'total_employment_pct', 'total_naics_2digit_coverage_pct']\n",
    "#         available_cols = [col for col in sample_cols if col in puma_coverage.columns]\n",
    "#         print(\"Sample PUMA coverage data:\")\n",
    "#         print(puma_coverage[available_cols].head(3))\n",
    "    \n",
    "#     print(f\"\\n✓ County Coverage Analysis Complete: {len(county_coverage)} population buckets\")\n",
    "#     print(f\"Using {county_employed['county_fips'].nunique()} ACS counties as denominators\")\n",
    "#     if len(county_coverage) > 0:\n",
    "#         sample_cols = ['pop_label', 'total_counties', 'total_employment_pct', 'total_naics_2digit_coverage_pct']\n",
    "#         available_cols = [col for col in sample_cols if col in county_coverage.columns]\n",
    "#         print(\"Sample County coverage data:\")\n",
    "#         print(county_coverage[available_cols].head(3))\n",
    "    \n",
    "#     return puma_coverage, county_coverage\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # FIXED SOC COVERAGE ANALYSIS FUNCTION\n",
    "# # ============================================================================\n",
    "\n",
    "# def calculate_soc_coverage_vectorized(employed_with_pop, unit_pop, unit_type, total_us_employment, full_county_universe=None):\n",
    "#     \"\"\"\n",
    "#     FIXED: Calculate SOC coverage using pure ACS denominators for consistency.\n",
    "#     \"\"\"\n",
    "#     print(f\"  Starting optimized SOC coverage calculation for {unit_type}...\")\n",
    "#     print(f\"  Using pure ACS denominators for consistent coverage...\")\n",
    "    \n",
    "#     all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "#     unit_label = 'pumas' if unit_type == 'PUMA' else 'counties'\n",
    "    \n",
    "#     # FIXED: Always use pure ACS denominators - count unique counties by pop+metro\n",
    "#     if unit_type == 'County':\n",
    "#         print(f\"    Using pure ACS denominators - counting ALL counties with employment data...\")\n",
    "        \n",
    "#         # Create metro label mapping for consistency\n",
    "#         employed_with_pop['metro_label'] = employed_with_pop['metro_status'].map({\n",
    "#             'Non-metro/Rural': 'Rural', \n",
    "#             'Metropolitan': 'Urban'\n",
    "#         })\n",
    "        \n",
    "#         # Count unique counties by pop+metro combination from ALL ACS data\n",
    "#         unit_counts_raw = employed_with_pop.groupby(['pop_label', 'metro_label'])['county_fips'].nunique().reset_index(name='count')\n",
    "#         unit_counts_pivot = unit_counts_raw.pivot(index='pop_label', columns='metro_label', values='count').fillna(0)\n",
    "#         unit_counts_pivot.columns = ['Non-metro/Rural', 'Metropolitan']  # Standardize column names\n",
    "#         unit_totals_full = employed_with_pop.groupby('pop_label')['county_fips'].nunique()\n",
    "        \n",
    "#         print(f\"    Total ACS counties: {employed_with_pop['county_fips'].nunique()}\")\n",
    "#         print(f\"    ACS county breakdown:\")\n",
    "#         for pop_label in all_buckets:\n",
    "#             if pop_label in unit_totals_full.index:\n",
    "#                 rural_count = unit_counts_pivot.loc[pop_label, 'Non-metro/Rural'] if pop_label in unit_counts_pivot.index and 'Non-metro/Rural' in unit_counts_pivot.columns else 0\n",
    "#                 urban_count = unit_counts_pivot.loc[pop_label, 'Metropolitan'] if pop_label in unit_counts_pivot.index and 'Metropolitan' in unit_counts_pivot.columns else 0\n",
    "#                 total_count = unit_totals_full[pop_label]\n",
    "#                 print(f\"      {pop_label}: {total_count} total ({rural_count} Rural + {urban_count} Urban)\")\n",
    "        \n",
    "#     else:\n",
    "#         # PUMA logic (unchanged)\n",
    "#         print(f\"    Using ACS data only for unit counts...\")\n",
    "        \n",
    "#         # Standardize metro status values\n",
    "#         employed_with_pop = employed_with_pop.copy()\n",
    "#         unit_pop = unit_pop.copy()\n",
    "        \n",
    "#         # Map employed data to match unit_pop naming if needed\n",
    "#         employed_metro_mapping = {\n",
    "#             'Rural': 'Non-metro/Rural',\n",
    "#             'Urban': 'Metropolitan'\n",
    "#         }\n",
    "        \n",
    "#         # Apply mapping if values need to be standardized\n",
    "#         if 'Rural' in employed_with_pop['metro_status'].values or 'Urban' in employed_with_pop['metro_status'].values:\n",
    "#             employed_with_pop['metro_status'] = employed_with_pop['metro_status'].map(employed_metro_mapping)\n",
    "        \n",
    "#         # Pre-create bucket categorical to ensure all buckets are present\n",
    "#         employed_with_pop['pop_label'] = pd.Categorical(employed_with_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "#         unit_pop['pop_label'] = pd.Categorical(unit_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "        \n",
    "#         # Vectorized unit counts by bucket and metro status (pure ACS)\n",
    "#         print(f\"    Computing unit counts...\")\n",
    "#         unit_counts_pivot = unit_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
    "#         unit_totals_full = unit_pop.groupby('pop_label').size()\n",
    "    \n",
    "#     # Vectorized employment totals by bucket and metro status\n",
    "#     print(f\"    Computing employment totals...\")\n",
    "#     emp_by_bucket_metro = employed_with_pop.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "#     emp_by_bucket_total = employed_with_pop.groupby('pop_label')['PERWT'].sum()\n",
    "    \n",
    "#     # Calculate SOC coverage by bucket and metro status\n",
    "#     print(f\"    Computing SOC coverage rates...\")\n",
    "    \n",
    "#     soc_levels = ['soc_2digit', 'soc_3digit', 'soc_4digit']\n",
    "    \n",
    "#     # Pre-calculate ALL SOC coverage by bucket and metro status\n",
    "#     coverage_data = {}\n",
    "    \n",
    "#     for level in soc_levels:\n",
    "#         # Validate SOC level exists\n",
    "#         if level not in employed_with_pop.columns:\n",
    "#             print(f\"    Warning: {level} not found in data\")\n",
    "#             continue\n",
    "            \n",
    "#         # Create mask for classified records\n",
    "#         classified_mask = employed_with_pop[level] != 'Unclassified'\n",
    "#         classified_data = employed_with_pop[classified_mask]\n",
    "        \n",
    "#         # Vectorized coverage calculation by bucket and metro status\n",
    "#         classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "#         classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
    "        \n",
    "#         # Calculate coverage percentages - vectorized division\n",
    "#         coverage_total = (classified_by_bucket_total / emp_by_bucket_total * 100).fillna(0)\n",
    "        \n",
    "#         # Handle metro status coverage (avoid division by zero)\n",
    "#         coverage_metro = classified_by_bucket_metro.div(emp_by_bucket_metro, fill_value=0) * 100\n",
    "#         coverage_metro = coverage_metro.fillna(0)\n",
    "\n",
    "#         coverage_data[level] = {\n",
    "#             'total': coverage_total,\n",
    "#             'metro': coverage_metro\n",
    "#         }\n",
    "    \n",
    "#     # Build results DataFrame efficiently\n",
    "#     print(f\"    Assembling results...\")\n",
    "#     results = []\n",
    "    \n",
    "#     for bucket in all_buckets:\n",
    "#         # Get unit counts (pure ACS)\n",
    "#         n_units_total = unit_totals_full.get(bucket, 0)\n",
    "        \n",
    "#         # Better access to unstacked data for unit counts\n",
    "#         if bucket in unit_counts_pivot.index:\n",
    "#             n_units_rural = unit_counts_pivot.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in unit_counts_pivot.columns else 0\n",
    "#             n_units_urban = unit_counts_pivot.loc[bucket, 'Metropolitan'] if 'Metropolitan' in unit_counts_pivot.columns else 0\n",
    "#         else:\n",
    "#             n_units_rural = n_units_urban = 0\n",
    "        \n",
    "#         # Get employment totals with proper index checking\n",
    "#         total_emp_all = emp_by_bucket_total.get(bucket, 0)\n",
    "        \n",
    "#         # Better access to employment by metro status\n",
    "#         if bucket in emp_by_bucket_metro.index:\n",
    "#             total_emp_rural = emp_by_bucket_metro.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in emp_by_bucket_metro.columns else 0\n",
    "#             total_emp_urban = emp_by_bucket_metro.loc[bucket, 'Metropolitan'] if 'Metropolitan' in emp_by_bucket_metro.columns else 0\n",
    "#         else:\n",
    "#             total_emp_rural = total_emp_urban = 0\n",
    "        \n",
    "#         # Calculate employment percentages\n",
    "#         total_emp_pct = (total_emp_all / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "#         rural_emp_pct = (total_emp_rural / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "#         urban_emp_pct = (total_emp_urban / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        \n",
    "#         # Build row\n",
    "#         row = {\n",
    "#             'pop_label': bucket,\n",
    "#             f'total_{unit_label}': int(n_units_total),\n",
    "#             f'rural_{unit_label}': int(n_units_rural),\n",
    "#             f'urban_{unit_label}': int(n_units_urban),\n",
    "#             'total_employment_pct': round(total_emp_pct, 2),\n",
    "#             'rural_employment_pct': round(rural_emp_pct, 2),\n",
    "#             'urban_employment_pct': round(urban_emp_pct, 2),\n",
    "#             'total_employment': int(total_emp_all),\n",
    "#             'rural_employment': int(total_emp_rural),\n",
    "#             'urban_employment': int(total_emp_urban)\n",
    "#         }\n",
    "        \n",
    "#         # Add SOC coverage data for ALL levels\n",
    "#         for level in soc_levels:\n",
    "#             if level not in coverage_data:\n",
    "#                 # If level doesn't exist, add zeros\n",
    "#                 row[f'total_{level}_coverage_pct'] = 0.0\n",
    "#                 row[f'rural_{level}_coverage_pct'] = 0.0\n",
    "#                 row[f'urban_{level}_coverage_pct'] = 0.0\n",
    "#                 continue\n",
    "                \n",
    "#             coverage_total = coverage_data[level]['total'].get(bucket, 0)\n",
    "            \n",
    "#             if bucket in coverage_data[level]['metro'].index:\n",
    "#                 coverage_rural = coverage_data[level]['metro'].loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in coverage_data[level]['metro'].columns else 0\n",
    "#                 coverage_urban = coverage_data[level]['metro'].loc[bucket, 'Metropolitan'] if 'Metropolitan' in coverage_data[level]['metro'].columns else 0\n",
    "#             else:\n",
    "#                 coverage_rural = coverage_urban = 0\n",
    "            \n",
    "#             row[f'total_{level}_coverage_pct'] = round(float(coverage_total), 2)\n",
    "#             row[f'rural_{level}_coverage_pct'] = round(float(coverage_rural), 2)\n",
    "#             row[f'urban_{level}_coverage_pct'] = round(float(coverage_urban), 2)\n",
    "        \n",
    "#         results.append(row)\n",
    "    \n",
    "#     coverage_df = pd.DataFrame(results)\n",
    "#     coverage_df['pop_label'] = pd.Categorical(coverage_df['pop_label'], categories=all_buckets, ordered=True)\n",
    "    \n",
    "#     print(f\"    Optimized SOC coverage calculation complete for {unit_type}\")\n",
    "#     return coverage_df.sort_values('pop_label').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02723418-1dae-4755-9860-a1ce142b73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_soc_coverage_vectorized(employed_with_pop, unit_pop, unit_type, total_us_employment, full_county_universe=None):\n",
    "    \"\"\"\n",
    "    Calculate SOC coverage using vectorized operations for efficiency.\n",
    "    Updated to support full county universe for accurate county counts.\n",
    "    \"\"\"\n",
    "    print(f\"  Starting optimized SOC coverage calculation for {unit_type}...\")\n",
    "    \n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']\n",
    "    unit_label = 'pumas' if unit_type == 'PUMA' else 'counties'\n",
    "    soc_levels = ['soc_2digit', 'soc_3digit', 'soc_4digit', 'soc_5digit', 'soc_6digit']\n",
    "    \n",
    "    # Determine if using full universe for county counts\n",
    "    use_full_universe = (unit_type == 'County' and full_county_universe is not None)\n",
    "    \n",
    "    if use_full_universe:\n",
    "        print(f\"    Using full county universe for accurate county counts...\")\n",
    "        # Create county_fips if not exists\n",
    "        if 'county_fips' not in employed_with_pop.columns:\n",
    "            employed_with_pop['county_fips'] = (\n",
    "                employed_with_pop['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "                employed_with_pop['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "            )\n",
    "        \n",
    "        # Create metro label mapping\n",
    "        employed_with_pop['metro_label'] = employed_with_pop['metro_status'].map({\n",
    "            'Non-metro/Rural': 'Rural',\n",
    "            'Metropolitan': 'Urban'\n",
    "        })\n",
    "        \n",
    "        # Get metro mapping from ACS data\n",
    "        metro_mapping = employed_with_pop[['county_fips', 'metro_label']].drop_duplicates()\n",
    "        \n",
    "        # FIXED: Use full universe for counts, estimate metro status for missing counties\n",
    "        universe_with_metro = full_county_universe.merge(metro_mapping, on='county_fips', how='left')\n",
    "        \n",
    "        counties_without_metro = universe_with_metro['metro_label'].isna().sum()\n",
    "        print(f\"    Warning: {counties_without_metro} counties have no ACS metro status\")\n",
    "        \n",
    "        # For missing metro status, estimate based on population size (simple heuristic)\n",
    "        # Counties over 50K are more likely to be urban\n",
    "        universe_with_metro.loc[\n",
    "            universe_with_metro['metro_label'].isna() & \n",
    "            universe_with_metro['pop_label'].isin(['75K-100K', '100K-1M', '1M+']), \n",
    "            'metro_label'\n",
    "        ] = 'Urban'\n",
    "        \n",
    "        universe_with_metro.loc[\n",
    "            universe_with_metro['metro_label'].isna(), \n",
    "            'metro_label'\n",
    "        ] = 'Rural'\n",
    "        \n",
    "        # Now use ALL counties for counts\n",
    "        unit_counts_full = universe_with_metro.groupby(['pop_label', 'metro_label']).size().reset_index(name='count')\n",
    "        unit_counts_pivot = unit_counts_full.pivot(index='pop_label', columns='metro_label', values='count').fillna(0)\n",
    "        unit_counts_pivot.columns = ['Non-metro/Rural', 'Metropolitan']  # Standardize column names\n",
    "        unit_totals_full = universe_with_metro.groupby('pop_label').size()\n",
    "        \n",
    "        print(f\"    Using ALL {len(universe_with_metro)} counties for counts (estimated metro status for missing)\")\n",
    "    else:\n",
    "        print(f\"    Using ACS data only for unit counts...\")\n",
    "        # Standardize metro status values\n",
    "        print(f\"    Standardizing metro status values...\")\n",
    "        \n",
    "        employed_with_pop = employed_with_pop.copy()\n",
    "        unit_pop = unit_pop.copy()\n",
    "        \n",
    "        # Map employed data to match unit_pop naming if needed\n",
    "        employed_metro_mapping = {\n",
    "            'Rural': 'Non-metro/Rural',\n",
    "            'Urban': 'Metropolitan'\n",
    "        }\n",
    "        \n",
    "        # Apply mapping if values need to be standardized\n",
    "        if 'Rural' in employed_with_pop['metro_status'].values or 'Urban' in employed_with_pop['metro_status'].values:\n",
    "            employed_with_pop['metro_status'] = employed_with_pop['metro_status'].map(employed_metro_mapping)\n",
    "        \n",
    "        print(f\"    Employment metro status values: {employed_with_pop['metro_status'].unique()}\")\n",
    "        print(f\"    Unit metro status values: {unit_pop['metro_status'].unique()}\")\n",
    "        \n",
    "        # Pre-create bucket categorical to ensure all buckets are present\n",
    "        employed_with_pop['pop_label'] = pd.Categorical(employed_with_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "        unit_pop['pop_label'] = pd.Categorical(unit_pop['pop_label'], categories=all_buckets, ordered=True)\n",
    "        \n",
    "        # Vectorized unit counts by bucket and metro status\n",
    "        print(f\"    Computing unit counts...\")\n",
    "        unit_counts_pivot = unit_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
    "        unit_totals_full = unit_pop.groupby('pop_label').size()\n",
    "    \n",
    "    # Vectorized employment totals by bucket and metro status (always from ACS data)\n",
    "    print(f\"    Computing employment totals...\")\n",
    "    emp_by_bucket_metro = employed_with_pop.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "    emp_by_bucket_total = employed_with_pop.groupby('pop_label')['PERWT'].sum()\n",
    "    \n",
    "    # Calculate SOC coverage by bucket and metro status\n",
    "    print(f\"    Computing SOC coverage rates...\")\n",
    "    \n",
    "    # Pre-calculate ALL SOC coverage by bucket and metro status\n",
    "    coverage_data = {}\n",
    "    \n",
    "    for level in soc_levels:\n",
    "        # Validate SOC level exists\n",
    "        if level not in employed_with_pop.columns:\n",
    "            print(f\"    Warning: {level} not found in data\")\n",
    "            continue\n",
    "            \n",
    "        # Create mask for classified records\n",
    "        classified_mask = employed_with_pop[level] != 'Unclassified'\n",
    "        classified_data = employed_with_pop[classified_mask]\n",
    "        \n",
    "        # Vectorized coverage calculation by bucket and metro status\n",
    "        classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
    "        classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
    "        \n",
    "        # Calculate coverage percentages - vectorized division\n",
    "        coverage_total = (classified_by_bucket_total / emp_by_bucket_total * 100).fillna(0)\n",
    "        \n",
    "        # Handle metro status coverage (avoid division by zero)\n",
    "        coverage_metro = classified_by_bucket_metro.div(emp_by_bucket_metro, fill_value=0) * 100\n",
    "        coverage_metro = coverage_metro.fillna(0)\n",
    "\n",
    "        coverage_data[level] = {\n",
    "            'total': coverage_total,\n",
    "            'metro': coverage_metro\n",
    "        }\n",
    "    \n",
    "    # Build results DataFrame efficiently\n",
    "    print(f\"    Assembling results...\")\n",
    "    results = []\n",
    "    \n",
    "    for bucket in all_buckets:\n",
    "        # Get unit counts (from full universe if available, otherwise from ACS)\n",
    "        n_units_total = unit_totals_full.get(bucket, 0)\n",
    "        \n",
    "        # Better access to unstacked data for unit counts\n",
    "        if bucket in unit_counts_pivot.index:\n",
    "            n_units_rural = unit_counts_pivot.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in unit_counts_pivot.columns else 0\n",
    "            n_units_urban = unit_counts_pivot.loc[bucket, 'Metropolitan'] if 'Metropolitan' in unit_counts_pivot.columns else 0\n",
    "        else:\n",
    "            n_units_rural = n_units_urban = 0\n",
    "        \n",
    "        # Get employment totals with proper index checking\n",
    "        total_emp_all = emp_by_bucket_total.get(bucket, 0)\n",
    "        \n",
    "        # Better access to employment by metro status\n",
    "        if bucket in emp_by_bucket_metro.index:\n",
    "            total_emp_rural = emp_by_bucket_metro.loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in emp_by_bucket_metro.columns else 0\n",
    "            total_emp_urban = emp_by_bucket_metro.loc[bucket, 'Metropolitan'] if 'Metropolitan' in emp_by_bucket_metro.columns else 0\n",
    "        else:\n",
    "            total_emp_rural = total_emp_urban = 0\n",
    "        \n",
    "        # Calculate employment percentages\n",
    "        total_emp_pct = (total_emp_all / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        rural_emp_pct = (total_emp_rural / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        urban_emp_pct = (total_emp_urban / total_us_employment * 100) if total_us_employment > 0 else 0\n",
    "        \n",
    "        # Build row\n",
    "        row = {\n",
    "            'pop_label': bucket,\n",
    "            f'total_{unit_label}': int(n_units_total),\n",
    "            f'rural_{unit_label}': int(n_units_rural),\n",
    "            f'urban_{unit_label}': int(n_units_urban),\n",
    "            'total_employment_pct': round(total_emp_pct, 2),\n",
    "            'rural_employment_pct': round(rural_emp_pct, 2),\n",
    "            'urban_employment_pct': round(urban_emp_pct, 2),\n",
    "            'total_employment': int(total_emp_all),\n",
    "            'rural_employment': int(total_emp_rural),\n",
    "            'urban_employment': int(total_emp_urban)\n",
    "        }\n",
    "        \n",
    "        # Add SOC coverage data for ALL levels\n",
    "        for level in soc_levels:\n",
    "            if level not in coverage_data:\n",
    "                # If level doesn't exist, add zeros\n",
    "                row[f'total_{level}_coverage_pct'] = 0.0\n",
    "                row[f'rural_{level}_coverage_pct'] = 0.0\n",
    "                row[f'urban_{level}_coverage_pct'] = 0.0\n",
    "                continue\n",
    "                \n",
    "            coverage_total = coverage_data[level]['total'].get(bucket, 0)\n",
    "            \n",
    "            if bucket in coverage_data[level]['metro'].index:\n",
    "                coverage_rural = coverage_data[level]['metro'].loc[bucket, 'Non-metro/Rural'] if 'Non-metro/Rural' in coverage_data[level]['metro'].columns else 0\n",
    "                coverage_urban = coverage_data[level]['metro'].loc[bucket, 'Metropolitan'] if 'Metropolitan' in coverage_data[level]['metro'].columns else 0\n",
    "            else:\n",
    "                coverage_rural = coverage_urban = 0\n",
    "            \n",
    "            row[f'total_{level}_coverage_pct'] = round(float(coverage_total), 2)\n",
    "            row[f'rural_{level}_coverage_pct'] = round(float(coverage_rural), 2)\n",
    "            row[f'urban_{level}_coverage_pct'] = round(float(coverage_urban), 2)\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    coverage_df = pd.DataFrame(results)\n",
    "    coverage_df['pop_label'] = pd.Categorical(coverage_df['pop_label'], categories=all_buckets, ordered=True)\n",
    "    \n",
    "    universe_note = \" with full universe\" if use_full_universe else \"\"\n",
    "    print(f\"    Optimized SOC coverage calculation{universe_note} complete for {unit_type}\")\n",
    "    return coverage_df.sort_values('pop_label').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e1795a7-5e2a-4cfa-bc2a-0147d0d6a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EMPLOYMENT SHARE ANALYSIS FUNCTIONS (PART 3)\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_employment_shares_pivot(df_employed, naics_level='naics_2digit', geo_type='PUMA'):\n",
    "    \"\"\"Calculate employment shares showing what % of each area's employment is in each industry\"\"\"\n",
    "    \n",
    "    print(f\"  Calculating employment shares for {naics_level} ({geo_type})...\")\n",
    "    \n",
    "    # Validate input\n",
    "    if naics_level not in df_employed.columns:\n",
    "        print(f\"    Warning: {naics_level} not found in data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if len(df_employed) == 0:\n",
    "        print(f\"    Warning: No data for {naics_level}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Filter out unclassified records\n",
    "    df_analysis = df_employed[df_employed[naics_level] != 'Unclassified'].copy()\n",
    "    \n",
    "    if len(df_analysis) == 0:\n",
    "        print(f\"    Warning: No classified data for {naics_level}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"      Processing {len(df_analysis):,} records...\")\n",
    "    \n",
    "    # Calculate employment by industry, metro status, and population bucket\n",
    "    grouped = (df_analysis.groupby([naics_level, 'metro_status', 'pop_label'])['PERWT']\n",
    "              .sum()\n",
    "              .reset_index())\n",
    "    \n",
    "    # Calculate total employment by geography (metro_status + pop_label combination)\n",
    "    geography_totals = (df_analysis.groupby(['metro_status', 'pop_label'])['PERWT']\n",
    "                       .sum()\n",
    "                       .reset_index()\n",
    "                       .rename(columns={'PERWT': 'total_geography_employment'}))\n",
    "    \n",
    "    # Merge with totals\n",
    "    merged = grouped.merge(geography_totals, on=['metro_status', 'pop_label'], how='left')\n",
    "    \n",
    "    # Calculate percentage shares (each geography sums to 100%)\n",
    "    merged['employment_share'] = (\n",
    "        (merged['PERWT'] / merged['total_geography_employment'] * 100)\n",
    "        .round(2)\n",
    "        .fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Create pivot table - industries as rows, population buckets as columns\n",
    "    try:\n",
    "        pivot = merged.pivot_table(\n",
    "            index=[naics_level, 'metro_status'],\n",
    "            columns='pop_label',\n",
    "            values='employment_share',\n",
    "            fill_value=0\n",
    "        ).reset_index()\n",
    "    except Exception as e:\n",
    "        print(f\"      Error creating pivot: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Ensure all bucket columns exist\n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "    for bucket in all_buckets:\n",
    "        if bucket not in pivot.columns:\n",
    "            pivot[bucket] = 0.0\n",
    "    \n",
    "    # Handle Unknown County for County analysis\n",
    "    if geo_type == 'County' and 'Unknown County' not in pivot.columns:\n",
    "        unknown_county_data = df_analysis[df_analysis['pop_label'] == 'Unknown County'] if 'Unknown County' in df_analysis['pop_label'].values else pd.DataFrame()\n",
    "        if len(unknown_county_data) > 0:\n",
    "            unknown_grouped = (unknown_county_data.groupby([naics_level, 'metro_status'])['PERWT']\n",
    "                             .sum()\n",
    "                             .reset_index())\n",
    "            unknown_totals = (unknown_county_data.groupby(['metro_status', 'pop_label'])['PERWT']\n",
    "                            .sum()\n",
    "                            .reset_index()\n",
    "                            .rename(columns={'PERWT': 'total_unknown_employment'}))\n",
    "            unknown_merged = unknown_grouped.merge(unknown_totals, on=['metro_status'], how='left')\n",
    "            unknown_merged['unknown_share'] = (\n",
    "                (unknown_merged['PERWT'] / unknown_merged['total_unknown_employment'] * 100)\n",
    "                .round(2)\n",
    "                .fillna(0)\n",
    "            )\n",
    "            # Add unknown county data to pivot\n",
    "            pivot = pivot.merge(\n",
    "                unknown_merged[[naics_level, 'metro_status', 'unknown_share']],\n",
    "                on=[naics_level, 'metro_status'],\n",
    "                how='left'\n",
    "            )\n",
    "            pivot['Unknown County'] = pivot['unknown_share'].fillna(0)\n",
    "            pivot = pivot.drop('unknown_share', axis=1)\n",
    "        else:\n",
    "            pivot['Unknown County'] = 0.0\n",
    "    elif geo_type == 'PUMA':\n",
    "        pivot['Unknown County'] = 0.0\n",
    "    \n",
    "    # Order columns correctly\n",
    "    base_columns = [naics_level, 'metro_status']\n",
    "    bucket_columns = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "    column_order = base_columns + bucket_columns\n",
    "    existing_columns = [col for col in column_order if col in pivot.columns]\n",
    "    pivot = pivot[existing_columns]\n",
    "    \n",
    "    # Add industry titles using NAICS mapping if available\n",
    "    print(f\"      Adding industry titles...\")\n",
    "    if 'NAICS_MAPPING' in globals() and NAICS_MAPPING:\n",
    "        def get_industry_title(code):\n",
    "            code_str = str(code).strip()\n",
    "            \n",
    "            # Try direct lookup first\n",
    "            if code_str in NAICS_MAPPING:\n",
    "                mapping_value = NAICS_MAPPING[code_str]\n",
    "                if isinstance(mapping_value, dict):\n",
    "                    return mapping_value.get('title', f'NAICS {code_str}')\n",
    "                elif isinstance(mapping_value, str):\n",
    "                    return mapping_value\n",
    "            \n",
    "            # ENHANCED FALLBACK: Try shorter codes\n",
    "            if len(code_str) > 2:\n",
    "                for fallback_length in [5, 4, 3, 2]:\n",
    "                    if len(code_str) > fallback_length:\n",
    "                        fallback_code = code_str[:fallback_length]\n",
    "                        if fallback_code in NAICS_MAPPING:\n",
    "                            mapping_value = NAICS_MAPPING[fallback_code]\n",
    "                            if isinstance(mapping_value, str):\n",
    "                                return f\"{mapping_value} (detailed)\"\n",
    "            \n",
    "            return f'NAICS {code_str}'\n",
    "    else:\n",
    "        # Fallback to generic titles\n",
    "        def get_industry_title(code):\n",
    "            return f'NAICS {code}'\n",
    "    \n",
    "    unique_codes = pivot[naics_level].unique()\n",
    "    title_mapping = {code: get_industry_title(code) for code in unique_codes}\n",
    "    pivot['industry_title'] = pivot[naics_level].map(title_mapping)\n",
    "    \n",
    "    # Final formatting\n",
    "    pivot.columns.name = None\n",
    "    pivot = pivot.rename(columns={\n",
    "        naics_level: 'industry_code',\n",
    "        'metro_status': 'rural_urban_status'\n",
    "    })\n",
    "    \n",
    "    # Add level and geo identifiers\n",
    "    pivot['naics_level'] = naics_level\n",
    "    pivot['geo_level'] = geo_type\n",
    "    \n",
    "    # Reorder final columns\n",
    "    final_columns = (['naics_level', 'industry_code', 'industry_title', 'rural_urban_status'] + \n",
    "                    bucket_columns + ['geo_level'])\n",
    "    existing_final_columns = [col for col in final_columns if col in pivot.columns]\n",
    "    pivot = pivot[existing_final_columns]\n",
    "    \n",
    "    # Sort for consistent output\n",
    "    pivot['rural_urban_status'] = pd.Categorical(\n",
    "        pivot['rural_urban_status'],\n",
    "        categories=['Non-metro/Rural', 'Metropolitan'],\n",
    "        ordered=True\n",
    "    )\n",
    "    pivot = pivot.sort_values(['industry_code', 'rural_urban_status']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"      Employment shares complete: {len(pivot)} industry-metro combinations\")\n",
    "    return pivot\n",
    "\n",
    "def create_employment_share_analysis(puma_employed, county_employed):\n",
    "    \"\"\"Create employment share analysis for both PUMA and County data across all NAICS levels\"\"\"\n",
    "    \n",
    "    print(\"\\nSTEP 6: Creating Employment Share Analysis...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    naics_levels = ['naics_2digit', 'naics_3digit', 'naics_4digit']\n",
    "    all_results = []\n",
    "    \n",
    "    # PUMA Employment Shares\n",
    "    print(f\"\\n--- PUMA Employment Shares ---\")\n",
    "    for level in naics_levels:\n",
    "        print(f\"  Processing {level}...\")\n",
    "        puma_shares = calculate_employment_shares_pivot(puma_employed, level, 'PUMA')\n",
    "        if len(puma_shares) > 0:\n",
    "            all_results.append(puma_shares)\n",
    "    \n",
    "    # County Employment Shares\n",
    "    print(f\"\\n--- County Employment Shares ---\")\n",
    "    for level in naics_levels:\n",
    "        print(f\"  Processing {level}...\")\n",
    "        county_shares = calculate_employment_shares_pivot(county_employed, level, 'County')\n",
    "        if len(county_shares) > 0:\n",
    "            all_results.append(county_shares)\n",
    "    \n",
    "    # Combine all results\n",
    "    if all_results:\n",
    "        combined_shares = pd.concat(all_results, ignore_index=True)\n",
    "        print(f\"\\n✓ Employment Share Analysis Complete: {len(combined_shares)} total records\")\n",
    "        \n",
    "        # Split back into PUMA and County for return\n",
    "        puma_employment_shares = combined_shares[combined_shares['geo_level'] == 'PUMA'].copy()\n",
    "        county_employment_shares = combined_shares[combined_shares['geo_level'] == 'County'].copy()\n",
    "        \n",
    "        print(f\"  PUMA Employment Shares: {len(puma_employment_shares)} records\")\n",
    "        print(f\"  County Employment Shares: {len(county_employment_shares)} records\")\n",
    "        \n",
    "        # Show sample\n",
    "        if len(combined_shares) > 0:\n",
    "            print(\"\\nSample Employment Share data:\")\n",
    "            sample_cols = ['naics_level', 'industry_code', 'industry_title', 'rural_urban_status', '0-25K', '25K-50K', 'geo_level']\n",
    "            available_cols = [col for col in sample_cols if col in combined_shares.columns]\n",
    "            print(combined_shares[available_cols].head(3))\n",
    "    else:\n",
    "        combined_shares = pd.DataFrame()\n",
    "        puma_employment_shares = pd.DataFrame()\n",
    "        county_employment_shares = pd.DataFrame()\n",
    "        print(f\"\\n⚠ No Employment Share data generated\")\n",
    "    \n",
    "    return puma_employment_shares, county_employment_shares\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4451c6ae-ec5e-45ad-ac44-18c0fb9ad5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SOC EMPLOYMENT SHARE ANALYSIS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_soc_employment_shares_pivot(df_employed, soc_level='soc_2digit', geo_type='PUMA'):\n",
    "    \"\"\"Calculate SOC employment shares showing what % of each area's employment is in each occupation\"\"\"\n",
    "    \n",
    "    print(f\"  Calculating SOC employment shares for {soc_level} ({geo_type})...\")\n",
    "    \n",
    "    # Validate input\n",
    "    if soc_level not in df_employed.columns:\n",
    "        print(f\"    Warning: {soc_level} not found in data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if len(df_employed) == 0:\n",
    "        print(f\"    Warning: No data for {soc_level}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Filter out unclassified records\n",
    "    df_analysis = df_employed[df_employed[soc_level] != 'Unclassified'].copy()\n",
    "    \n",
    "    if len(df_analysis) == 0:\n",
    "        print(f\"    Warning: No classified data for {soc_level}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"      Processing {len(df_analysis):,} records...\")\n",
    "    \n",
    "    # Calculate employment by occupation, metro status, and population bucket\n",
    "    grouped = (df_analysis.groupby([soc_level, 'metro_status', 'pop_label'])['PERWT']\n",
    "              .sum()\n",
    "              .reset_index())\n",
    "    \n",
    "    # Calculate total employment by geography (metro_status + pop_label combination)\n",
    "    geography_totals = (df_analysis.groupby(['metro_status', 'pop_label'])['PERWT']\n",
    "                       .sum()\n",
    "                       .reset_index()\n",
    "                       .rename(columns={'PERWT': 'total_geography_employment'}))\n",
    "    \n",
    "    # Merge with totals\n",
    "    merged = grouped.merge(geography_totals, on=['metro_status', 'pop_label'], how='left')\n",
    "    \n",
    "    # Calculate percentage shares (each geography sums to 100%)\n",
    "    merged['employment_share'] = (\n",
    "        (merged['PERWT'] / merged['total_geography_employment'] * 100)\n",
    "        .round(2)\n",
    "        .fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Create pivot table - occupations as rows, population buckets as columns\n",
    "    try:\n",
    "        pivot = merged.pivot_table(\n",
    "            index=[soc_level, 'metro_status'],\n",
    "            columns='pop_label',\n",
    "            values='employment_share',\n",
    "            fill_value=0\n",
    "        ).reset_index()\n",
    "    except Exception as e:\n",
    "        print(f\"      Error creating pivot: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Ensure all bucket columns exist\n",
    "    all_buckets = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "    for bucket in all_buckets:\n",
    "        if bucket not in pivot.columns:\n",
    "            pivot[bucket] = 0.0\n",
    "    \n",
    "    # Handle Unknown County for County analysis\n",
    "    if geo_type == 'County' and 'Unknown County' not in pivot.columns:\n",
    "        unknown_county_data = df_analysis[df_analysis['pop_label'] == 'Unknown County'] if 'Unknown County' in df_analysis['pop_label'].values else pd.DataFrame()\n",
    "        if len(unknown_county_data) > 0:\n",
    "            unknown_grouped = (unknown_county_data.groupby([soc_level, 'metro_status'])['PERWT']\n",
    "                             .sum()\n",
    "                             .reset_index())\n",
    "            unknown_totals = (unknown_county_data.groupby(['metro_status', 'pop_label'])['PERWT']\n",
    "                            .sum()\n",
    "                            .reset_index()\n",
    "                            .rename(columns={'PERWT': 'total_unknown_employment'}))\n",
    "            unknown_merged = unknown_grouped.merge(unknown_totals, on=['metro_status'], how='left')\n",
    "            unknown_merged['unknown_share'] = (\n",
    "                (unknown_merged['PERWT'] / unknown_merged['total_unknown_employment'] * 100)\n",
    "                .round(2)\n",
    "                .fillna(0)\n",
    "            )\n",
    "            # Add unknown county data to pivot\n",
    "            pivot = pivot.merge(\n",
    "                unknown_merged[[soc_level, 'metro_status', 'unknown_share']],\n",
    "                on=[soc_level, 'metro_status'],\n",
    "                how='left'\n",
    "            )\n",
    "            pivot['Unknown County'] = pivot['unknown_share'].fillna(0)\n",
    "            pivot = pivot.drop('unknown_share', axis=1)\n",
    "        else:\n",
    "            pivot['Unknown County'] = 0.0\n",
    "    elif geo_type == 'PUMA':\n",
    "        pivot['Unknown County'] = 0.0\n",
    "    \n",
    "    # Order columns correctly\n",
    "    base_columns = [soc_level, 'metro_status']\n",
    "    bucket_columns = ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "    column_order = base_columns + bucket_columns\n",
    "    existing_columns = [col for col in column_order if col in pivot.columns]\n",
    "    pivot = pivot[existing_columns]\n",
    "    \n",
    "    # Add occupation titles using SOC mapping if available\n",
    "    print(f\"      Adding occupation titles...\")\n",
    "    if 'SOC_MAPPING' in globals() and SOC_MAPPING:\n",
    "        # Use the loaded SOC mapping\n",
    "        def get_occupation_title(code):\n",
    "            code_str = str(code).strip()\n",
    "            # Look for this code in the SOC mapping\n",
    "            for acs_code, soc_hierarchy in SOC_MAPPING.items():\n",
    "                # Check different SOC levels\n",
    "                for soc_level_check in ['soc2_code', 'soc3_code', 'soc4_code', 'soc5_code', 'soc6_code']:\n",
    "                    if soc_hierarchy.get(soc_level_check) == code_str:\n",
    "                        title_key = soc_level_check.replace('_code', '_title')\n",
    "                        return soc_hierarchy.get(title_key, f'SOC {code_str}')\n",
    "            \n",
    "            # Fallback to basic SOC titles\n",
    "            basic_soc_titles = {\n",
    "                '11': 'Management Occupations',\n",
    "                '13': 'Business and Financial Operations',\n",
    "                '15': 'Computer and Mathematical Occupations',\n",
    "                '17': 'Architecture and Engineering Occupations',\n",
    "                '19': 'Life, Physical, and Social Science Occupations',\n",
    "                '21': 'Community and Social Service Occupations',\n",
    "                '23': 'Legal Occupations',\n",
    "                '25': 'Educational Instruction and Library Occupations',\n",
    "                '27': 'Arts, Design, Entertainment, Sports, and Media Occupations',\n",
    "                '29': 'Healthcare Practitioners and Technical Occupations',\n",
    "                '31': 'Healthcare Support Occupations',\n",
    "                '33': 'Protective Service Occupations',\n",
    "                '35': 'Food Preparation and Serving Related Occupations',\n",
    "                '37': 'Building and Grounds Cleaning and Maintenance Occupations',\n",
    "                '39': 'Personal Care and Service Occupations',\n",
    "                '41': 'Sales and Related Occupations',\n",
    "                '43': 'Office and Administrative Support Occupations',\n",
    "                '45': 'Farming, Fishing, and Forestry Occupations',\n",
    "                '47': 'Construction and Extraction Occupations',\n",
    "                '49': 'Installation, Maintenance, and Repair Occupations',\n",
    "                '51': 'Production Occupations',\n",
    "                '53': 'Transportation and Material Moving Occupations',\n",
    "                '55': 'Military Specific Occupations'\n",
    "            }\n",
    "            \n",
    "            # Use 2-digit code for basic titles\n",
    "            code_2digit = code_str[:2] if len(code_str) >= 2 else code_str\n",
    "            return basic_soc_titles.get(code_2digit, f'SOC {code_str}')\n",
    "    else:\n",
    "        # Fallback to generic titles\n",
    "        def get_occupation_title(code):\n",
    "            return f'SOC {code}'\n",
    "    \n",
    "    unique_codes = pivot[soc_level].unique()\n",
    "    title_mapping = {code: get_occupation_title(code) for code in unique_codes}\n",
    "    pivot['occupation_title'] = pivot[soc_level].map(title_mapping)\n",
    "    \n",
    "    # Final formatting\n",
    "    pivot.columns.name = None\n",
    "    pivot = pivot.rename(columns={\n",
    "        soc_level: 'occupation_code',\n",
    "        'metro_status': 'rural_urban_status'\n",
    "    })\n",
    "    \n",
    "    # Add level and geo identifiers\n",
    "    pivot['soc_level'] = soc_level\n",
    "    pivot['geo_level'] = geo_type\n",
    "    \n",
    "    # Reorder final columns\n",
    "    final_columns = (['soc_level', 'occupation_code', 'occupation_title', 'rural_urban_status'] + \n",
    "                    bucket_columns + ['geo_level'])\n",
    "    existing_final_columns = [col for col in final_columns if col in pivot.columns]\n",
    "    pivot = pivot[existing_final_columns]\n",
    "    \n",
    "    # Sort for consistent output\n",
    "    pivot['rural_urban_status'] = pd.Categorical(\n",
    "        pivot['rural_urban_status'],\n",
    "        categories=['Non-metro/Rural', 'Metropolitan'],\n",
    "        ordered=True\n",
    "    )\n",
    "    pivot = pivot.sort_values(['occupation_code', 'rural_urban_status']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"      SOC employment shares complete: {len(pivot)} occupation-metro combinations\")\n",
    "    return pivot\n",
    "    \n",
    "def create_soc_employment_share_analysis(puma_employed, county_employed):\n",
    "    \"\"\"Create SOC employment share analysis for both PUMA and County data across all SOC levels\"\"\"\n",
    "    \n",
    "    print(\"\\nCreating SOC Employment Share Analysis...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    soc_levels = ['soc_2digit', 'soc_3digit', 'soc_4digit']\n",
    "    all_results = []\n",
    "    \n",
    "    # PUMA SOC Employment Shares\n",
    "    print(f\"\\n--- PUMA SOC Employment Shares ---\")\n",
    "    for level in soc_levels:\n",
    "        print(f\"  Processing {level}...\")\n",
    "        puma_shares = calculate_soc_employment_shares_pivot(puma_employed, level, 'PUMA')\n",
    "        if len(puma_shares) > 0:\n",
    "            all_results.append(puma_shares)\n",
    "    \n",
    "    # County SOC Employment Shares\n",
    "    print(f\"\\n--- County SOC Employment Shares ---\")\n",
    "    for level in soc_levels:\n",
    "        print(f\"  Processing {level}...\")\n",
    "        county_shares = calculate_soc_employment_shares_pivot(county_employed, level, 'County')\n",
    "        if len(county_shares) > 0:\n",
    "            all_results.append(county_shares)\n",
    "    \n",
    "    # Combine all results\n",
    "    if all_results:\n",
    "        combined_shares = pd.concat(all_results, ignore_index=True)\n",
    "        print(f\"\\n✓ SOC Employment Share Analysis Complete: {len(combined_shares)} total records\")\n",
    "        \n",
    "        # Split back into PUMA and County for return\n",
    "        puma_soc_employment_shares = combined_shares[combined_shares['geo_level'] == 'PUMA'].copy()\n",
    "        county_soc_employment_shares = combined_shares[combined_shares['geo_level'] == 'County'].copy()\n",
    "        \n",
    "        print(f\"  PUMA SOC Employment Shares: {len(puma_soc_employment_shares)} records\")\n",
    "        print(f\"  County SOC Employment Shares: {len(county_soc_employment_shares)} records\")\n",
    "        \n",
    "        # Show sample\n",
    "        if len(combined_shares) > 0:\n",
    "            print(\"\\nSample SOC Employment Share data:\")\n",
    "            sample_cols = ['soc_level', 'occupation_code', 'occupation_title', 'rural_urban_status', '0-25K', '25K-50K', 'geo_level']\n",
    "            available_cols = [col for col in sample_cols if col in combined_shares.columns]\n",
    "            print(combined_shares[available_cols].head(3))\n",
    "    else:\n",
    "        combined_shares = pd.DataFrame()\n",
    "        puma_soc_employment_shares = pd.DataFrame()\n",
    "        county_soc_employment_shares = pd.DataFrame()\n",
    "        print(f\"\\n⚠ No SOC Employment Share data generated\")\n",
    "    \n",
    "    return puma_soc_employment_shares, county_soc_employment_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2e2f103-c46e-4f13-8ada-f0a8f1a10fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_missing_counties_analysis(county_employed, full_county_universe):\n",
    "    \"\"\"\n",
    "    Create detailed analysis of missing counties between Snowflake and ACS datasets\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating missing counties analysis...\")\n",
    "    \n",
    "    # Get county sets\n",
    "    counties_with_acs = set(county_employed['county_fips'].unique())\n",
    "    counties_in_snowflake = set(full_county_universe['county_fips'].unique())\n",
    "    \n",
    "    # Find missing counties (in Snowflake but not in ACS)\n",
    "    missing_from_acs = counties_in_snowflake - counties_with_acs\n",
    "    \n",
    "    # Find extra counties (in ACS but not in Snowflake) \n",
    "    missing_from_snowflake = counties_with_acs - counties_in_snowflake\n",
    "    \n",
    "    # Create missing counties dataframe\n",
    "    missing_counties_data = []\n",
    "    \n",
    "    for fips in sorted(missing_from_acs):\n",
    "        county_info = full_county_universe[full_county_universe['county_fips'] == fips].iloc[0]\n",
    "        missing_counties_data.append({\n",
    "            'county_fips': fips,\n",
    "            'county_name': county_info['county_name'],\n",
    "            'pop_label': county_info['pop_label'],\n",
    "            'status': 'Missing from ACS',\n",
    "            'reason': 'No employment data available'\n",
    "        })\n",
    "    \n",
    "    for fips in sorted(missing_from_snowflake):\n",
    "        # Get county info from ACS data\n",
    "        county_info = county_employed[county_employed['county_fips'] == fips].iloc[0]\n",
    "        missing_counties_data.append({\n",
    "            'county_fips': fips,\n",
    "            'county_name': f\"Unknown county {fips}\",  # We don't have names in ACS\n",
    "            'pop_label': county_info['pop_label'],\n",
    "            'status': 'Missing from Snowflake',\n",
    "            'reason': 'Not in population dataset'\n",
    "        })\n",
    "    \n",
    "    missing_counties_df = pd.DataFrame(missing_counties_data)\n",
    "    \n",
    "    # Create coverage summary by population bucket\n",
    "    coverage_summary = []\n",
    "    \n",
    "    for bucket in ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']:\n",
    "        # Counties in this bucket from Snowflake\n",
    "        snowflake_bucket = full_county_universe[full_county_universe['pop_label'] == bucket]\n",
    "        total_counties = len(snowflake_bucket)\n",
    "        \n",
    "        # How many have ACS data\n",
    "        bucket_fips = set(snowflake_bucket['county_fips'])\n",
    "        covered_counties = len(bucket_fips.intersection(counties_with_acs))\n",
    "        missing_counties = len(bucket_fips - counties_with_acs)\n",
    "        \n",
    "        # Calculate employment records for covered counties\n",
    "        if covered_counties > 0:\n",
    "            covered_fips = bucket_fips.intersection(counties_with_acs)\n",
    "            employment_records = len(county_employed[county_employed['county_fips'].isin(covered_fips)])\n",
    "        else:\n",
    "            employment_records = 0\n",
    "        \n",
    "        coverage_summary.append({\n",
    "            'population_bucket': bucket,\n",
    "            'total_counties_snowflake': total_counties,\n",
    "            'counties_with_acs_data': covered_counties,\n",
    "            'counties_missing_from_acs': missing_counties,\n",
    "            'coverage_percentage': round(covered_counties / total_counties * 100, 0) if total_counties > 0 else 0,\n",
    "            'employment_records': employment_records\n",
    "        })\n",
    "    \n",
    "    coverage_summary_df = pd.DataFrame(coverage_summary)\n",
    "    \n",
    "    print(f\"✓ Missing counties analysis complete:\")\n",
    "    print(f\"  Counties missing from ACS: {len(missing_from_acs)}\")\n",
    "    print(f\"  Counties missing from Snowflake: {len(missing_from_snowflake)}\")\n",
    "    print(f\"  Counties in both datasets: {len(counties_with_acs.intersection(counties_in_snowflake))}\")\n",
    "    \n",
    "    return missing_counties_df, coverage_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fde5c32d-aee2-4913-9b17-f908f5c683b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SEQUENTIAL ANALYSIS STEPS - CLEANED\n",
    "# ============================================================================\n",
    "\n",
    "def step_1_load_data():\n",
    "    print(\"STEP 1: Loading data...\")\n",
    "    df = load_and_prepare_data(\"usa_00052.csv.gz\")\n",
    "    print(f\"✓ Data loaded: {len(df):,} records, {df.shape[1]} columns\")\n",
    "    print(f\"✓ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "    key_cols = ['EMPSTAT', 'INDNAICS', 'OCCSOC', 'PUMA', 'COUNTYICP', 'MET2013', 'PERWT']\n",
    "    for col in key_cols:\n",
    "        print(f\"  {'✓' if col in df.columns else '✗'} {col}\")\n",
    "\n",
    "    print(\"\\nSample of raw data:\")\n",
    "    print(df[['EMPSTAT', 'INDNAICS', 'OCCSOC', 'PERWT']].head(3))\n",
    "    return df\n",
    "\n",
    "def step_2_add_classifications(df):\n",
    "    print(\"\\nSTEP 2: Adding NAICS and SOC classifications...\")\n",
    "    df = add_classifications(df)\n",
    "    print(\"✓ Classifications added\")\n",
    "    return df\n",
    "\n",
    "def step_3_prepare_employment_data(df, full_county_universe=None):\n",
    "    # Filter employed individuals with valid NAICS + SOC\n",
    "    puma_employed = filter_employment_data(df, 'PUMA')\n",
    "    county_employed = filter_employment_data(df, 'County')\n",
    "\n",
    "    # Add geo features, population buckets, metro status\n",
    "    puma_employed = add_geographic_features(puma_employed, 'PUMA', full_dataset=df)\n",
    "    county_employed = add_geographic_features(county_employed, 'County', full_dataset=df)\n",
    "\n",
    "    # Apply Snowflake population labels to county ACS data\n",
    "    if full_county_universe is not None:\n",
    "        print(\"Applying Snowflake population labels to ACS county data...\")\n",
    "        \n",
    "        # Ensure county_fips exists\n",
    "        if 'county_fips' not in county_employed.columns:\n",
    "            county_employed['county_fips'] = (\n",
    "                county_employed['STATEFIP'].astype(int).astype(str).str.zfill(2) + \n",
    "                county_employed['COUNTYFIP'].astype(int).astype(str).str.zfill(3)\n",
    "            )\n",
    "        \n",
    "        # Replace ACS pop_label with Snowflake pop_label\n",
    "        pop_mapping = full_county_universe.set_index('county_fips')['pop_label'].to_dict()\n",
    "        county_employed['pop_label_original'] = county_employed['pop_label']  # Keep original for reference\n",
    "        county_employed['pop_label'] = county_employed['county_fips'].map(pop_mapping)\n",
    "        \n",
    "        # Handle any unmapped counties (keep original if no Snowflake data)\n",
    "        county_employed['pop_label'] = county_employed['pop_label'].fillna(county_employed['pop_label_original'])\n",
    "        \n",
    "        print(f\"✓ Population labels updated for {len(county_employed)} county records\")\n",
    "        \n",
    "        # Show the impact\n",
    "        remapped_count = (county_employed['pop_label'] != county_employed['pop_label_original']).sum()\n",
    "        print(f\"✓ {remapped_count} records had population labels updated\")\n",
    "\n",
    "    print(\"✓ Employment data prepared with population + metro features.\")\n",
    "    return puma_employed, county_employed\n",
    "\n",
    "\n",
    "def step_4_create_naics_coverage_analysis(puma_employed, county_employed, full_county_universe=None):\n",
    "    return create_coverage_analysis(puma_employed, county_employed, full_county_universe)\n",
    "\n",
    "def step_5_create_soc_coverage_analysis(puma_employed, county_employed, full_county_universe=None):\n",
    "    total_us_employment_puma = puma_employed['PERWT'].sum()\n",
    "    total_us_employment_county = county_employed['PERWT'].sum()\n",
    "\n",
    "    puma_unit_pop = create_unit_population_summary(puma_employed, 'PUMA')\n",
    "    county_unit_pop = create_unit_population_summary(county_employed, 'County')\n",
    "\n",
    "    puma_soc_coverage = calculate_soc_coverage_vectorized(\n",
    "        puma_employed, puma_unit_pop, 'PUMA', total_us_employment_puma\n",
    "    )\n",
    "    county_soc_coverage = calculate_soc_coverage_vectorized(\n",
    "        county_employed, county_unit_pop, 'County', total_us_employment_county,\n",
    "        full_county_universe=full_county_universe  # ← Add this\n",
    "    )\n",
    "    return puma_soc_coverage, county_soc_coverage\n",
    "\n",
    "def step_6_create_employment_share_analysis(puma_employed, county_employed):\n",
    "    return create_employment_share_analysis(puma_employed, county_employed)\n",
    "\n",
    "def step_6b_create_soc_employment_share_analysis(puma_employed, county_employed):\n",
    "    return create_soc_employment_share_analysis(puma_employed, county_employed)\n",
    "\n",
    "def step_8_export_to_excel_extended(\n",
    "    puma_coverage, county_coverage,\n",
    "    puma_soc_coverage, county_soc_coverage,\n",
    "    puma_employment_shares, county_employment_shares,\n",
    "    soc_employment_shares_puma, soc_employment_shares_county,\n",
    "    naics_presence_puma, naics_presence_county,\n",
    "    soc_presence_puma, soc_presence_county,\n",
    "    missing_counties_df, coverage_summary_df,  # Add these parameters\n",
    "    naics_output_path=\"naics_employment_analysis.xlsx\",\n",
    "    soc_output_path=\"soc_employment_analysis.xlsx\",\n",
    "    missing_counties_path=\"missing_counties_analysis.xlsx\"  # Add this parameter\n",
    "):\n",
    "    print(\"\\nSTEP 8: Exporting NAICS results to Excel...\")\n",
    "    with pd.ExcelWriter(naics_output_path, engine='xlsxwriter') as writer:\n",
    "        puma_coverage.to_excel(writer, sheet_name=\"NAICS PUMA Coverage\", index=False)\n",
    "        county_coverage.to_excel(writer, sheet_name=\"NAICS County Coverage\", index=False)\n",
    "        puma_employment_shares.to_excel(writer, sheet_name=\"NAICS PUMA Shares\", index=False)\n",
    "        county_employment_shares.to_excel(writer, sheet_name=\"NAICS County Shares\", index=False)\n",
    "        naics_presence_puma.to_excel(writer, sheet_name=\"NAICS PUMA Presence\", index=False)\n",
    "        naics_presence_county.to_excel(writer, sheet_name=\"NAICS County Presence\", index=False)\n",
    "    print(f\"✓ NAICS Excel exported: {naics_output_path}\")\n",
    "\n",
    "    print(\"\\nSTEP 8: Exporting SOC results to Excel...\")\n",
    "    with pd.ExcelWriter(soc_output_path, engine='xlsxwriter') as writer:\n",
    "        puma_soc_coverage.to_excel(writer, sheet_name=\"SOC PUMA Coverage\", index=False)\n",
    "        county_soc_coverage.to_excel(writer, sheet_name=\"SOC County Coverage\", index=False)\n",
    "        soc_employment_shares_puma.to_excel(writer, sheet_name=\"SOC PUMA Shares\", index=False)\n",
    "        soc_employment_shares_county.to_excel(writer, sheet_name=\"SOC County Shares\", index=False)\n",
    "        soc_presence_puma.to_excel(writer, sheet_name=\"SOC PUMA Presence\", index=False)\n",
    "        soc_presence_county.to_excel(writer, sheet_name=\"SOC County Presence\", index=False)\n",
    "    print(f\"✓ SOC Excel exported: {soc_output_path}\")\n",
    "    \n",
    "    print(f\"\\nSTEP 8: Exporting missing counties analysis to Excel...\")\n",
    "    with pd.ExcelWriter(missing_counties_path, engine='xlsxwriter') as writer:\n",
    "        # Missing counties details\n",
    "        missing_counties_df.to_excel(writer, sheet_name=\"Missing Counties Detail\", index=False)\n",
    "        \n",
    "        # Coverage summary by population bucket\n",
    "        coverage_summary_df.to_excel(writer, sheet_name=\"Coverage by Pop Bucket\", index=False)\n",
    "        \n",
    "        # Get workbook and add formatting\n",
    "        workbook = writer.book\n",
    "        \n",
    "        # Format coverage summary sheet\n",
    "        worksheet = writer.sheets['Coverage by Pop Bucket']\n",
    "        \n",
    "        # Add percentage format (divide by 100 since we're storing as whole numbers)\n",
    "        percent_format = workbook.add_format({'num_format': '0\"%\"'})\n",
    "        worksheet.set_column('E:E', 15, percent_format)  # coverage_percentage column\n",
    "        \n",
    "        # Add number format with commas\n",
    "        number_format = workbook.add_format({'num_format': '#,##0'})\n",
    "        worksheet.set_column('B:D', 15, number_format)  # count columns\n",
    "        worksheet.set_column('F:F', 15, number_format)  # employment_records column\n",
    "    \n",
    "    print(f\"✓ Missing counties analysis exported: {missing_counties_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def step_9_final_summary(analysis_results):\n",
    "    print_final_summary(analysis_results)\n",
    "\n",
    "def step_10_geographic_analysis(puma_employed, county_employed, full_county_universe=None):\n",
    "    \"\"\"STEP 10: Geographic presence analysis\"\"\"\n",
    "    print(\"\\nSTEP 10: Geographic Presence Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # PUMA analysis (no full universe available)\n",
    "    naics_presence_puma = create_naics_representation_matrix(puma_employed, unit='PUMA')\n",
    "    soc_presence_puma = create_soc_representation_matrix(puma_employed, unit='PUMA')\n",
    "    \n",
    "    # County analysis with optional full universe\n",
    "    naics_presence_county = create_naics_representation_matrix(\n",
    "        county_employed, unit='County', full_county_universe=full_county_universe\n",
    "    )\n",
    "    soc_presence_county = create_soc_representation_matrix(\n",
    "        county_employed, unit='County', full_county_universe=full_county_universe\n",
    "    )\n",
    "    \n",
    "    return naics_presence_puma, naics_presence_county, soc_presence_puma, soc_presence_county\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9fb721b-4d70-49ac-a706-ef3156c6cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# POST-PIPELINE VERIFICATION CHECKS (Remove when satisfied)\n",
    "# ============================================================================\n",
    "\n",
    "def verify_pipeline_fixes(county_employed, full_county_universe):\n",
    "    \"\"\"\n",
    "    Comprehensive verification that all fixes are working correctly\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"POST-PIPELINE VERIFICATION CHECKS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Verify Denton County population classification\n",
    "    print(\"\\n1. DENTON COUNTY POPULATION CLASSIFICATION:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    denton_county = county_employed[county_employed['county_fips'] == '48121']\n",
    "    if len(denton_county) > 0:\n",
    "        current_pop_label = denton_county['pop_label'].iloc[0]\n",
    "        if 'pop_label_original' in county_employed.columns:\n",
    "            original_pop_label = denton_county['pop_label_original'].iloc[0]\n",
    "            print(f\"   Records found: {len(denton_county):,}\")\n",
    "            print(f\"   Original ACS classification: {original_pop_label}\")\n",
    "            print(f\"   Current classification: {current_pop_label}\")\n",
    "            \n",
    "            if current_pop_label == '1M+' and original_pop_label != '1M+':\n",
    "                print(\"   ✓ SUCCESS: Denton County reclassified from ACS to Snowflake population\")\n",
    "            elif current_pop_label == '1M+':\n",
    "                print(\"   ✓ SUCCESS: Denton County correctly classified as 1M+\")\n",
    "            else:\n",
    "                print(f\"   ✗ ISSUE: Denton County not classified as 1M+ (currently: {current_pop_label})\")\n",
    "        else:\n",
    "            print(f\"   Records found: {len(denton_county):,}\")\n",
    "            print(f\"   Current classification: {current_pop_label}\")\n",
    "            if current_pop_label == '1M+':\n",
    "                print(\"   ✓ SUCCESS: Denton County classified as 1M+\")\n",
    "            else:\n",
    "                print(f\"   ✗ ISSUE: Denton County not classified as 1M+ (currently: {current_pop_label})\")\n",
    "    else:\n",
    "        print(\"   ✗ ISSUE: Denton County (48121) not found in data\")\n",
    "    \n",
    "    # 2. Overall 1M+ county coverage check\n",
    "    print(\"\\n2. 1M+ COUNTY COVERAGE ANALYSIS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Counties that should be 1M+ (from Snowflake)\n",
    "    counties_1m_snowflake = set(full_county_universe[full_county_universe['pop_label'] == '1M+']['county_fips'])\n",
    "    \n",
    "    # Counties with ACS data\n",
    "    counties_with_acs = set(county_employed['county_fips'].unique())\n",
    "    \n",
    "    # Counties classified as 1M+ in current ACS data\n",
    "    counties_1m_acs = set(county_employed[county_employed['pop_label'] == '1M+']['county_fips'].unique())\n",
    "    \n",
    "    total_1m_snowflake = len(counties_1m_snowflake)\n",
    "    covered_1m = len(counties_1m_snowflake.intersection(counties_with_acs))\n",
    "    classified_1m = len(counties_1m_snowflake.intersection(counties_1m_acs))\n",
    "    \n",
    "    print(f\"   Total 1M+ counties (Snowflake): {total_1m_snowflake}\")\n",
    "    print(f\"   1M+ counties with ACS data: {covered_1m}\")\n",
    "    print(f\"   1M+ counties classified as 1M+ in ACS: {classified_1m}\")\n",
    "    print(f\"   Coverage rate: {covered_1m/total_1m_snowflake*100:.0f}%\")\n",
    "    print(f\"   Classification accuracy: {classified_1m/covered_1m*100:.0f}%\" if covered_1m > 0 else \"   Classification accuracy: N/A\")\n",
    "    \n",
    "    # Show missing counties\n",
    "    missing_counties = counties_1m_snowflake - counties_with_acs\n",
    "    if missing_counties:\n",
    "        print(f\"\\n   Missing 1M+ counties ({len(missing_counties)}):\")\n",
    "        for fips in sorted(missing_counties):\n",
    "            county_name = full_county_universe[full_county_universe['county_fips'] == fips]['county_name'].iloc[0]\n",
    "            print(f\"     {fips}: {county_name}\")\n",
    "    \n",
    "    # Show misclassified counties\n",
    "    misclassified = counties_with_acs.intersection(counties_1m_snowflake) - counties_1m_acs\n",
    "    if misclassified:\n",
    "        print(f\"\\n   1M+ counties not classified as 1M+ ({len(misclassified)}):\")\n",
    "        for fips in sorted(misclassified):\n",
    "            county_name = full_county_universe[full_county_universe['county_fips'] == fips]['county_name'].iloc[0]\n",
    "            current_label = county_employed[county_employed['county_fips'] == fips]['pop_label'].iloc[0]\n",
    "            print(f\"     {fips}: {county_name} (classified as: {current_label})\")\n",
    "    \n",
    "    # 3. Population bucket distribution comparison\n",
    "    print(\"\\n3. POPULATION BUCKET DISTRIBUTION:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    acs_dist = county_employed.groupby('pop_label').size().sort_index()\n",
    "    acs_coverage = county_employed.groupby('pop_label')['county_fips'].nunique().sort_index()\n",
    "    \n",
    "    print(f\"   {'Bucket':<12} {'ACS Records':<12} {'Unique Counties':<15}\")\n",
    "    print(f\"   {'-'*12} {'-'*12} {'-'*15}\")\n",
    "    for bucket in ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+']:\n",
    "        records = acs_dist.get(bucket, 0)\n",
    "        counties = acs_coverage.get(bucket, 0)\n",
    "        print(f\"   {bucket:<12} {records:<12,} {counties:<15}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"VERIFICATION COMPLETE\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2aa8bfe-0b60-4b68-bdae-aa8d6be6ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Loading data...\n",
      "Loading data from usa_00052.csv.gz...\n",
      "Loaded 15,912,393 records\n",
      "✓ Data loaded: 15,912,393 records, 24 columns\n",
      "✓ Memory usage: 4503.7 MB\n",
      "  ✓ EMPSTAT\n",
      "  ✓ INDNAICS\n",
      "  ✓ OCCSOC\n",
      "  ✓ PUMA\n",
      "  ✓ COUNTYICP\n",
      "  ✓ MET2013\n",
      "  ✓ PERWT\n",
      "\n",
      "Sample of raw data:\n",
      "   EMPSTAT INDNAICS  OCCSOC  PERWT\n",
      "0        3        0       0    2.0\n",
      "1        3        0       0   14.0\n",
      "2        1     8131  434051    4.0\n",
      "\n",
      "STEP 2: Adding NAICS and SOC classifications...\n",
      "  Processing NAICS with consolidation...\n",
      "  NAICS consolidation applied:\n",
      "    32→31: 229,248 records\n",
      "    33→31: 517,774 records\n",
      "    3M→31: 28,117 records\n",
      "    45→44: 523,956 records\n",
      "    49→48: 162,164 records\n",
      "  Processing SOC...\n",
      "    Processing 9,396,234 SOC records with mapping...\n",
      "  ✓ NAICS classifications created with consolidation\n",
      "  ✓ SOC classifications created\n",
      "✓ Classifications added\n",
      "Creating full county universe from Snowflake data...\n",
      "✓ Full county universe created: 3144 counties\n",
      "Population bucket distribution (all US counties):\n",
      "  0-25K: 1526 counties\n",
      "  100K-1M: 570 counties\n",
      "  1M+: 48 counties\n",
      "  25K-50K: 616 counties\n",
      "  50K-75K: 252 counties\n",
      "  75K-100K: 132 counties\n",
      "\n",
      "STEP 3A: Filtering PUMA employment data...\n",
      "✓ PUMA employment records with valid classifications: 7,366,658\n",
      "  (Filtered out INDNAICS=0 and OCCSOC=0 as unemployed/not applicable)\n",
      "\n",
      "STEP 3A: Filtering County employment data...\n",
      "✓ County employment records with valid classifications: 7,366,658\n",
      "  (Filtered out INDNAICS=0 and OCCSOC=0 as unemployed/not applicable)\n",
      "\n",
      "STEP 3B: Adding geographic features for PUMA...\n",
      "    Using full dataset for population bucketing (total population)...\n",
      "    Total geographic units with population data: 2462\n",
      "\n",
      "PUMA metro status distribution (employment):\n",
      "  Metropolitan: 129,449,470 employed (80.6%)\n",
      "  Non-metro/Rural: 31,133,945 employed (19.4%)\n",
      "\n",
      "PUMA population bucket distribution:\n",
      "  100K-1M: 158,872,334 employed in 2428 PUMAs (98.9%)\n",
      "  75K-100K: 1,711,081 employed in 34 PUMAs (1.1%)\n",
      "\n",
      "STEP 3B: Adding geographic features for County...\n",
      "    Using full dataset for population bucketing (total population)...\n",
      "    Total geographic units with population data: 444\n",
      "    Assigned 2,591,104 employment records to 'Unknown County'\n",
      "\n",
      "County metro status distribution (employment):\n",
      "  Metropolitan: 129,449,470 employed (80.6%)\n",
      "  Non-metro/Rural: 31,133,945 employed (19.4%)\n",
      "\n",
      "County population bucket distribution:\n",
      "  100K-1M: 65,415,723 employed in 399 counties (40.7%)\n",
      "  1M+: 46,130,176 employed in 45 counties (28.7%)\n",
      "  Unknown County: 49,037,516 employed in 49 counties (30.5%)\n",
      "\n",
      "✓ Unknown County check: 2,591,104 employment records, 49,037,516 employment\n",
      "Applying Snowflake population labels to ACS county data...\n",
      "✓ Population labels updated for 7366658 county records\n",
      "✓ 48281 records had population labels updated\n",
      "✓ Employment data prepared with population + metro features.\n",
      "\n",
      "STEP 4: Creating NAICS Coverage Analysis...\n",
      "==================================================\n",
      "Total US Employment (PUMA): 160,583,415\n",
      "Total US Employment (County): 160,583,415\n",
      "\n",
      "--- PUMA NAICS Coverage ---\n",
      "Creating PUMA unit population summary...\n",
      "✓ PUMA unit summary created: 2462 units\n",
      "  Starting optimized NAICS coverage calculation for PUMA...\n",
      "    Using ACS data only for unit counts...\n",
      "    Standardizing metro status values...\n",
      "    Employment metro status values: ['Metropolitan' 'Non-metro/Rural']\n",
      "    Unit metro status values: ['Non-metro/Rural' 'Metropolitan']\n",
      "    Computing unit counts...\n",
      "    Computing employment totals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/858493384.py:89: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  unit_counts_pivot = unit_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/858493384.py:90: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  unit_totals_full = unit_pop.groupby('pop_label').size()\n",
      "/tmp/ipykernel_3793/858493384.py:94: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  emp_by_bucket_metro = employed_with_pop.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/858493384.py:95: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  emp_by_bucket_total = employed_with_pop.groupby('pop_label')['PERWT'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computing NAICS coverage rates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/858493384.py:116: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/858493384.py:117: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
      "/tmp/ipykernel_3793/858493384.py:116: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/858493384.py:117: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
      "/tmp/ipykernel_3793/858493384.py:116: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/858493384.py:117: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Assembling results...\n",
      "    Optimized NAICS coverage calculation complete for PUMA\n",
      "\n",
      "--- County NAICS Coverage ---\n",
      "Using full county universe for accurate coverage percentages...\n",
      "  Starting NAICS coverage calculation with full universe for County...\n",
      "    Warning: 2700 counties have no metro status (excluded)\n",
      "    Counties with metro status: 445 / 3144\n",
      "    NAICS coverage calculation with full universe complete for County\n",
      "✓ Added Unknown County row: 49,037,516 employment\n",
      "\n",
      "✓ PUMA Coverage Analysis Complete: 6 population buckets\n",
      "Sample PUMA coverage data:\n",
      "  pop_label  total_pumas  total_employment_pct  \\\n",
      "0     0-25K            0                   0.0   \n",
      "1   25K-50K            0                   0.0   \n",
      "2   50K-75K            0                   0.0   \n",
      "\n",
      "   total_naics_2digit_coverage_pct  \n",
      "0                              0.0  \n",
      "1                              0.0  \n",
      "2                              0.0  \n",
      "\n",
      "✓ County Coverage Analysis Complete: 7 population buckets\n",
      "Sample County coverage data:\n",
      "  pop_label  total_counties  total_employment_pct  \\\n",
      "0     0-25K               0                   0.0   \n",
      "1   25K-50K               0                   0.0   \n",
      "2   50K-75K               0                   0.0   \n",
      "\n",
      "   total_naics_2digit_coverage_pct  \n",
      "0                              0.0  \n",
      "1                              0.0  \n",
      "2                              0.0  \n",
      "Creating PUMA unit population summary...\n",
      "✓ PUMA unit summary created: 2462 units\n",
      "Creating County unit population summary...\n",
      "✓ County unit summary created: 535 units\n",
      "  Starting optimized SOC coverage calculation for PUMA...\n",
      "    Using ACS data only for unit counts...\n",
      "    Standardizing metro status values...\n",
      "    Employment metro status values: ['Metropolitan' 'Non-metro/Rural']\n",
      "    Unit metro status values: ['Non-metro/Rural' 'Metropolitan']\n",
      "    Computing unit counts...\n",
      "    Computing employment totals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/3137606673.py:86: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  unit_counts_pivot = unit_pop.groupby(['pop_label', 'metro_status']).size().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:87: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  unit_totals_full = unit_pop.groupby('pop_label').size()\n",
      "/tmp/ipykernel_3793/3137606673.py:91: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  emp_by_bucket_metro = employed_with_pop.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:92: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  emp_by_bucket_total = employed_with_pop.groupby('pop_label')['PERWT'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computing SOC coverage rates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/3137606673.py:111: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:112: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
      "/tmp/ipykernel_3793/3137606673.py:111: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:112: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
      "/tmp/ipykernel_3793/3137606673.py:111: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:112: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
      "/tmp/ipykernel_3793/3137606673.py:111: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:112: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n",
      "/tmp/ipykernel_3793/3137606673.py:111: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_metro = classified_data.groupby(['pop_label', 'metro_status'])['PERWT'].sum().unstack(fill_value=0)\n",
      "/tmp/ipykernel_3793/3137606673.py:112: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  classified_by_bucket_total = classified_data.groupby('pop_label')['PERWT'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Assembling results...\n",
      "    Optimized SOC coverage calculation complete for PUMA\n",
      "  Starting optimized SOC coverage calculation for County...\n",
      "    Using full county universe for accurate county counts...\n",
      "    Warning: 2700 counties have no ACS metro status\n",
      "    Using ALL 3145 counties for counts (estimated metro status for missing)\n",
      "    Computing employment totals...\n",
      "    Computing SOC coverage rates...\n",
      "    Assembling results...\n",
      "    Optimized SOC coverage calculation with full universe complete for County\n",
      "\n",
      "STEP 6: Creating Employment Share Analysis...\n",
      "==================================================\n",
      "\n",
      "--- PUMA Employment Shares ---\n",
      "  Processing naics_2digit...\n",
      "  Calculating employment shares for naics_2digit (PUMA)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding industry titles...\n",
      "      Employment shares complete: 42 industry-metro combinations\n",
      "  Processing naics_3digit...\n",
      "  Calculating employment shares for naics_3digit (PUMA)...\n",
      "      Processing 6,883,560 records...\n",
      "      Adding industry titles...\n",
      "      Employment shares complete: 184 industry-metro combinations\n",
      "  Processing naics_4digit...\n",
      "  Calculating employment shares for naics_4digit (PUMA)...\n",
      "      Processing 6,239,805 records...\n",
      "      Adding industry titles...\n",
      "      Employment shares complete: 384 industry-metro combinations\n",
      "\n",
      "--- County Employment Shares ---\n",
      "  Processing naics_2digit...\n",
      "  Calculating employment shares for naics_2digit (County)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding industry titles...\n",
      "      Employment shares complete: 42 industry-metro combinations\n",
      "  Processing naics_3digit...\n",
      "  Calculating employment shares for naics_3digit (County)...\n",
      "      Processing 6,883,560 records...\n",
      "      Adding industry titles...\n",
      "      Employment shares complete: 184 industry-metro combinations\n",
      "  Processing naics_4digit...\n",
      "  Calculating employment shares for naics_4digit (County)...\n",
      "      Processing 6,239,805 records...\n",
      "      Adding industry titles...\n",
      "      Employment shares complete: 384 industry-metro combinations\n",
      "\n",
      "✓ Employment Share Analysis Complete: 1220 total records\n",
      "  PUMA Employment Shares: 610 records\n",
      "  County Employment Shares: 610 records\n",
      "\n",
      "Sample Employment Share data:\n",
      "    naics_level industry_code                                 industry_title  \\\n",
      "0  naics_2digit            11     Agriculture, Forestry, Fishing and Hunting   \n",
      "1  naics_2digit            11     Agriculture, Forestry, Fishing and Hunting   \n",
      "2  naics_2digit            21  Mining, Quarrying, and Oil and Gas Extraction   \n",
      "\n",
      "  rural_urban_status  0-25K  25K-50K geo_level  \n",
      "0    Non-metro/Rural    0.0      0.0      PUMA  \n",
      "1       Metropolitan    0.0      0.0      PUMA  \n",
      "2    Non-metro/Rural    0.0      0.0      PUMA  \n",
      "\n",
      "Creating SOC Employment Share Analysis...\n",
      "==================================================\n",
      "\n",
      "--- PUMA SOC Employment Shares ---\n",
      "  Processing soc_2digit...\n",
      "  Calculating SOC employment shares for soc_2digit (PUMA)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding occupation titles...\n",
      "      SOC employment shares complete: 46 occupation-metro combinations\n",
      "  Processing soc_3digit...\n",
      "  Calculating SOC employment shares for soc_3digit (PUMA)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding occupation titles...\n",
      "      SOC employment shares complete: 196 occupation-metro combinations\n",
      "  Processing soc_4digit...\n",
      "  Calculating SOC employment shares for soc_4digit (PUMA)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding occupation titles...\n",
      "      SOC employment shares complete: 224 occupation-metro combinations\n",
      "\n",
      "--- County SOC Employment Shares ---\n",
      "  Processing soc_2digit...\n",
      "  Calculating SOC employment shares for soc_2digit (County)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding occupation titles...\n",
      "      SOC employment shares complete: 46 occupation-metro combinations\n",
      "  Processing soc_3digit...\n",
      "  Calculating SOC employment shares for soc_3digit (County)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding occupation titles...\n",
      "      SOC employment shares complete: 196 occupation-metro combinations\n",
      "  Processing soc_4digit...\n",
      "  Calculating SOC employment shares for soc_4digit (County)...\n",
      "      Processing 7,366,658 records...\n",
      "      Adding occupation titles...\n",
      "      SOC employment shares complete: 224 occupation-metro combinations\n",
      "\n",
      "✓ SOC Employment Share Analysis Complete: 932 total records\n",
      "  PUMA SOC Employment Shares: 466 records\n",
      "  County SOC Employment Shares: 466 records\n",
      "\n",
      "Sample SOC Employment Share data:\n",
      "    soc_level occupation_code                               occupation_title  \\\n",
      "0  soc_2digit              11                         Management Occupations   \n",
      "1  soc_2digit              11                         Management Occupations   \n",
      "2  soc_2digit              13  Business and Financial Operations Occupations   \n",
      "\n",
      "  rural_urban_status  0-25K  25K-50K geo_level  \n",
      "0    Non-metro/Rural    0.0      0.0      PUMA  \n",
      "1       Metropolitan    0.0      0.0      PUMA  \n",
      "2    Non-metro/Rural    0.0      0.0      PUMA  \n",
      "\n",
      "STEP 10: Geographic Presence Analysis\n",
      "============================================================\n",
      "Creating NAICS representation matrix for PUMA (vectorized)...\n",
      "Using pure ACS denominators (all counties with employment data)...\n",
      "Total ACS counties: 2462\n",
      "ACS denominator breakdown:\n",
      "  100K-1M Rural: 506 counties\n",
      "  100K-1M Urban: 1922 counties\n",
      "  75K-100K Rural: 3 counties\n",
      "  75K-100K Urban: 31 counties\n",
      "  naics_2digit: 21 codes processed\n",
      "  naics_3digit: 92 codes processed\n",
      "  naics_4digit: 192 codes processed\n",
      "  naics_5digit: 76 codes processed\n",
      "  naics_6digit: 13 codes processed\n",
      "✓ NAICS representation matrix (pure ACS denominators): 394 total codes\n",
      "Creating SOC representation matrix for PUMA (vectorized)...\n",
      "Using pure ACS denominators (all counties with employment data)...\n",
      "  soc_2digit: 23 codes processed\n",
      "  soc_3digit: 98 codes processed\n",
      "  soc_4digit: 112 codes processed\n",
      "  soc_5digit: 524 codes processed\n",
      "✓ SOC representation matrix (pure ACS denominators): 757 total codes\n",
      "Creating NAICS representation matrix for County (vectorized)...\n",
      "Using pure ACS denominators (all counties with employment data)...\n",
      "Total ACS counties: 493\n",
      "ACS denominator breakdown:\n",
      "  100K-1M Rural: 47 counties\n",
      "  100K-1M Urban: 353 counties\n",
      "  1M+ Urban: 45 counties\n",
      "  Unknown County Rural: 47 counties\n",
      "  Unknown County Urban: 43 counties\n",
      "  naics_2digit: 21 codes processed\n",
      "  naics_3digit: 92 codes processed\n",
      "  naics_4digit: 192 codes processed\n",
      "  naics_5digit: 76 codes processed\n",
      "  naics_6digit: 13 codes processed\n",
      "✓ NAICS representation matrix (pure ACS denominators): 394 total codes\n",
      "Creating SOC representation matrix for County (vectorized)...\n",
      "Using pure ACS denominators (all counties with employment data)...\n",
      "  soc_2digit: 23 codes processed\n",
      "  soc_3digit: 98 codes processed\n",
      "  soc_4digit: 112 codes processed\n",
      "  soc_5digit: 524 codes processed\n",
      "✓ SOC representation matrix (pure ACS denominators): 757 total codes\n",
      "\n",
      "Creating missing counties analysis...\n",
      "✓ Missing counties analysis complete:\n",
      "  Counties missing from ACS: 2700\n",
      "  Counties missing from Snowflake: 49\n",
      "  Counties in both datasets: 444\n",
      "\n",
      "STEP 8: Exporting NAICS results to Excel...\n",
      "✓ NAICS Excel exported: acs_ipums_naics_file.xlsx\n",
      "\n",
      "STEP 8: Exporting SOC results to Excel...\n",
      "✓ SOC Excel exported: acs_ipums_soc_file.xlsx\n",
      "\n",
      "STEP 8: Exporting missing counties analysis to Excel...\n",
      "✓ Missing counties analysis exported: missing_counties_analysis.xlsx\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE - SUMMARY\n",
      "============================================================\n",
      "NAICS_Coverage Analysis:\n",
      "  PUMA tab: 6 rows\n",
      "  County tab: 7 rows\n",
      "SOC_Coverage Analysis:\n",
      "  PUMA tab: 6 rows\n",
      "  County tab: 6 rows\n",
      "NAICS_Employment_Shares Analysis:\n",
      "  PUMA tab: 610 rows\n",
      "  County tab: 610 rows\n",
      "SOC_Employment_Shares Analysis:\n",
      "  PUMA tab: 466 rows\n",
      "  County tab: 466 rows\n",
      "\n",
      "✓ Analysis complete! You can now open the Excel files to view results.\n",
      "\n",
      "================================================================================\n",
      "POST-PIPELINE VERIFICATION CHECKS\n",
      "================================================================================\n",
      "\n",
      "1. DENTON COUNTY POPULATION CLASSIFICATION:\n",
      "--------------------------------------------------\n",
      "   Records found: 23,090\n",
      "   Original ACS classification: 100K-1M\n",
      "   Current classification: 1M+\n",
      "   ✓ SUCCESS: Denton County reclassified from ACS to Snowflake population\n",
      "\n",
      "2. 1M+ COUNTY COVERAGE ANALYSIS:\n",
      "--------------------------------------------------\n",
      "   Total 1M+ counties (Snowflake): 48\n",
      "   1M+ counties with ACS data: 45\n",
      "   1M+ counties classified as 1M+ in ACS: 45\n",
      "   Coverage rate: 94%\n",
      "   Classification accuracy: 100%\n",
      "\n",
      "   Missing 1M+ counties (3):\n",
      "     04019: Pima County, Arizona\n",
      "     12086: Miami-Dade County, Florida\n",
      "     51059: Fairfax County, Virginia\n",
      "\n",
      "3. POPULATION BUCKET DISTRIBUTION:\n",
      "--------------------------------------------------\n",
      "   Bucket       ACS Records  Unique Counties\n",
      "   ------------ ------------ ---------------\n",
      "   0-25K        0            0              \n",
      "   25K-50K      0            0              \n",
      "   50K-75K      0            0              \n",
      "   75K-100K     0            0              \n",
      "   100K-1M      2,822,034    399            \n",
      "   1M+          1,953,520    45             \n",
      "\n",
      "================================================================================\n",
      "VERIFICATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "# STEP 1: Load raw data\n",
    "df = step_1_load_data()\n",
    "\n",
    "# STEP 2: Add NAICS and SOC classifications\n",
    "df = step_2_add_classifications(df)\n",
    "\n",
    "# STEP 2.5: Load full county universe from Snowflake\n",
    "full_county_universe = create_full_county_universe(county_population_df)\n",
    "\n",
    "# STEP 3: Prepare employment data (includes population mapping)\n",
    "puma_employed, county_employed = step_3_prepare_employment_data(df, full_county_universe)\n",
    "\n",
    "# # STEP 3B: Add geographic features (including metro + pop labels)\n",
    "# puma_employed = add_geographic_features(puma_employed, geo_type='PUMA', full_dataset=df)\n",
    "# county_employed = add_geographic_features(county_employed, geo_type='County', full_dataset=df)\n",
    "\n",
    "# STEP 4: NAICS coverage analysis\n",
    "puma_coverage, county_coverage = step_4_create_naics_coverage_analysis(\n",
    "    puma_employed, county_employed, full_county_universe=full_county_universe\n",
    ")\n",
    "\n",
    "# STEP 5: SOC coverage analysis\n",
    "puma_soc_coverage, county_soc_coverage = step_5_create_soc_coverage_analysis(\n",
    "    puma_employed, county_employed, full_county_universe=full_county_universe\n",
    ")\n",
    "\n",
    "# STEP 6: NAICS employment shares\n",
    "puma_employment_shares, county_employment_shares = step_6_create_employment_share_analysis(puma_employed, county_employed)\n",
    "\n",
    "# STEP 6B: SOC employment shares\n",
    "puma_soc_employment_shares, county_soc_employment_shares = step_6b_create_soc_employment_share_analysis(puma_employed, county_employed)\n",
    "\n",
    "# Step 10: Add combined label for geographic representation analysis\n",
    "naics_rep_puma, naics_rep_county, soc_rep_puma, soc_rep_county = step_10_geographic_analysis(\n",
    "    puma_employed, county_employed, full_county_universe=full_county_universe\n",
    ")\n",
    "\n",
    "# STEP 7.5: Create missing counties analysis\n",
    "missing_counties_df, coverage_summary_df = create_missing_counties_analysis(county_employed, full_county_universe)\n",
    "\n",
    "# STEP 8: Export to Excel (including missing counties analysis)\n",
    "step_8_export_to_excel_extended(\n",
    "    puma_coverage, county_coverage,\n",
    "    puma_soc_coverage, county_soc_coverage,\n",
    "    puma_employment_shares, county_employment_shares,\n",
    "    puma_soc_employment_shares, county_soc_employment_shares,\n",
    "    naics_rep_puma, naics_rep_county,\n",
    "    soc_rep_puma, soc_rep_county,\n",
    "    missing_counties_df, coverage_summary_df,  # Add these\n",
    "    naics_output_path=\"acs_ipums_naics_file.xlsx\",\n",
    "    soc_output_path=\"acs_ipums_soc_file.xlsx\",\n",
    "    missing_counties_path=\"missing_counties_analysis.xlsx\"  # Add this\n",
    ")\n",
    "\n",
    "# STEP 9: Final summary (console only)\n",
    "analysis_results = {\n",
    "    'NAICS_Coverage': (puma_coverage, county_coverage),\n",
    "    'SOC_Coverage': (puma_soc_coverage, county_soc_coverage),\n",
    "    'NAICS_Employment_Shares': (puma_employment_shares, county_employment_shares),\n",
    "    'SOC_Employment_Shares': (puma_soc_employment_shares, county_soc_employment_shares)\n",
    "}\n",
    "step_9_final_summary(analysis_results)\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICATION CHECKS (Remove when satisfied with results)\n",
    "# ============================================================================\n",
    "verify_pipeline_fixes(county_employed, full_county_universe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7100fe4-264c-405a-8cd8-50c4d10a27fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with COUNTYFIP = 0: 2591104\n",
      "Unique county_fips with COUNTYFIP = 0: 49\n",
      "Records with pop_label = 'Unknown County': 2591104\n",
      "Unique county_fips in Unknown County: 49\n",
      "Sample county_fips values: ['01000' '02000' '04000' '05000' '06000' '08000' '09000' '12000' '13000'\n",
      " '15000']\n"
     ]
    }
   ],
   "source": [
    "# Check how many unique county_fips have value '00000' or similar\n",
    "unknown_counties = county_employed[county_employed['COUNTYFIP'] == 0]\n",
    "print(f\"Records with COUNTYFIP = 0: {len(unknown_counties)}\")\n",
    "print(f\"Unique county_fips with COUNTYFIP = 0: {unknown_counties['county_fips'].nunique()}\")\n",
    "\n",
    "# Check what's in pop_label = 'Unknown County'\n",
    "unknown_pop = county_employed[county_employed['pop_label'] == 'Unknown County']\n",
    "print(f\"Records with pop_label = 'Unknown County': {len(unknown_pop)}\")\n",
    "print(f\"Unique county_fips in Unknown County: {unknown_pop['county_fips'].nunique()}\")\n",
    "print(f\"Sample county_fips values: {unknown_pop['county_fips'].unique()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b3693c5-fc52-4d22-8efd-7e99890ad992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUGGING COVERAGE DENOMINATORS\n",
      "================================================================================\n",
      "\n",
      "1. BASIC DATASET COUNTS:\n",
      "   Total counties in Snowflake: 3,144\n",
      "   Counties with ACS employment data: 493\n",
      "\n",
      "2. POPULATION BUCKET BREAKDOWN:\n",
      "   Snowflake population distribution:\n",
      "     0-25K: 1,526 counties\n",
      "     100K-1M: 570 counties\n",
      "     1M+: 48 counties\n",
      "     25K-50K: 616 counties\n",
      "     50K-75K: 252 counties\n",
      "     75K-100K: 132 counties\n",
      "\n",
      "   ACS population distribution (after Snowflake mapping):\n",
      "     100K-1M: 399 counties\n",
      "     1M+: 45 counties\n",
      "     Unknown County: 49 counties\n",
      "\n",
      "3. METRO STATUS BREAKDOWN:\n",
      "   Counties with metro status mapping: 535\n",
      "   Snowflake counties that can be assigned metro status: 445\n",
      "   Snowflake counties without metro status: 2,700\n",
      "\n",
      "4. POPULATION + METRO COMBINATIONS:\n",
      "   Denominator combinations (what rep matrices use):\n",
      "     100K-1M Rural: 47 counties\n",
      "     100K-1M Urban: 353 counties\n",
      "     1M+ Urban: 45 counties\n",
      "\n",
      "   Pure ACS combinations:\n",
      "     100K-1M Rural: 47 counties\n",
      "     100K-1M Urban: 353 counties\n",
      "     1M+ Urban: 45 counties\n",
      "     Unknown County Rural: 47 counties\n",
      "     Unknown County Urban: 43 counties\n",
      "\n",
      "5. COVERAGE COMPARISON:\n",
      "   Bucket       Metro    Snowflake  ACS      Match?  \n",
      "   ------------ -------- ---------- -------- --------\n",
      "   100K-1M      Rural    47         47       ✓       \n",
      "   100K-1M      Urban    353        353      ✓       \n",
      "   1M+          Urban    45         45       ✓       \n",
      "   Unknown County Rural    0          47       ✗       \n",
      "   Unknown County Urban    0          43       ✗       \n",
      "\n",
      "6. 1M+ COUNTIES SPECIFIC ANALYSIS:\n",
      "   Total 1M+ counties (Snowflake): 48\n",
      "   1M+ counties with ACS data: 45\n",
      "   1M+ counties with metro status: 45\n",
      "   1M+ Rural counties (denominator): 0\n",
      "   1M+ Urban counties (denominator): 45\n",
      "\n",
      "7. CONCLUSION:\n",
      "   ✗ Your coverage denominators ≠ ACS denominators\n",
      "   ✗ Some counties without employment data are included\n",
      "   ✗ Coverage percentages may be misleading\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Debug coverage denominators to understand what's being used\n",
    "\n",
    "def debug_coverage_denominators(county_employed, full_county_universe):\n",
    "    \"\"\"\n",
    "    Debug what denominators are actually being used in coverage calculations\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DEBUGGING COVERAGE DENOMINATORS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Basic counts\n",
    "    print(\"\\n1. BASIC DATASET COUNTS:\")\n",
    "    print(f\"   Total counties in Snowflake: {len(full_county_universe):,}\")\n",
    "    print(f\"   Counties with ACS employment data: {len(county_employed['county_fips'].unique()):,}\")\n",
    "    \n",
    "    # 2. Population bucket analysis\n",
    "    print(\"\\n2. POPULATION BUCKET BREAKDOWN:\")\n",
    "    \n",
    "    # Snowflake population distribution\n",
    "    snowflake_pop_dist = full_county_universe['pop_label'].value_counts().sort_index()\n",
    "    print(f\"   Snowflake population distribution:\")\n",
    "    for bucket, count in snowflake_pop_dist.items():\n",
    "        print(f\"     {bucket}: {count:,} counties\")\n",
    "    \n",
    "    # ACS population distribution (after Snowflake mapping)\n",
    "    acs_pop_dist = county_employed.groupby('pop_label')['county_fips'].nunique().sort_index()\n",
    "    print(f\"\\n   ACS population distribution (after Snowflake mapping):\")\n",
    "    for bucket, count in acs_pop_dist.items():\n",
    "        print(f\"     {bucket}: {count:,} counties\")\n",
    "    \n",
    "    # 3. Metro status analysis\n",
    "    print(\"\\n3. METRO STATUS BREAKDOWN:\")\n",
    "    \n",
    "    # Create metro mapping like representation matrices do\n",
    "    county_employed['metro_label'] = county_employed['metro_status'].map({\n",
    "        'Non-metro/Rural': 'Rural',\n",
    "        'Metropolitan': 'Urban'\n",
    "    })\n",
    "    \n",
    "    metro_mapping = county_employed[['county_fips', 'metro_label']].drop_duplicates()\n",
    "    print(f\"   Counties with metro status mapping: {len(metro_mapping):,}\")\n",
    "    \n",
    "    # Merge Snowflake with metro mapping (like representation matrices)\n",
    "    universe_with_metro = full_county_universe.merge(metro_mapping, on='county_fips', how='left')\n",
    "    counties_with_metro = universe_with_metro.dropna(subset=['metro_label'])\n",
    "    \n",
    "    print(f\"   Snowflake counties that can be assigned metro status: {len(counties_with_metro):,}\")\n",
    "    print(f\"   Snowflake counties without metro status: {len(universe_with_metro) - len(counties_with_metro):,}\")\n",
    "    \n",
    "    # 4. Pop + Metro combinations\n",
    "    print(\"\\n4. POPULATION + METRO COMBINATIONS:\")\n",
    "    \n",
    "    # What representation matrices actually use as denominators\n",
    "    total_counts = counties_with_metro.groupby(['pop_label', 'metro_label']).size().reset_index(name='total_units')\n",
    "    print(f\"   Denominator combinations (what rep matrices use):\")\n",
    "    for _, row in total_counts.iterrows():\n",
    "        print(f\"     {row['pop_label']} {row['metro_label']}: {row['total_units']:,} counties\")\n",
    "    \n",
    "    # What pure ACS would give us\n",
    "    acs_counts = county_employed.groupby(['pop_label', 'metro_label'])['county_fips'].nunique().reset_index(name='acs_units')\n",
    "    print(f\"\\n   Pure ACS combinations:\")\n",
    "    for _, row in acs_counts.iterrows():\n",
    "        print(f\"     {row['pop_label']} {row['metro_label']}: {row['acs_units']:,} counties\")\n",
    "    \n",
    "    # 5. Coverage comparison\n",
    "    print(\"\\n5. COVERAGE COMPARISON:\")\n",
    "    \n",
    "    # Compare the denominators\n",
    "    comparison = total_counts.merge(acs_counts, on=['pop_label', 'metro_label'], how='outer', suffixes=('_snowflake', '_acs')).fillna(0)\n",
    "    \n",
    "    print(f\"   {'Bucket':<12} {'Metro':<8} {'Snowflake':<10} {'ACS':<8} {'Match?':<8}\")\n",
    "    print(f\"   {'-'*12} {'-'*8} {'-'*10} {'-'*8} {'-'*8}\")\n",
    "    \n",
    "    for _, row in comparison.iterrows():\n",
    "        bucket = row['pop_label']\n",
    "        metro = row['metro_label']\n",
    "        sf_count = int(row['total_units'])\n",
    "        acs_count = int(row['acs_units'])\n",
    "        match = \"✓\" if sf_count == acs_count else \"✗\"\n",
    "        \n",
    "        print(f\"   {bucket:<12} {metro:<8} {sf_count:<10} {acs_count:<8} {match:<8}\")\n",
    "    \n",
    "    # 6. 1M+ specific analysis\n",
    "    print(\"\\n6. 1M+ COUNTIES SPECIFIC ANALYSIS:\")\n",
    "    \n",
    "    # 1M+ counties from Snowflake\n",
    "    counties_1m_snowflake = set(full_county_universe[full_county_universe['pop_label'] == '1M+']['county_fips'])\n",
    "    \n",
    "    # 1M+ counties with ACS data\n",
    "    counties_1m_acs = set(county_employed[county_employed['pop_label'] == '1M+']['county_fips'])\n",
    "    \n",
    "    # 1M+ counties with metro status\n",
    "    counties_1m_with_metro = set(counties_with_metro[counties_with_metro['pop_label'] == '1M+']['county_fips'])\n",
    "    \n",
    "    print(f\"   Total 1M+ counties (Snowflake): {len(counties_1m_snowflake):,}\")\n",
    "    print(f\"   1M+ counties with ACS data: {len(counties_1m_acs):,}\")\n",
    "    print(f\"   1M+ counties with metro status: {len(counties_1m_with_metro):,}\")\n",
    "    \n",
    "    # Rural/Urban split for 1M+\n",
    "    counties_1m_rural = len(counties_with_metro[(counties_with_metro['pop_label'] == '1M+') & (counties_with_metro['metro_label'] == 'Rural')])\n",
    "    counties_1m_urban = len(counties_with_metro[(counties_with_metro['pop_label'] == '1M+') & (counties_with_metro['metro_label'] == 'Urban')])\n",
    "    \n",
    "    print(f\"   1M+ Rural counties (denominator): {counties_1m_rural:,}\")\n",
    "    print(f\"   1M+ Urban counties (denominator): {counties_1m_urban:,}\")\n",
    "    \n",
    "    print(\"\\n7. CONCLUSION:\")\n",
    "    if len(counties_with_metro) == len(metro_mapping):\n",
    "        print(\"   ✓ Your coverage denominators = ACS denominators\")\n",
    "        print(\"   ✓ Only counties with employment data are included\")\n",
    "        print(\"   ✓ 100% coverage makes sense - you have data for all counties you can analyze\")\n",
    "    else:\n",
    "        print(\"   ✗ Your coverage denominators ≠ ACS denominators\") \n",
    "        print(\"   ✗ Some counties without employment data are included\")\n",
    "        print(\"   ✗ Coverage percentages may be misleading\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the debug\n",
    "debug_coverage_denominators(county_employed, full_county_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ce14daa-b159-4ba3-a4e0-fc4971791d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>total_pumas</th>\n",
       "      <th>rural_pumas</th>\n",
       "      <th>urban_pumas</th>\n",
       "      <th>total_employment_pct</th>\n",
       "      <th>rural_employment_pct</th>\n",
       "      <th>urban_employment_pct</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>rural_employment</th>\n",
       "      <th>urban_employment</th>\n",
       "      <th>total_naics_2digit_coverage_pct</th>\n",
       "      <th>rural_naics_2digit_coverage_pct</th>\n",
       "      <th>urban_naics_2digit_coverage_pct</th>\n",
       "      <th>total_naics_3digit_coverage_pct</th>\n",
       "      <th>rural_naics_3digit_coverage_pct</th>\n",
       "      <th>urban_naics_3digit_coverage_pct</th>\n",
       "      <th>total_naics_4digit_coverage_pct</th>\n",
       "      <th>rural_naics_4digit_coverage_pct</th>\n",
       "      <th>urban_naics_4digit_coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-25K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25K-50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50K-75K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75K-100K</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1711081</td>\n",
       "      <td>117616</td>\n",
       "      <td>1593465</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.16</td>\n",
       "      <td>91.76</td>\n",
       "      <td>94.34</td>\n",
       "      <td>85.59</td>\n",
       "      <td>75.74</td>\n",
       "      <td>86.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100K-1M</td>\n",
       "      <td>2428</td>\n",
       "      <td>506</td>\n",
       "      <td>1922</td>\n",
       "      <td>98.93</td>\n",
       "      <td>19.31</td>\n",
       "      <td>79.62</td>\n",
       "      <td>158872334</td>\n",
       "      <td>31016329</td>\n",
       "      <td>127856005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.96</td>\n",
       "      <td>92.46</td>\n",
       "      <td>93.08</td>\n",
       "      <td>84.10</td>\n",
       "      <td>82.19</td>\n",
       "      <td>84.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1M+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  total_pumas  rural_pumas  urban_pumas  total_employment_pct  \\\n",
       "0     0-25K            0            0            0                  0.00   \n",
       "1   25K-50K            0            0            0                  0.00   \n",
       "2   50K-75K            0            0            0                  0.00   \n",
       "3  75K-100K           34            3           31                  1.07   \n",
       "4   100K-1M         2428          506         1922                 98.93   \n",
       "5       1M+            0            0            0                  0.00   \n",
       "\n",
       "   rural_employment_pct  urban_employment_pct  total_employment  \\\n",
       "0                  0.00                  0.00                 0   \n",
       "1                  0.00                  0.00                 0   \n",
       "2                  0.00                  0.00                 0   \n",
       "3                  0.07                  0.99           1711081   \n",
       "4                 19.31                 79.62         158872334   \n",
       "5                  0.00                  0.00                 0   \n",
       "\n",
       "   rural_employment  urban_employment  total_naics_2digit_coverage_pct  \\\n",
       "0                 0                 0                              0.0   \n",
       "1                 0                 0                              0.0   \n",
       "2                 0                 0                              0.0   \n",
       "3            117616           1593465                            100.0   \n",
       "4          31016329         127856005                            100.0   \n",
       "5                 0                 0                              0.0   \n",
       "\n",
       "   rural_naics_2digit_coverage_pct  urban_naics_2digit_coverage_pct  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                            100.0                            100.0   \n",
       "4                            100.0                            100.0   \n",
       "5                              0.0                              0.0   \n",
       "\n",
       "   total_naics_3digit_coverage_pct  rural_naics_3digit_coverage_pct  \\\n",
       "0                             0.00                             0.00   \n",
       "1                             0.00                             0.00   \n",
       "2                             0.00                             0.00   \n",
       "3                            94.16                            91.76   \n",
       "4                            92.96                            92.46   \n",
       "5                             0.00                             0.00   \n",
       "\n",
       "   urban_naics_3digit_coverage_pct  total_naics_4digit_coverage_pct  \\\n",
       "0                             0.00                             0.00   \n",
       "1                             0.00                             0.00   \n",
       "2                             0.00                             0.00   \n",
       "3                            94.34                            85.59   \n",
       "4                            93.08                            84.10   \n",
       "5                             0.00                             0.00   \n",
       "\n",
       "   rural_naics_4digit_coverage_pct  urban_naics_4digit_coverage_pct  \n",
       "0                             0.00                             0.00  \n",
       "1                             0.00                             0.00  \n",
       "2                             0.00                             0.00  \n",
       "3                            75.74                            86.32  \n",
       "4                            82.19                            84.56  \n",
       "5                             0.00                             0.00  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puma_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "793c7f84-6ac1-41aa-99f7-68e107277ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>total_counties</th>\n",
       "      <th>rural_counties</th>\n",
       "      <th>urban_counties</th>\n",
       "      <th>total_employment_pct</th>\n",
       "      <th>rural_employment_pct</th>\n",
       "      <th>urban_employment_pct</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>rural_employment</th>\n",
       "      <th>urban_employment</th>\n",
       "      <th>total_naics_2digit_coverage_pct</th>\n",
       "      <th>rural_naics_2digit_coverage_pct</th>\n",
       "      <th>urban_naics_2digit_coverage_pct</th>\n",
       "      <th>total_naics_3digit_coverage_pct</th>\n",
       "      <th>rural_naics_3digit_coverage_pct</th>\n",
       "      <th>urban_naics_3digit_coverage_pct</th>\n",
       "      <th>total_naics_4digit_coverage_pct</th>\n",
       "      <th>rural_naics_4digit_coverage_pct</th>\n",
       "      <th>urban_naics_4digit_coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-25K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25K-50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50K-75K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75K-100K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100K-1M</td>\n",
       "      <td>400</td>\n",
       "      <td>47</td>\n",
       "      <td>353</td>\n",
       "      <td>40.72</td>\n",
       "      <td>2.53</td>\n",
       "      <td>38.19</td>\n",
       "      <td>65391071.0</td>\n",
       "      <td>4069053</td>\n",
       "      <td>61322018</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.16</td>\n",
       "      <td>93.56</td>\n",
       "      <td>93.13</td>\n",
       "      <td>84.73</td>\n",
       "      <td>85.76</td>\n",
       "      <td>84.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1M+</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>28.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.74</td>\n",
       "      <td>46154828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46154828</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>93.33</td>\n",
       "      <td>84.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Population Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49037516.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pop_label  total_counties  rural_counties  urban_counties  \\\n",
       "0               0-25K               0               0               0   \n",
       "1             25K-50K               0               0               0   \n",
       "2             50K-75K               0               0               0   \n",
       "3            75K-100K               0               0               0   \n",
       "4             100K-1M             400              47             353   \n",
       "5                 1M+              45               0              45   \n",
       "6  Population Unknown               0               0               0   \n",
       "\n",
       "   total_employment_pct  rural_employment_pct  urban_employment_pct  \\\n",
       "0                  0.00                  0.00                  0.00   \n",
       "1                  0.00                  0.00                  0.00   \n",
       "2                  0.00                  0.00                  0.00   \n",
       "3                  0.00                  0.00                  0.00   \n",
       "4                 40.72                  2.53                 38.19   \n",
       "5                 28.74                  0.00                 28.74   \n",
       "6                 30.54                  0.00                  0.00   \n",
       "\n",
       "   total_employment  rural_employment  urban_employment  \\\n",
       "0               0.0                 0                 0   \n",
       "1               0.0                 0                 0   \n",
       "2               0.0                 0                 0   \n",
       "3               0.0                 0                 0   \n",
       "4        65391071.0           4069053          61322018   \n",
       "5        46154828.0                 0          46154828   \n",
       "6        49037516.0                 0                 0   \n",
       "\n",
       "   total_naics_2digit_coverage_pct  rural_naics_2digit_coverage_pct  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                            100.0                            100.0   \n",
       "5                            100.0                              0.0   \n",
       "6                              0.0                              0.0   \n",
       "\n",
       "   urban_naics_2digit_coverage_pct  total_naics_3digit_coverage_pct  \\\n",
       "0                              0.0                             0.00   \n",
       "1                              0.0                             0.00   \n",
       "2                              0.0                             0.00   \n",
       "3                              0.0                             0.00   \n",
       "4                            100.0                            93.16   \n",
       "5                            100.0                            93.33   \n",
       "6                              0.0                             0.00   \n",
       "\n",
       "   rural_naics_3digit_coverage_pct  urban_naics_3digit_coverage_pct  \\\n",
       "0                             0.00                             0.00   \n",
       "1                             0.00                             0.00   \n",
       "2                             0.00                             0.00   \n",
       "3                             0.00                             0.00   \n",
       "4                            93.56                            93.13   \n",
       "5                             0.00                            93.33   \n",
       "6                             0.00                             0.00   \n",
       "\n",
       "   total_naics_4digit_coverage_pct  rural_naics_4digit_coverage_pct  \\\n",
       "0                             0.00                             0.00   \n",
       "1                             0.00                             0.00   \n",
       "2                             0.00                             0.00   \n",
       "3                             0.00                             0.00   \n",
       "4                            84.73                            85.76   \n",
       "5                            84.86                             0.00   \n",
       "6                             0.00                             0.00   \n",
       "\n",
       "   urban_naics_4digit_coverage_pct  \n",
       "0                             0.00  \n",
       "1                             0.00  \n",
       "2                             0.00  \n",
       "3                             0.00  \n",
       "4                            84.66  \n",
       "5                            84.86  \n",
       "6                             0.00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e845e376-384b-4983-9ef4-6a6bee60e253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics_level</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>industry_title</th>\n",
       "      <th>rural_urban_status</th>\n",
       "      <th>0-25K</th>\n",
       "      <th>25K-50K</th>\n",
       "      <th>50K-75K</th>\n",
       "      <th>75K-100K</th>\n",
       "      <th>100K-1M</th>\n",
       "      <th>1M+</th>\n",
       "      <th>Unknown County</th>\n",
       "      <th>geo_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>21</td>\n",
       "      <td>Mining, Quarrying, and Oil and Gas Extraction</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>21</td>\n",
       "      <td>Mining, Quarrying, and Oil and Gas Extraction</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>22</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92M1</td>\n",
       "      <td>Administration of environmental quality, and h...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92M2</td>\n",
       "      <td>Administration of economic programs and space ...</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92M2</td>\n",
       "      <td>Administration of economic programs and space ...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92MP</td>\n",
       "      <td>Justice, public order, and safety activities</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92MP</td>\n",
       "      <td>Justice, public order, and safety activities</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      naics_level industry_code  \\\n",
       "0    naics_2digit            11   \n",
       "1    naics_2digit            11   \n",
       "2    naics_2digit            21   \n",
       "3    naics_2digit            21   \n",
       "4    naics_2digit            22   \n",
       "..            ...           ...   \n",
       "605  naics_4digit          92M1   \n",
       "606  naics_4digit          92M2   \n",
       "607  naics_4digit          92M2   \n",
       "608  naics_4digit          92MP   \n",
       "609  naics_4digit          92MP   \n",
       "\n",
       "                                        industry_title rural_urban_status  \\\n",
       "0           Agriculture, Forestry, Fishing and Hunting    Non-metro/Rural   \n",
       "1           Agriculture, Forestry, Fishing and Hunting       Metropolitan   \n",
       "2        Mining, Quarrying, and Oil and Gas Extraction    Non-metro/Rural   \n",
       "3        Mining, Quarrying, and Oil and Gas Extraction       Metropolitan   \n",
       "4                                            Utilities    Non-metro/Rural   \n",
       "..                                                 ...                ...   \n",
       "605  Administration of environmental quality, and h...       Metropolitan   \n",
       "606  Administration of economic programs and space ...    Non-metro/Rural   \n",
       "607  Administration of economic programs and space ...       Metropolitan   \n",
       "608       Justice, public order, and safety activities    Non-metro/Rural   \n",
       "609       Justice, public order, and safety activities       Metropolitan   \n",
       "\n",
       "     0-25K  25K-50K  50K-75K  75K-100K  100K-1M  1M+  Unknown County geo_level  \n",
       "0      0.0      0.0      0.0      8.23     2.89  0.0             0.0      PUMA  \n",
       "1      0.0      0.0      0.0      0.34     0.78  0.0             0.0      PUMA  \n",
       "2      0.0      0.0      0.0      1.77     0.93  0.0             0.0      PUMA  \n",
       "3      0.0      0.0      0.0      0.05     0.29  0.0             0.0      PUMA  \n",
       "4      0.0      0.0      0.0      1.60     1.13  0.0             0.0      PUMA  \n",
       "..     ...      ...      ...       ...      ...  ...             ...       ...  \n",
       "605    0.0      0.0      0.0      0.17     0.18  0.0             0.0      PUMA  \n",
       "606    0.0      0.0      0.0      1.40     0.46  0.0             0.0      PUMA  \n",
       "607    0.0      0.0      0.0      0.40     0.42  0.0             0.0      PUMA  \n",
       "608    0.0      0.0      0.0      3.63     2.65  0.0             0.0      PUMA  \n",
       "609    0.0      0.0      0.0      1.66     2.02  0.0             0.0      PUMA  \n",
       "\n",
       "[610 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puma_employment_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff3c15fa-8d0f-4775-b378-e9b64fbed228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums by area type (should be ~100%):\n",
      "                                 0-25K  25K-50K  50K-75K  75K-100K  100K-1M  \\\n",
      "rural_urban_status naics_level                                                \n",
      "Non-metro/Rural    naics_2digit    0.0      0.0      0.0       0.0    99.99   \n",
      "                   naics_3digit    0.0      0.0      0.0       0.0    99.96   \n",
      "                   naics_4digit    0.0      0.0      0.0       0.0    99.98   \n",
      "Metropolitan       naics_2digit    0.0      0.0      0.0       0.0   100.02   \n",
      "                   naics_3digit    0.0      0.0      0.0       0.0    99.99   \n",
      "                   naics_4digit    0.0      0.0      0.0       0.0   100.03   \n",
      "\n",
      "                                    1M+  Unknown County  \n",
      "rural_urban_status naics_level                           \n",
      "Non-metro/Rural    naics_2digit    0.00          100.01  \n",
      "                   naics_3digit    0.00          100.02  \n",
      "                   naics_4digit    0.00           99.97  \n",
      "Metropolitan       naics_2digit  100.01           99.99  \n",
      "                   naics_3digit  100.02          100.01  \n",
      "                   naics_4digit   99.97          100.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/606075091.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  verification = county_employment_shares.groupby(['rural_urban_status', 'naics_level'])[\n"
     ]
    }
   ],
   "source": [
    "# Check if shares sum to 100% for each area type\n",
    "verification = county_employment_shares.groupby(['rural_urban_status', 'naics_level'])[\n",
    "    ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "].sum()\n",
    "\n",
    "print(\"Sums by area type (should be ~100%):\")\n",
    "print(verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66cde64e-2c31-47ea-bedc-1d4df0755883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics_level</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>industry_title</th>\n",
       "      <th>rural_urban_status</th>\n",
       "      <th>0-25K</th>\n",
       "      <th>25K-50K</th>\n",
       "      <th>50K-75K</th>\n",
       "      <th>75K-100K</th>\n",
       "      <th>100K-1M</th>\n",
       "      <th>1M+</th>\n",
       "      <th>Unknown County</th>\n",
       "      <th>geo_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.19</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>21</td>\n",
       "      <td>Mining, Quarrying, and Oil and Gas Extraction</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>21</td>\n",
       "      <td>Mining, Quarrying, and Oil and Gas Extraction</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.37</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>naics_2digit</td>\n",
       "      <td>22</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92M1</td>\n",
       "      <td>Administration of environmental quality, and h...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92M2</td>\n",
       "      <td>Administration of economic programs and space ...</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92M2</td>\n",
       "      <td>Administration of economic programs and space ...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92MP</td>\n",
       "      <td>Justice, public order, and safety activities</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>naics_4digit</td>\n",
       "      <td>92MP</td>\n",
       "      <td>Justice, public order, and safety activities</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.37</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       naics_level industry_code  \\\n",
       "610   naics_2digit            11   \n",
       "611   naics_2digit            11   \n",
       "612   naics_2digit            21   \n",
       "613   naics_2digit            21   \n",
       "614   naics_2digit            22   \n",
       "...            ...           ...   \n",
       "1215  naics_4digit          92M1   \n",
       "1216  naics_4digit          92M2   \n",
       "1217  naics_4digit          92M2   \n",
       "1218  naics_4digit          92MP   \n",
       "1219  naics_4digit          92MP   \n",
       "\n",
       "                                         industry_title rural_urban_status  \\\n",
       "610          Agriculture, Forestry, Fishing and Hunting    Non-metro/Rural   \n",
       "611          Agriculture, Forestry, Fishing and Hunting       Metropolitan   \n",
       "612       Mining, Quarrying, and Oil and Gas Extraction    Non-metro/Rural   \n",
       "613       Mining, Quarrying, and Oil and Gas Extraction       Metropolitan   \n",
       "614                                           Utilities    Non-metro/Rural   \n",
       "...                                                 ...                ...   \n",
       "1215  Administration of environmental quality, and h...       Metropolitan   \n",
       "1216  Administration of economic programs and space ...    Non-metro/Rural   \n",
       "1217  Administration of economic programs and space ...       Metropolitan   \n",
       "1218       Justice, public order, and safety activities    Non-metro/Rural   \n",
       "1219       Justice, public order, and safety activities       Metropolitan   \n",
       "\n",
       "      0-25K  25K-50K  50K-75K  75K-100K  100K-1M   1M+  Unknown County  \\\n",
       "610     0.0      0.0      0.0       0.0     1.25  0.00            3.16   \n",
       "611     0.0      0.0      0.0       0.0     0.90  0.42            1.19   \n",
       "612     0.0      0.0      0.0       0.0     0.20  0.00            1.04   \n",
       "613     0.0      0.0      0.0       0.0     0.30  0.22            0.37   \n",
       "614     0.0      0.0      0.0       0.0     0.76  0.00            1.19   \n",
       "...     ...      ...      ...       ...      ...   ...             ...   \n",
       "1215    0.0      0.0      0.0       0.0     0.19  0.14            0.23   \n",
       "1216    0.0      0.0      0.0       0.0     0.45  0.00            0.47   \n",
       "1217    0.0      0.0      0.0       0.0     0.45  0.34            0.49   \n",
       "1218    0.0      0.0      0.0       0.0     1.83  0.00            2.78   \n",
       "1219    0.0      0.0      0.0       0.0     2.13  1.70            2.37   \n",
       "\n",
       "     geo_level  \n",
       "610     County  \n",
       "611     County  \n",
       "612     County  \n",
       "613     County  \n",
       "614     County  \n",
       "...        ...  \n",
       "1215    County  \n",
       "1216    County  \n",
       "1217    County  \n",
       "1218    County  \n",
       "1219    County  \n",
       "\n",
       "[610 rows x 12 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_employment_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a3b9b53-35aa-458f-a053-bf9474c2ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums by area type (should be ~100%):\n",
      "                                 0-25K  25K-50K  50K-75K  75K-100K  100K-1M  \\\n",
      "rural_urban_status naics_level                                                \n",
      "Non-metro/Rural    naics_2digit    0.0      0.0      0.0       0.0    99.99   \n",
      "                   naics_3digit    0.0      0.0      0.0       0.0    99.96   \n",
      "                   naics_4digit    0.0      0.0      0.0       0.0    99.98   \n",
      "Metropolitan       naics_2digit    0.0      0.0      0.0       0.0   100.02   \n",
      "                   naics_3digit    0.0      0.0      0.0       0.0    99.99   \n",
      "                   naics_4digit    0.0      0.0      0.0       0.0   100.03   \n",
      "\n",
      "                                    1M+  Unknown County  \n",
      "rural_urban_status naics_level                           \n",
      "Non-metro/Rural    naics_2digit    0.00          100.01  \n",
      "                   naics_3digit    0.00          100.02  \n",
      "                   naics_4digit    0.00           99.97  \n",
      "Metropolitan       naics_2digit  100.01           99.99  \n",
      "                   naics_3digit  100.02          100.01  \n",
      "                   naics_4digit   99.97          100.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793/606075091.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  verification = county_employment_shares.groupby(['rural_urban_status', 'naics_level'])[\n"
     ]
    }
   ],
   "source": [
    "# Check if shares sum to 100% for each area type\n",
    "verification = county_employment_shares.groupby(['rural_urban_status', 'naics_level'])[\n",
    "    ['0-25K', '25K-50K', '50K-75K', '75K-100K', '100K-1M', '1M+', 'Unknown County']\n",
    "].sum()\n",
    "\n",
    "print(\"Sums by area type (should be ~100%):\")\n",
    "print(verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68674d33-e413-4b2b-a781-27e033a5b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry_code</th>\n",
       "      <th>industry_title</th>\n",
       "      <th>0-25K Rural</th>\n",
       "      <th>0-25K Urban</th>\n",
       "      <th>25K-50K Rural</th>\n",
       "      <th>25K-50K Urban</th>\n",
       "      <th>50K-75K Rural</th>\n",
       "      <th>50K-75K Urban</th>\n",
       "      <th>75K-100K Rural</th>\n",
       "      <th>75K-100K Urban</th>\n",
       "      <th>100K-1M Rural</th>\n",
       "      <th>100K-1M Urban</th>\n",
       "      <th>1M+ Rural</th>\n",
       "      <th>1M+ Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>Crop production</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>99.8</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>Animal production and aquaculture</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>99.4</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>86.6</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1133</td>\n",
       "      <td>Logging</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>75.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>9281P</td>\n",
       "      <td>National security and international affairs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.6</td>\n",
       "      <td>98.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>92M</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>92M1</td>\n",
       "      <td>Administration of environmental quality, and h...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.1</td>\n",
       "      <td>97.6</td>\n",
       "      <td>91.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>92M2</td>\n",
       "      <td>Administration of economic programs and space ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>99.8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>92MP</td>\n",
       "      <td>Justice, public order, and safety activities</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    industry_code                                     industry_title  \\\n",
       "0              11         Agriculture, Forestry, Fishing and Hunting   \n",
       "1             111                                    Crop production   \n",
       "2             112                  Animal production and aquaculture   \n",
       "3             113                               Forestry and Logging   \n",
       "4            1133                                            Logging   \n",
       "..            ...                                                ...   \n",
       "389         9281P        National security and international affairs   \n",
       "390           92M                                       Unclassified   \n",
       "391          92M1  Administration of environmental quality, and h...   \n",
       "392          92M2  Administration of economic programs and space ...   \n",
       "393          92MP       Justice, public order, and safety activities   \n",
       "\n",
       "     0-25K Rural  0-25K Urban  25K-50K Rural  25K-50K Urban  50K-75K Rural  \\\n",
       "0            0.0          0.0            0.0            0.0            0.0   \n",
       "1            0.0          0.0            0.0            0.0            0.0   \n",
       "2            0.0          0.0            0.0            0.0            0.0   \n",
       "3            0.0          0.0            0.0            0.0            0.0   \n",
       "4            0.0          0.0            0.0            0.0            0.0   \n",
       "..           ...          ...            ...            ...            ...   \n",
       "389          0.0          0.0            0.0            0.0            0.0   \n",
       "390          0.0          0.0            0.0            0.0            0.0   \n",
       "391          0.0          0.0            0.0            0.0            0.0   \n",
       "392          0.0          0.0            0.0            0.0            0.0   \n",
       "393          0.0          0.0            0.0            0.0            0.0   \n",
       "\n",
       "     50K-75K Urban  75K-100K Rural  75K-100K Urban  100K-1M Rural  \\\n",
       "0              0.0           100.0           100.0          100.0   \n",
       "1              0.0           100.0            93.5           99.8   \n",
       "2              0.0           100.0            74.2           99.4   \n",
       "3              0.0           100.0            32.3           86.6   \n",
       "4              0.0            66.7             9.7           75.5   \n",
       "..             ...             ...             ...            ...   \n",
       "389            0.0           100.0           100.0           98.6   \n",
       "390            0.0           100.0           100.0          100.0   \n",
       "391            0.0           100.0            87.1           97.6   \n",
       "392            0.0           100.0            96.8           99.8   \n",
       "393            0.0           100.0           100.0          100.0   \n",
       "\n",
       "     100K-1M Urban  1M+ Rural  1M+ Urban  \n",
       "0             99.4        0.0        0.0  \n",
       "1             96.4        0.0        0.0  \n",
       "2             80.2        0.0        0.0  \n",
       "3             46.1        0.0        0.0  \n",
       "4             25.7        0.0        0.0  \n",
       "..             ...        ...        ...  \n",
       "389           98.6        0.0        0.0  \n",
       "390          100.0        0.0        0.0  \n",
       "391           91.9        0.0        0.0  \n",
       "392           99.0        0.0        0.0  \n",
       "393          100.0        0.0        0.0  \n",
       "\n",
       "[394 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naics_rep_puma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaeea70d-bd5d-48cb-a13c-312b0ca12990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry_code</th>\n",
       "      <th>industry_title</th>\n",
       "      <th>0-25K Rural</th>\n",
       "      <th>0-25K Urban</th>\n",
       "      <th>25K-50K Rural</th>\n",
       "      <th>25K-50K Urban</th>\n",
       "      <th>50K-75K Rural</th>\n",
       "      <th>50K-75K Urban</th>\n",
       "      <th>75K-100K Rural</th>\n",
       "      <th>75K-100K Urban</th>\n",
       "      <th>100K-1M Rural</th>\n",
       "      <th>100K-1M Urban</th>\n",
       "      <th>1M+ Rural</th>\n",
       "      <th>1M+ Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>Crop production</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>Animal production and aquaculture</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>76.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1133</td>\n",
       "      <td>Logging</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.8</td>\n",
       "      <td>53.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>9281P</td>\n",
       "      <td>National security and international affairs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>92M</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>92M1</td>\n",
       "      <td>Administration of environmental quality, and h...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.7</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>92M2</td>\n",
       "      <td>Administration of economic programs and space ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>92MP</td>\n",
       "      <td>Justice, public order, and safety activities</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    industry_code                                     industry_title  \\\n",
       "0              11         Agriculture, Forestry, Fishing and Hunting   \n",
       "1             111                                    Crop production   \n",
       "2             112                  Animal production and aquaculture   \n",
       "3             113                               Forestry and Logging   \n",
       "4            1133                                            Logging   \n",
       "..            ...                                                ...   \n",
       "389         9281P        National security and international affairs   \n",
       "390           92M                                       Unclassified   \n",
       "391          92M1  Administration of environmental quality, and h...   \n",
       "392          92M2  Administration of economic programs and space ...   \n",
       "393          92MP       Justice, public order, and safety activities   \n",
       "\n",
       "     0-25K Rural  0-25K Urban  25K-50K Rural  25K-50K Urban  50K-75K Rural  \\\n",
       "0            0.0          0.0            0.0            0.0            0.0   \n",
       "1            0.0          0.0            0.0            0.0            0.0   \n",
       "2            0.0          0.0            0.0            0.0            0.0   \n",
       "3            0.0          0.0            0.0            0.0            0.0   \n",
       "4            0.0          0.0            0.0            0.0            0.0   \n",
       "..           ...          ...            ...            ...            ...   \n",
       "389          0.0          0.0            0.0            0.0            0.0   \n",
       "390          0.0          0.0            0.0            0.0            0.0   \n",
       "391          0.0          0.0            0.0            0.0            0.0   \n",
       "392          0.0          0.0            0.0            0.0            0.0   \n",
       "393          0.0          0.0            0.0            0.0            0.0   \n",
       "\n",
       "     50K-75K Urban  75K-100K Rural  75K-100K Urban  100K-1M Rural  \\\n",
       "0              0.0             0.0             0.0          100.0   \n",
       "1              0.0             0.0             0.0          100.0   \n",
       "2              0.0             0.0             0.0          100.0   \n",
       "3              0.0             0.0             0.0           83.0   \n",
       "4              0.0             0.0             0.0           63.8   \n",
       "..             ...             ...             ...            ...   \n",
       "389            0.0             0.0             0.0          100.0   \n",
       "390            0.0             0.0             0.0          100.0   \n",
       "391            0.0             0.0             0.0           95.7   \n",
       "392            0.0             0.0             0.0          100.0   \n",
       "393            0.0             0.0             0.0          100.0   \n",
       "\n",
       "     100K-1M Urban  1M+ Rural  1M+ Urban  \n",
       "0            100.0        0.0      100.0  \n",
       "1            100.0        0.0      100.0  \n",
       "2             97.7        0.0      100.0  \n",
       "3             76.2        0.0       93.3  \n",
       "4             53.5        0.0       75.6  \n",
       "..             ...        ...        ...  \n",
       "389           99.4        0.0      100.0  \n",
       "390          100.0        0.0      100.0  \n",
       "391           98.0        0.0      100.0  \n",
       "392          100.0        0.0      100.0  \n",
       "393          100.0        0.0      100.0  \n",
       "\n",
       "[394 rows x 14 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naics_rep_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "084a54e8-e9f7-4a14-a072-8910d82eb28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>total_pumas</th>\n",
       "      <th>rural_pumas</th>\n",
       "      <th>urban_pumas</th>\n",
       "      <th>total_employment_pct</th>\n",
       "      <th>rural_employment_pct</th>\n",
       "      <th>urban_employment_pct</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>rural_employment</th>\n",
       "      <th>urban_employment</th>\n",
       "      <th>...</th>\n",
       "      <th>urban_soc_3digit_coverage_pct</th>\n",
       "      <th>total_soc_4digit_coverage_pct</th>\n",
       "      <th>rural_soc_4digit_coverage_pct</th>\n",
       "      <th>urban_soc_4digit_coverage_pct</th>\n",
       "      <th>total_soc_5digit_coverage_pct</th>\n",
       "      <th>rural_soc_5digit_coverage_pct</th>\n",
       "      <th>urban_soc_5digit_coverage_pct</th>\n",
       "      <th>total_soc_6digit_coverage_pct</th>\n",
       "      <th>rural_soc_6digit_coverage_pct</th>\n",
       "      <th>urban_soc_6digit_coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-25K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25K-50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50K-75K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75K-100K</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1711081</td>\n",
       "      <td>117616</td>\n",
       "      <td>1593465</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100K-1M</td>\n",
       "      <td>2428</td>\n",
       "      <td>506</td>\n",
       "      <td>1922</td>\n",
       "      <td>98.93</td>\n",
       "      <td>19.31</td>\n",
       "      <td>79.62</td>\n",
       "      <td>158872334</td>\n",
       "      <td>31016329</td>\n",
       "      <td>127856005</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1M+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  total_pumas  rural_pumas  urban_pumas  total_employment_pct  \\\n",
       "0     0-25K            0            0            0                  0.00   \n",
       "1   25K-50K            0            0            0                  0.00   \n",
       "2   50K-75K            0            0            0                  0.00   \n",
       "3  75K-100K           34            3           31                  1.07   \n",
       "4   100K-1M         2428          506         1922                 98.93   \n",
       "5       1M+            0            0            0                  0.00   \n",
       "\n",
       "   rural_employment_pct  urban_employment_pct  total_employment  \\\n",
       "0                  0.00                  0.00                 0   \n",
       "1                  0.00                  0.00                 0   \n",
       "2                  0.00                  0.00                 0   \n",
       "3                  0.07                  0.99           1711081   \n",
       "4                 19.31                 79.62         158872334   \n",
       "5                  0.00                  0.00                 0   \n",
       "\n",
       "   rural_employment  urban_employment  ...  urban_soc_3digit_coverage_pct  \\\n",
       "0                 0                 0  ...                            0.0   \n",
       "1                 0                 0  ...                            0.0   \n",
       "2                 0                 0  ...                            0.0   \n",
       "3            117616           1593465  ...                          100.0   \n",
       "4          31016329         127856005  ...                          100.0   \n",
       "5                 0                 0  ...                            0.0   \n",
       "\n",
       "   total_soc_4digit_coverage_pct  rural_soc_4digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                          100.0                          100.0   \n",
       "4                          100.0                          100.0   \n",
       "5                            0.0                            0.0   \n",
       "\n",
       "   urban_soc_4digit_coverage_pct  total_soc_5digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                          100.0                          100.0   \n",
       "4                          100.0                          100.0   \n",
       "5                            0.0                            0.0   \n",
       "\n",
       "   rural_soc_5digit_coverage_pct  urban_soc_5digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                          100.0                          100.0   \n",
       "4                          100.0                          100.0   \n",
       "5                            0.0                            0.0   \n",
       "\n",
       "   total_soc_6digit_coverage_pct  rural_soc_6digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "5                            0.0                            0.0   \n",
       "\n",
       "   urban_soc_6digit_coverage_pct  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "5                            0.0  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puma_soc_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bf60706-04ea-441c-b34c-bb0d01ef846b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_label</th>\n",
       "      <th>total_counties</th>\n",
       "      <th>rural_counties</th>\n",
       "      <th>urban_counties</th>\n",
       "      <th>total_employment_pct</th>\n",
       "      <th>rural_employment_pct</th>\n",
       "      <th>urban_employment_pct</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>rural_employment</th>\n",
       "      <th>urban_employment</th>\n",
       "      <th>...</th>\n",
       "      <th>urban_soc_3digit_coverage_pct</th>\n",
       "      <th>total_soc_4digit_coverage_pct</th>\n",
       "      <th>rural_soc_4digit_coverage_pct</th>\n",
       "      <th>urban_soc_4digit_coverage_pct</th>\n",
       "      <th>total_soc_5digit_coverage_pct</th>\n",
       "      <th>rural_soc_5digit_coverage_pct</th>\n",
       "      <th>urban_soc_5digit_coverage_pct</th>\n",
       "      <th>total_soc_6digit_coverage_pct</th>\n",
       "      <th>rural_soc_6digit_coverage_pct</th>\n",
       "      <th>urban_soc_6digit_coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-25K</td>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25K-50K</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50K-75K</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75K-100K</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100K-1M</td>\n",
       "      <td>571</td>\n",
       "      <td>47</td>\n",
       "      <td>524</td>\n",
       "      <td>40.72</td>\n",
       "      <td>2.53</td>\n",
       "      <td>38.19</td>\n",
       "      <td>65391071</td>\n",
       "      <td>4069053</td>\n",
       "      <td>61322018</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1M+</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>28.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.74</td>\n",
       "      <td>46154828</td>\n",
       "      <td>0</td>\n",
       "      <td>46154828</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pop_label  total_counties  rural_counties  urban_counties  \\\n",
       "0     0-25K            1526            1526               0   \n",
       "1   25K-50K             616             616               0   \n",
       "2   50K-75K             252             252               0   \n",
       "3  75K-100K             132               0             132   \n",
       "4   100K-1M             571              47             524   \n",
       "5       1M+              48               0              48   \n",
       "\n",
       "   total_employment_pct  rural_employment_pct  urban_employment_pct  \\\n",
       "0                  0.00                  0.00                  0.00   \n",
       "1                  0.00                  0.00                  0.00   \n",
       "2                  0.00                  0.00                  0.00   \n",
       "3                  0.00                  0.00                  0.00   \n",
       "4                 40.72                  2.53                 38.19   \n",
       "5                 28.74                  0.00                 28.74   \n",
       "\n",
       "   total_employment  rural_employment  urban_employment  ...  \\\n",
       "0                 0                 0                 0  ...   \n",
       "1                 0                 0                 0  ...   \n",
       "2                 0                 0                 0  ...   \n",
       "3                 0                 0                 0  ...   \n",
       "4          65391071           4069053          61322018  ...   \n",
       "5          46154828                 0          46154828  ...   \n",
       "\n",
       "   urban_soc_3digit_coverage_pct  total_soc_4digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                          100.0                          100.0   \n",
       "5                          100.0                          100.0   \n",
       "\n",
       "   rural_soc_4digit_coverage_pct  urban_soc_4digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                          100.0                          100.0   \n",
       "5                            0.0                          100.0   \n",
       "\n",
       "   total_soc_5digit_coverage_pct  rural_soc_5digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                          100.0                          100.0   \n",
       "5                          100.0                            0.0   \n",
       "\n",
       "   urban_soc_5digit_coverage_pct  total_soc_6digit_coverage_pct  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                          100.0                            0.0   \n",
       "5                          100.0                            0.0   \n",
       "\n",
       "   rural_soc_6digit_coverage_pct  urban_soc_6digit_coverage_pct  \n",
       "0                            0.0                            0.0  \n",
       "1                            0.0                            0.0  \n",
       "2                            0.0                            0.0  \n",
       "3                            0.0                            0.0  \n",
       "4                            0.0                            0.0  \n",
       "5                            0.0                            0.0  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_soc_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "290a7793-fa83-45c7-82b5-459a1b5f5650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soc_level</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>rural_urban_status</th>\n",
       "      <th>0-25K</th>\n",
       "      <th>25K-50K</th>\n",
       "      <th>50K-75K</th>\n",
       "      <th>75K-100K</th>\n",
       "      <th>100K-1M</th>\n",
       "      <th>1M+</th>\n",
       "      <th>Unknown County</th>\n",
       "      <th>geo_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.18</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.43</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>13</td>\n",
       "      <td>Business and Financial Operations Occupations</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>13</td>\n",
       "      <td>Business and Financial Operations Occupations</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>15</td>\n",
       "      <td>Computer and Mathematical Occupations</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-100</td>\n",
       "      <td>Military Officer Special and Tactical Operatio...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-200</td>\n",
       "      <td>First-Line Enlisted Military Supervisors</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-200</td>\n",
       "      <td>First-Line Enlisted Military Supervisors</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-300</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-300</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      soc_level occupation_code  \\\n",
       "0    soc_2digit              11   \n",
       "1    soc_2digit              11   \n",
       "2    soc_2digit              13   \n",
       "3    soc_2digit              13   \n",
       "4    soc_2digit              15   \n",
       "..          ...             ...   \n",
       "461  soc_4digit          55-100   \n",
       "462  soc_4digit          55-200   \n",
       "463  soc_4digit          55-200   \n",
       "464  soc_4digit          55-300   \n",
       "465  soc_4digit          55-300   \n",
       "\n",
       "                                      occupation_title rural_urban_status  \\\n",
       "0                               Management Occupations    Non-metro/Rural   \n",
       "1                               Management Occupations       Metropolitan   \n",
       "2        Business and Financial Operations Occupations    Non-metro/Rural   \n",
       "3        Business and Financial Operations Occupations       Metropolitan   \n",
       "4                Computer and Mathematical Occupations    Non-metro/Rural   \n",
       "..                                                 ...                ...   \n",
       "461  Military Officer Special and Tactical Operatio...       Metropolitan   \n",
       "462           First-Line Enlisted Military Supervisors    Non-metro/Rural   \n",
       "463           First-Line Enlisted Military Supervisors       Metropolitan   \n",
       "464  Military Enlisted Tactical Operations and Air/...    Non-metro/Rural   \n",
       "465  Military Enlisted Tactical Operations and Air/...       Metropolitan   \n",
       "\n",
       "     0-25K  25K-50K  50K-75K  75K-100K  100K-1M  1M+  Unknown County geo_level  \n",
       "0      0.0      0.0      0.0     13.18    10.09  0.0             0.0      PUMA  \n",
       "1      0.0      0.0      0.0     12.43    11.60  0.0             0.0      PUMA  \n",
       "2      0.0      0.0      0.0      2.96     3.90  0.0             0.0      PUMA  \n",
       "3      0.0      0.0      0.0      7.14     6.39  0.0             0.0      PUMA  \n",
       "4      0.0      0.0      0.0      1.53     1.89  0.0             0.0      PUMA  \n",
       "..     ...      ...      ...       ...      ...  ...             ...       ...  \n",
       "461    0.0      0.0      0.0      0.05     0.04  0.0             0.0      PUMA  \n",
       "462    0.0      0.0      0.0      0.02     0.04  0.0             0.0      PUMA  \n",
       "463    0.0      0.0      0.0      0.03     0.03  0.0             0.0      PUMA  \n",
       "464    0.0      0.0      0.0      0.01     0.17  0.0             0.0      PUMA  \n",
       "465    0.0      0.0      0.0      0.13     0.11  0.0             0.0      PUMA  \n",
       "\n",
       "[466 rows x 12 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puma_soc_employment_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da23fa5d-8394-4f93-b3d7-2c19c70263dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soc_level</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>rural_urban_status</th>\n",
       "      <th>0-25K</th>\n",
       "      <th>25K-50K</th>\n",
       "      <th>50K-75K</th>\n",
       "      <th>75K-100K</th>\n",
       "      <th>100K-1M</th>\n",
       "      <th>1M+</th>\n",
       "      <th>Unknown County</th>\n",
       "      <th>geo_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.06</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.58</td>\n",
       "      <td>11.84</td>\n",
       "      <td>11.22</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>13</td>\n",
       "      <td>Business and Financial Operations Occupations</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.69</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>13</td>\n",
       "      <td>Business and Financial Operations Occupations</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.92</td>\n",
       "      <td>5.71</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>soc_2digit</td>\n",
       "      <td>15</td>\n",
       "      <td>Computer and Mathematical Occupations</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-100</td>\n",
       "      <td>Military Officer Special and Tactical Operatio...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-200</td>\n",
       "      <td>First-Line Enlisted Military Supervisors</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-200</td>\n",
       "      <td>First-Line Enlisted Military Supervisors</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-300</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>Non-metro/Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>soc_4digit</td>\n",
       "      <td>55-300</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>Metropolitan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      soc_level occupation_code  \\\n",
       "466  soc_2digit              11   \n",
       "467  soc_2digit              11   \n",
       "468  soc_2digit              13   \n",
       "469  soc_2digit              13   \n",
       "470  soc_2digit              15   \n",
       "..          ...             ...   \n",
       "927  soc_4digit          55-100   \n",
       "928  soc_4digit          55-200   \n",
       "929  soc_4digit          55-200   \n",
       "930  soc_4digit          55-300   \n",
       "931  soc_4digit          55-300   \n",
       "\n",
       "                                      occupation_title rural_urban_status  \\\n",
       "466                             Management Occupations    Non-metro/Rural   \n",
       "467                             Management Occupations       Metropolitan   \n",
       "468      Business and Financial Operations Occupations    Non-metro/Rural   \n",
       "469      Business and Financial Operations Occupations       Metropolitan   \n",
       "470              Computer and Mathematical Occupations    Non-metro/Rural   \n",
       "..                                                 ...                ...   \n",
       "927  Military Officer Special and Tactical Operatio...       Metropolitan   \n",
       "928           First-Line Enlisted Military Supervisors    Non-metro/Rural   \n",
       "929           First-Line Enlisted Military Supervisors       Metropolitan   \n",
       "930  Military Enlisted Tactical Operations and Air/...    Non-metro/Rural   \n",
       "931  Military Enlisted Tactical Operations and Air/...       Metropolitan   \n",
       "\n",
       "     0-25K  25K-50K  50K-75K  75K-100K  100K-1M    1M+  Unknown County  \\\n",
       "466    0.0      0.0      0.0       0.0    10.37   0.00           10.06   \n",
       "467    0.0      0.0      0.0       0.0    11.58  11.84           11.22   \n",
       "468    0.0      0.0      0.0       0.0     5.29   0.00            3.69   \n",
       "469    0.0      0.0      0.0       0.0     6.25   6.92            5.71   \n",
       "470    0.0      0.0      0.0       0.0     3.20   0.00            1.69   \n",
       "..     ...      ...      ...       ...      ...    ...             ...   \n",
       "927    0.0      0.0      0.0       0.0     0.05   0.02            0.07   \n",
       "928    0.0      0.0      0.0       0.0     0.07   0.00            0.03   \n",
       "929    0.0      0.0      0.0       0.0     0.04   0.02            0.05   \n",
       "930    0.0      0.0      0.0       0.0     0.15   0.00            0.17   \n",
       "931    0.0      0.0      0.0       0.0     0.12   0.08            0.17   \n",
       "\n",
       "    geo_level  \n",
       "466    County  \n",
       "467    County  \n",
       "468    County  \n",
       "469    County  \n",
       "470    County  \n",
       "..        ...  \n",
       "927    County  \n",
       "928    County  \n",
       "929    County  \n",
       "930    County  \n",
       "931    County  \n",
       "\n",
       "[466 rows x 12 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_soc_employment_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bef575b-d5bf-4348-94c9-1d3fff3e39ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>0-25K Rural</th>\n",
       "      <th>0-25K Urban</th>\n",
       "      <th>25K-50K Rural</th>\n",
       "      <th>25K-50K Urban</th>\n",
       "      <th>50K-75K Rural</th>\n",
       "      <th>50K-75K Urban</th>\n",
       "      <th>75K-100K Rural</th>\n",
       "      <th>75K-100K Urban</th>\n",
       "      <th>100K-1M Rural</th>\n",
       "      <th>100K-1M Urban</th>\n",
       "      <th>1M+ Rural</th>\n",
       "      <th>1M+ Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-100</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>55-200</td>\n",
       "      <td>First-Line Enlisted Military Supervisors</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>55-2011</td>\n",
       "      <td>First-Line Supervisors of Air Crew Members</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>55-3</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>43.7</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>55-300</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>43.7</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>55-3011</td>\n",
       "      <td>Air Crew Members</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>43.7</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    occupation_code                                   occupation_title  \\\n",
       "0                11                             Management Occupations   \n",
       "1              11-1                                     Top Executives   \n",
       "2            11-100                    General and Operations Managers   \n",
       "3           11-1011                                   Chief Executives   \n",
       "4           11-1021                    General and Operations Managers   \n",
       "..              ...                                                ...   \n",
       "752          55-200           First-Line Enlisted Military Supervisors   \n",
       "753         55-2011         First-Line Supervisors of Air Crew Members   \n",
       "754            55-3  Military Enlisted Tactical Operations and Air/...   \n",
       "755          55-300  Military Enlisted Tactical Operations and Air/...   \n",
       "756         55-3011                                   Air Crew Members   \n",
       "\n",
       "     0-25K Rural  0-25K Urban  25K-50K Rural  25K-50K Urban  50K-75K Rural  \\\n",
       "0            0.0          0.0            0.0            0.0            0.0   \n",
       "1            0.0          0.0            0.0            0.0            0.0   \n",
       "2            0.0          0.0            0.0            0.0            0.0   \n",
       "3            0.0          0.0            0.0            0.0            0.0   \n",
       "4            0.0          0.0            0.0            0.0            0.0   \n",
       "..           ...          ...            ...            ...            ...   \n",
       "752          0.0          0.0            0.0            0.0            0.0   \n",
       "753          0.0          0.0            0.0            0.0            0.0   \n",
       "754          0.0          0.0            0.0            0.0            0.0   \n",
       "755          0.0          0.0            0.0            0.0            0.0   \n",
       "756          0.0          0.0            0.0            0.0            0.0   \n",
       "\n",
       "     50K-75K Urban  75K-100K Rural  75K-100K Urban  100K-1M Rural  \\\n",
       "0              0.0           100.0           100.0          100.0   \n",
       "1              0.0           100.0           100.0          100.0   \n",
       "2              0.0           100.0           100.0          100.0   \n",
       "3              0.0           100.0           100.0          100.0   \n",
       "4              0.0           100.0           100.0          100.0   \n",
       "..             ...             ...             ...            ...   \n",
       "752            0.0            33.3            19.4           30.2   \n",
       "753            0.0            33.3            19.4           30.2   \n",
       "754            0.0            33.3            12.9           43.7   \n",
       "755            0.0            33.3            12.9           43.7   \n",
       "756            0.0            33.3            12.9           43.7   \n",
       "\n",
       "     100K-1M Urban  1M+ Rural  1M+ Urban  \n",
       "0            100.0        0.0        0.0  \n",
       "1            100.0        0.0        0.0  \n",
       "2            100.0        0.0        0.0  \n",
       "3             99.8        0.0        0.0  \n",
       "4            100.0        0.0        0.0  \n",
       "..             ...        ...        ...  \n",
       "752           28.8        0.0        0.0  \n",
       "753           28.8        0.0        0.0  \n",
       "754           40.3        0.0        0.0  \n",
       "755           40.3        0.0        0.0  \n",
       "756           40.3        0.0        0.0  \n",
       "\n",
       "[757 rows x 14 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc_rep_puma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8b9843f-1a5f-453b-8ff3-b12e05b47f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>0-25K Rural</th>\n",
       "      <th>0-25K Urban</th>\n",
       "      <th>25K-50K Rural</th>\n",
       "      <th>25K-50K Urban</th>\n",
       "      <th>50K-75K Rural</th>\n",
       "      <th>50K-75K Urban</th>\n",
       "      <th>75K-100K Rural</th>\n",
       "      <th>75K-100K Urban</th>\n",
       "      <th>100K-1M Rural</th>\n",
       "      <th>100K-1M Urban</th>\n",
       "      <th>1M+ Rural</th>\n",
       "      <th>1M+ Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-100</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>55-200</td>\n",
       "      <td>First-Line Enlisted Military Supervisors</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.4</td>\n",
       "      <td>53.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>55-2011</td>\n",
       "      <td>First-Line Supervisors of Air Crew Members</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.4</td>\n",
       "      <td>53.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>55-3</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>55-300</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>55-3011</td>\n",
       "      <td>Air Crew Members</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    occupation_code                                   occupation_title  \\\n",
       "0                11                             Management Occupations   \n",
       "1              11-1                                     Top Executives   \n",
       "2            11-100                    General and Operations Managers   \n",
       "3           11-1011                                   Chief Executives   \n",
       "4           11-1021                    General and Operations Managers   \n",
       "..              ...                                                ...   \n",
       "752          55-200           First-Line Enlisted Military Supervisors   \n",
       "753         55-2011         First-Line Supervisors of Air Crew Members   \n",
       "754            55-3  Military Enlisted Tactical Operations and Air/...   \n",
       "755          55-300  Military Enlisted Tactical Operations and Air/...   \n",
       "756         55-3011                                   Air Crew Members   \n",
       "\n",
       "     0-25K Rural  0-25K Urban  25K-50K Rural  25K-50K Urban  50K-75K Rural  \\\n",
       "0            0.0          0.0            0.0            0.0            0.0   \n",
       "1            0.0          0.0            0.0            0.0            0.0   \n",
       "2            0.0          0.0            0.0            0.0            0.0   \n",
       "3            0.0          0.0            0.0            0.0            0.0   \n",
       "4            0.0          0.0            0.0            0.0            0.0   \n",
       "..           ...          ...            ...            ...            ...   \n",
       "752          0.0          0.0            0.0            0.0            0.0   \n",
       "753          0.0          0.0            0.0            0.0            0.0   \n",
       "754          0.0          0.0            0.0            0.0            0.0   \n",
       "755          0.0          0.0            0.0            0.0            0.0   \n",
       "756          0.0          0.0            0.0            0.0            0.0   \n",
       "\n",
       "     50K-75K Urban  75K-100K Rural  75K-100K Urban  100K-1M Rural  \\\n",
       "0              0.0             0.0             0.0          100.0   \n",
       "1              0.0             0.0             0.0          100.0   \n",
       "2              0.0             0.0             0.0          100.0   \n",
       "3              0.0             0.0             0.0          100.0   \n",
       "4              0.0             0.0             0.0          100.0   \n",
       "..             ...             ...             ...            ...   \n",
       "752            0.0             0.0             0.0           40.4   \n",
       "753            0.0             0.0             0.0           40.4   \n",
       "754            0.0             0.0             0.0           46.8   \n",
       "755            0.0             0.0             0.0           46.8   \n",
       "756            0.0             0.0             0.0           46.8   \n",
       "\n",
       "     100K-1M Urban  1M+ Rural  1M+ Urban  \n",
       "0            100.0        0.0      100.0  \n",
       "1            100.0        0.0      100.0  \n",
       "2            100.0        0.0      100.0  \n",
       "3            100.0        0.0      100.0  \n",
       "4            100.0        0.0      100.0  \n",
       "..             ...        ...        ...  \n",
       "752           53.5        0.0       77.8  \n",
       "753           53.5        0.0       77.8  \n",
       "754           63.5        0.0       93.3  \n",
       "755           63.5        0.0       93.3  \n",
       "756           63.5        0.0       93.3  \n",
       "\n",
       "[757 rows x 14 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc_rep_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0c4d8e6a-b9e0-458b-b8ef-4c64fada99f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>pop_label</th>\n",
       "      <th>status</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>50K-75K</td>\n",
       "      <td>Missing from ACS</td>\n",
       "      <td>No employment data available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01005</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>0-25K</td>\n",
       "      <td>Missing from ACS</td>\n",
       "      <td>No employment data available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01007</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>0-25K</td>\n",
       "      <td>Missing from ACS</td>\n",
       "      <td>No employment data available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01009</td>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>50K-75K</td>\n",
       "      <td>Missing from ACS</td>\n",
       "      <td>No employment data available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01011</td>\n",
       "      <td>Bullock County, Alabama</td>\n",
       "      <td>0-25K</td>\n",
       "      <td>Missing from ACS</td>\n",
       "      <td>No employment data available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>51000</td>\n",
       "      <td>Unknown county 51000</td>\n",
       "      <td>Unknown County</td>\n",
       "      <td>Missing from Snowflake</td>\n",
       "      <td>Not in population dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>53000</td>\n",
       "      <td>Unknown county 53000</td>\n",
       "      <td>Unknown County</td>\n",
       "      <td>Missing from Snowflake</td>\n",
       "      <td>Not in population dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>54000</td>\n",
       "      <td>Unknown county 54000</td>\n",
       "      <td>Unknown County</td>\n",
       "      <td>Missing from Snowflake</td>\n",
       "      <td>Not in population dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>55000</td>\n",
       "      <td>Unknown county 55000</td>\n",
       "      <td>Unknown County</td>\n",
       "      <td>Missing from Snowflake</td>\n",
       "      <td>Not in population dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>56000</td>\n",
       "      <td>Unknown county 56000</td>\n",
       "      <td>Unknown County</td>\n",
       "      <td>Missing from Snowflake</td>\n",
       "      <td>Not in population dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2749 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_fips              county_name       pop_label  \\\n",
       "0          01001  Autauga County, Alabama         50K-75K   \n",
       "1          01005  Barbour County, Alabama           0-25K   \n",
       "2          01007     Bibb County, Alabama           0-25K   \n",
       "3          01009   Blount County, Alabama         50K-75K   \n",
       "4          01011  Bullock County, Alabama           0-25K   \n",
       "...          ...                      ...             ...   \n",
       "2744       51000     Unknown county 51000  Unknown County   \n",
       "2745       53000     Unknown county 53000  Unknown County   \n",
       "2746       54000     Unknown county 54000  Unknown County   \n",
       "2747       55000     Unknown county 55000  Unknown County   \n",
       "2748       56000     Unknown county 56000  Unknown County   \n",
       "\n",
       "                      status                        reason  \n",
       "0           Missing from ACS  No employment data available  \n",
       "1           Missing from ACS  No employment data available  \n",
       "2           Missing from ACS  No employment data available  \n",
       "3           Missing from ACS  No employment data available  \n",
       "4           Missing from ACS  No employment data available  \n",
       "...                      ...                           ...  \n",
       "2744  Missing from Snowflake     Not in population dataset  \n",
       "2745  Missing from Snowflake     Not in population dataset  \n",
       "2746  Missing from Snowflake     Not in population dataset  \n",
       "2747  Missing from Snowflake     Not in population dataset  \n",
       "2748  Missing from Snowflake     Not in population dataset  \n",
       "\n",
       "[2749 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_counties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fd9c31f-b578-4a0d-9efc-ab2a3e758dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_bucket</th>\n",
       "      <th>total_counties_snowflake</th>\n",
       "      <th>counties_with_acs_data</th>\n",
       "      <th>counties_missing_from_acs</th>\n",
       "      <th>coverage_percentage</th>\n",
       "      <th>employment_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-25K</td>\n",
       "      <td>1526</td>\n",
       "      <td>0</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25K-50K</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50K-75K</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75K-100K</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100K-1M</td>\n",
       "      <td>570</td>\n",
       "      <td>399</td>\n",
       "      <td>171</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2822034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1M+</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1953520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  population_bucket  total_counties_snowflake  counties_with_acs_data  \\\n",
       "0             0-25K                      1526                       0   \n",
       "1           25K-50K                       616                       0   \n",
       "2           50K-75K                       252                       0   \n",
       "3          75K-100K                       132                       0   \n",
       "4           100K-1M                       570                     399   \n",
       "5               1M+                        48                      45   \n",
       "\n",
       "   counties_missing_from_acs  coverage_percentage  employment_records  \n",
       "0                       1526                  0.0                   0  \n",
       "1                        616                  0.0                   0  \n",
       "2                        252                  0.0                   0  \n",
       "3                        132                  0.0                   0  \n",
       "4                        171                 70.0             2822034  \n",
       "5                          3                 94.0             1953520  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfe8b8-c8c2-4b17-93bd-4e21fdff9c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
